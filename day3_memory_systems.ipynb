{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3: Memory Systems & Knowledge Management\n",
    "\n",
    "**Duration**: 2 hours  \n",
    "**Learning Format**: 30 min theory + 60 min code + 30 min exercises  \n",
    "**LLM Provider**: OpenAI (GPT-4, GPT-3.5-turbo)\n",
    "\n",
    "## ðŸ“‹ Learning Objectives\n",
    "By the end of this session, you will:\n",
    "- Understand different types of memory systems in AI agents\n",
    "- Implement semantic, episodic, and procedural memory\n",
    "- Integrate vector storage with OpenAI embeddings\n",
    "- Build memory management tools for persistent knowledge\n",
    "- Create agents with cross-session memory capabilities\n",
    "\n",
    "## ðŸ“š Prerequisites\n",
    "- Completed Day 1 (LangGraph Foundations)\n",
    "- Completed Day 2 (State Management & Persistence)\n",
    "- OpenAI API key configured\n",
    "- Basic understanding of embeddings and vector databases\n",
    "\n",
    "## ðŸŽ¯ What We'll Build Today\n",
    "- Personal assistant with comprehensive memory\n",
    "- Knowledge extraction and storage system\n",
    "- Multi-domain memory management agent\n",
    "- Vector-based semantic search capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ“– Part 1: Learning Materials (30 minutes)\n",
    "\n",
    "## ðŸŽ¥ Video Resources\n",
    "\n",
    "**Required Watching** (15 minutes):\n",
    "- [Memory Systems in AI Agents](https://www.youtube.com/watch?v=memory-systems-example) - Overview of memory types\n",
    "- [LangGraph Memory Management](https://www.youtube.com/watch?v=langgraph-memory-example) - Implementation patterns\n",
    "\n",
    "**Optional Deep Dive** (30 minutes):\n",
    "- [Vector Databases for AI](https://www.youtube.com/watch?v=vector-db-example) - Vector storage fundamentals\n",
    "- [OpenAI Embeddings Guide](https://www.youtube.com/watch?v=openai-embeddings-example) - Best practices\n",
    "\n",
    "## ðŸ“š Documentation References\n",
    "- [LangGraph Memory Documentation](https://langchain-ai.github.io/langgraph/concepts/memory/)\n",
    "- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)\n",
    "- [Vector Storage Integration](https://python.langchain.com/docs/integrations/vectorstores/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Theory: Memory Systems in AI Agents\n",
    "\n",
    "### Types of Memory Systems\n",
    "\n",
    "#### 1. **Semantic Memory** ðŸ§©\n",
    "- **What**: General knowledge and facts\n",
    "- **Examples**: \"Paris is the capital of France\", \"Python is a programming language\"\n",
    "- **Implementation**: Vector storage with embeddings for similarity search\n",
    "- **Use Cases**: Knowledge bases, fact retrieval, general information\n",
    "\n",
    "#### 2. **Episodic Memory** ðŸ“–\n",
    "- **What**: Specific events and experiences\n",
    "- **Examples**: \"User asked about weather on Tuesday\", \"Previous conversation about project X\"\n",
    "- **Implementation**: Timestamped conversation logs with context\n",
    "- **Use Cases**: Conversation continuity, user preferences, interaction history\n",
    "\n",
    "#### 3. **Procedural Memory** âš™ï¸\n",
    "- **What**: Skills and procedures (how to do things)\n",
    "- **Examples**: \"How to process a refund\", \"Steps to deploy code\"\n",
    "- **Implementation**: Structured workflows and action sequences\n",
    "- **Use Cases**: Business processes, automated workflows, skill execution\n",
    "\n",
    "### Memory Management Strategies\n",
    "\n",
    "#### **Short-term vs Long-term Memory**\n",
    "```\n",
    "Short-term (Session):\n",
    "â”œâ”€â”€ Current conversation context\n",
    "â”œâ”€â”€ Temporary variables\n",
    "â””â”€â”€ Active task state\n",
    "\n",
    "Long-term (Persistent):\n",
    "â”œâ”€â”€ User preferences\n",
    "â”œâ”€â”€ Historical interactions\n",
    "â”œâ”€â”€ Learned knowledge\n",
    "â””â”€â”€ Accumulated experiences\n",
    "```\n",
    "\n",
    "#### **Namespace-based Organization**\n",
    "- **User-specific**: `user:123:preferences`\n",
    "- **Domain-specific**: `domain:finance:knowledge`\n",
    "- **Temporal**: `session:2024-01-15:conversation`\n",
    "- **Contextual**: `project:alpha:requirements`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Theory: Vector Storage Integration\n",
    "\n",
    "### Why Vector Storage for Memory?\n",
    "1. **Semantic Similarity**: Find related information based on meaning\n",
    "2. **Scalability**: Handle large amounts of knowledge efficiently\n",
    "3. **Flexibility**: Store and retrieve complex, unstructured information\n",
    "4. **Context Awareness**: Understand relationships between concepts\n",
    "\n",
    "### OpenAI Embeddings Strategy\n",
    "```python\n",
    "# Memory Storage Flow\n",
    "Information â†’ Embedding â†’ Vector DB â†’ Similarity Search â†’ Retrieval\n",
    "```\n",
    "\n",
    "### Memory Lifecycle\n",
    "1. **Encoding**: Convert information to embeddings\n",
    "2. **Storage**: Save to vector database with metadata\n",
    "3. **Retrieval**: Query based on similarity\n",
    "4. **Integration**: Inject relevant memories into agent context\n",
    "5. **Update**: Modify or expand existing memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ’» Part 2: Hands-on Code Implementation (60 minutes)\n",
    "\n",
    "## ðŸš€ Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langgraph openai pydantic chromadb python-dotenv sqlalchemy pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, TypedDict, Annotated\n",
    "from dataclasses import dataclass\n",
    "import uuid\n",
    "\n",
    "# LangGraph and LangChain imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "# OpenAI and Pydantic\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Vector storage\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import numpy as np\n",
    "\n",
    "# Environment setup\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"âœ… All dependencies loaded successfully!\")\n",
    "print(f\"ðŸ“Š OpenAI API configured: {'âœ…' if os.getenv('OPENAI_API_KEY') else 'âŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Section 1: Memory System Foundation\n",
    "\n",
    "Let's start by building the core memory system architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory System Data Models\n",
    "\n",
    "class MemoryType:\n",
    "    SEMANTIC = \"semantic\"      # Facts and knowledge\n",
    "    EPISODIC = \"episodic\"      # Events and experiences\n",
    "    PROCEDURAL = \"procedural\"  # Skills and procedures\n",
    "\n",
    "class MemoryEntry(BaseModel):\n",
    "    \"\"\"Base memory entry model\"\"\"\n",
    "    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    content: str\n",
    "    memory_type: str\n",
    "    namespace: str\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "    embedding: Optional[List[float]] = None\n",
    "    importance_score: float = Field(default=1.0, ge=0.0, le=1.0)\n",
    "\n",
    "class SemanticMemory(MemoryEntry):\n",
    "    \"\"\"Semantic memory for facts and knowledge\"\"\"\n",
    "    memory_type: str = Field(default=MemoryType.SEMANTIC)\n",
    "    topic: str\n",
    "    confidence: float = Field(default=1.0, ge=0.0, le=1.0)\n",
    "    source: Optional[str] = None\n",
    "\n",
    "class EpisodicMemory(MemoryEntry):\n",
    "    \"\"\"Episodic memory for events and experiences\"\"\"\n",
    "    memory_type: str = Field(default=MemoryType.EPISODIC)\n",
    "    event_type: str\n",
    "    participants: List[str] = Field(default_factory=list)\n",
    "    context: Dict[str, Any] = Field(default_factory=dict)\n",
    "    duration: Optional[timedelta] = None\n",
    "\n",
    "class ProceduralMemory(MemoryEntry):\n",
    "    \"\"\"Procedural memory for skills and procedures\"\"\"\n",
    "    memory_type: str = Field(default=MemoryType.PROCEDURAL)\n",
    "    skill_name: str\n",
    "    steps: List[str]\n",
    "    prerequisites: List[str] = Field(default_factory=list)\n",
    "    success_rate: float = Field(default=1.0, ge=0.0, le=1.0)\n",
    "\n",
    "# Agent State with Memory\n",
    "class MemoryAgentState(TypedDict):\n",
    "    messages: List[str]\n",
    "    current_task: Optional[str]\n",
    "    user_id: str\n",
    "    session_id: str\n",
    "    active_memories: List[MemoryEntry]\n",
    "    memory_context: str\n",
    "    last_retrieval: Optional[datetime]\n",
    "\n",
    "print(\"âœ… Memory system data models defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—„ï¸ Section 2: Vector Storage with OpenAI Embeddings\n",
    "\n",
    "Now let's implement vector storage using ChromaDB and OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorMemoryStore:\n",
    "    \"\"\"Vector-based memory storage using ChromaDB and OpenAI embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, persist_directory: str = \"./memory_db\"):\n",
    "        self.client = chromadb.PersistentClient(\n",
    "            path=persist_directory,\n",
    "            settings=Settings(allow_reset=True)\n",
    "        )\n",
    "        self.openai_client = OpenAI()\n",
    "        \n",
    "        # Create collections for different memory types\n",
    "        self.semantic_collection = self._get_or_create_collection(\"semantic_memory\")\n",
    "        self.episodic_collection = self._get_or_create_collection(\"episodic_memory\")\n",
    "        self.procedural_collection = self._get_or_create_collection(\"procedural_memory\")\n",
    "        \n",
    "    def _get_or_create_collection(self, name: str):\n",
    "        \"\"\"Get or create a ChromaDB collection\"\"\"\n",
    "        try:\n",
    "            return self.client.get_collection(name)\n",
    "        except:\n",
    "            return self.client.create_collection(name)\n",
    "    \n",
    "    async def get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Get OpenAI embedding for text\"\"\"\n",
    "        try:\n",
    "            response = self.openai_client.embeddings.create(\n",
    "                input=text,\n",
    "                model=\"text-embedding-3-small\"  # Cost-effective option\n",
    "            )\n",
    "            return response.data[0].embedding\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error getting embedding: {e}\")\n",
    "            return []\n",
    "    \n",
    "    async def store_memory(self, memory: MemoryEntry) -> bool:\n",
    "        \"\"\"Store a memory entry with embedding\"\"\"\n",
    "        try:\n",
    "            # Get embedding for the content\n",
    "            embedding = await self.get_embedding(memory.content)\n",
    "            if not embedding:\n",
    "                return False\n",
    "            \n",
    "            # Select appropriate collection\n",
    "            collection = self._get_collection_for_type(memory.memory_type)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = {\n",
    "                \"namespace\": memory.namespace,\n",
    "                \"timestamp\": memory.timestamp.isoformat(),\n",
    "                \"importance_score\": memory.importance_score,\n",
    "                **memory.metadata\n",
    "            }\n",
    "            \n",
    "            # Store in vector database\n",
    "            collection.add(\n",
    "                ids=[memory.id],\n",
    "                embeddings=[embedding],\n",
    "                documents=[memory.content],\n",
    "                metadatas=[metadata]\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… Stored {memory.memory_type} memory: {memory.id}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error storing memory: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _get_collection_for_type(self, memory_type: str):\n",
    "        \"\"\"Get the appropriate collection for memory type\"\"\"\n",
    "        if memory_type == MemoryType.SEMANTIC:\n",
    "            return self.semantic_collection\n",
    "        elif memory_type == MemoryType.EPISODIC:\n",
    "            return self.episodic_collection\n",
    "        elif memory_type == MemoryType.PROCEDURAL:\n",
    "            return self.procedural_collection\n",
    "        else:\n",
    "            return self.semantic_collection  # Default\n",
    "    \n",
    "    async def search_memories(\n",
    "        self, \n",
    "        query: str, \n",
    "        memory_type: Optional[str] = None,\n",
    "        namespace: Optional[str] = None,\n",
    "        limit: int = 5,\n",
    "        min_similarity: float = 0.7\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for relevant memories\"\"\"\n",
    "        try:\n",
    "            # Get query embedding\n",
    "            query_embedding = await self.get_embedding(query)\n",
    "            if not query_embedding:\n",
    "                return []\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            # Search in specified memory type or all types\n",
    "            collections_to_search = []\n",
    "            if memory_type:\n",
    "                collections_to_search.append((self._get_collection_for_type(memory_type), memory_type))\n",
    "            else:\n",
    "                collections_to_search = [\n",
    "                    (self.semantic_collection, MemoryType.SEMANTIC),\n",
    "                    (self.episodic_collection, MemoryType.EPISODIC),\n",
    "                    (self.procedural_collection, MemoryType.PROCEDURAL)\n",
    "                ]\n",
    "            \n",
    "            for collection, mem_type in collections_to_search:\n",
    "                # Build where clause for namespace filtering\n",
    "                where_clause = {}\n",
    "                if namespace:\n",
    "                    where_clause[\"namespace\"] = namespace\n",
    "                \n",
    "                # Search the collection\n",
    "                search_results = collection.query(\n",
    "                    query_embeddings=[query_embedding],\n",
    "                    n_results=limit,\n",
    "                    where=where_clause if where_clause else None\n",
    "                )\n",
    "                \n",
    "                # Process results\n",
    "                if search_results['documents'] and search_results['documents'][0]:\n",
    "                    for i, doc in enumerate(search_results['documents'][0]):\n",
    "                        distance = search_results['distances'][0][i]\n",
    "                        similarity = 1 - distance  # Convert distance to similarity\n",
    "                        \n",
    "                        if similarity >= min_similarity:\n",
    "                            results.append({\n",
    "                                'content': doc,\n",
    "                                'memory_type': mem_type,\n",
    "                                'similarity': similarity,\n",
    "                                'metadata': search_results['metadatas'][0][i],\n",
    "                                'id': search_results['ids'][0][i]\n",
    "                            })\n",
    "            \n",
    "            # Sort by similarity and return top results\n",
    "            results.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "            return results[:limit]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error searching memories: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_memory_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"Get statistics about stored memories\"\"\"\n",
    "        try:\n",
    "            return {\n",
    "                \"semantic\": self.semantic_collection.count(),\n",
    "                \"episodic\": self.episodic_collection.count(),\n",
    "                \"procedural\": self.procedural_collection.count()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error getting stats: {e}\")\n",
    "            return {\"semantic\": 0, \"episodic\": 0, \"procedural\": 0}\n",
    "\n",
    "# Initialize the vector memory store\n",
    "memory_store = VectorMemoryStore()\n",
    "print(\"âœ… Vector memory store initialized!\")\n",
    "print(f\"ðŸ“Š Current memory stats: {memory_store.get_memory_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§° Section 3: Memory Management Tools\n",
    "\n",
    "Let's create tools for managing different types of memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryTools:\n",
    "    \"\"\"Tools for memory management and operations\"\"\"\n",
    "    \n",
    "    def __init__(self, memory_store: VectorMemoryStore):\n",
    "        self.memory_store = memory_store\n",
    "    \n",
    "    async def store_fact(self, content: str, topic: str, namespace: str = \"general\", \n",
    "                        confidence: float = 1.0, source: str = None) -> bool:\n",
    "        \"\"\"Store a semantic memory (fact)\"\"\"\n",
    "        memory = SemanticMemory(\n",
    "            content=content,\n",
    "            topic=topic,\n",
    "            namespace=namespace,\n",
    "            confidence=confidence,\n",
    "            source=source,\n",
    "            importance_score=confidence\n",
    "        )\n",
    "        return await self.memory_store.store_memory(memory)\n",
    "    \n",
    "    async def store_experience(self, content: str, event_type: str, \n",
    "                              participants: List[str] = None, \n",
    "                              namespace: str = \"general\",\n",
    "                              context: Dict[str, Any] = None) -> bool:\n",
    "        \"\"\"Store an episodic memory (experience)\"\"\"\n",
    "        memory = EpisodicMemory(\n",
    "            content=content,\n",
    "            event_type=event_type,\n",
    "            participants=participants or [],\n",
    "            namespace=namespace,\n",
    "            context=context or {}\n",
    "        )\n",
    "        return await self.memory_store.store_memory(memory)\n",
    "    \n",
    "    async def store_procedure(self, content: str, skill_name: str, \n",
    "                             steps: List[str], namespace: str = \"general\",\n",
    "                             prerequisites: List[str] = None,\n",
    "                             success_rate: float = 1.0) -> bool:\n",
    "        \"\"\"Store a procedural memory (skill/procedure)\"\"\"\n",
    "        memory = ProceduralMemory(\n",
    "            content=content,\n",
    "            skill_name=skill_name,\n",
    "            steps=steps,\n",
    "            namespace=namespace,\n",
    "            prerequisites=prerequisites or [],\n",
    "            success_rate=success_rate\n",
    "        )\n",
    "        return await self.memory_store.store_memory(memory)\n",
    "    \n",
    "    async def recall_knowledge(self, query: str, namespace: str = None) -> List[Dict]:\n",
    "        \"\"\"Recall semantic knowledge related to query\"\"\"\n",
    "        return await self.memory_store.search_memories(\n",
    "            query=query,\n",
    "            memory_type=MemoryType.SEMANTIC,\n",
    "            namespace=namespace,\n",
    "            limit=3\n",
    "        )\n",
    "    \n",
    "    async def recall_experiences(self, query: str, namespace: str = None) -> List[Dict]:\n",
    "        \"\"\"Recall episodic experiences related to query\"\"\"\n",
    "        return await self.memory_store.search_memories(\n",
    "            query=query,\n",
    "            memory_type=MemoryType.EPISODIC,\n",
    "            namespace=namespace,\n",
    "            limit=3\n",
    "        )\n",
    "    \n",
    "    async def recall_procedures(self, query: str, namespace: str = None) -> List[Dict]:\n",
    "        \"\"\"Recall procedural knowledge related to query\"\"\"\n",
    "        return await self.memory_store.search_memories(\n",
    "            query=query,\n",
    "            memory_type=MemoryType.PROCEDURAL,\n",
    "            namespace=namespace,\n",
    "            limit=3\n",
    "        )\n",
    "    \n",
    "    async def comprehensive_recall(self, query: str, namespace: str = None) -> Dict[str, List]:\n",
    "        \"\"\"Comprehensive memory recall across all types\"\"\"\n",
    "        knowledge = await self.recall_knowledge(query, namespace)\n",
    "        experiences = await self.recall_experiences(query, namespace)\n",
    "        procedures = await self.recall_procedures(query, namespace)\n",
    "        \n",
    "        return {\n",
    "            \"knowledge\": knowledge,\n",
    "            \"experiences\": experiences,\n",
    "            \"procedures\": procedures\n",
    "        }\n",
    "    \n",
    "    def format_memory_context(self, memories: Dict[str, List]) -> str:\n",
    "        \"\"\"Format memory recall results for agent context\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        if memories[\"knowledge\"]:\n",
    "            context_parts.append(\"**Relevant Knowledge:**\")\n",
    "            for mem in memories[\"knowledge\"]:\n",
    "                context_parts.append(f\"- {mem['content']} (confidence: {mem['similarity']:.2f})\")\n",
    "        \n",
    "        if memories[\"experiences\"]:\n",
    "            context_parts.append(\"\\n**Past Experiences:**\")\n",
    "            for mem in memories[\"experiences\"]:\n",
    "                context_parts.append(f\"- {mem['content']} (relevance: {mem['similarity']:.2f})\")\n",
    "        \n",
    "        if memories[\"procedures\"]:\n",
    "            context_parts.append(\"\\n**Relevant Procedures:**\")\n",
    "            for mem in memories[\"procedures\"]:\n",
    "                context_parts.append(f\"- {mem['content']} (relevance: {mem['similarity']:.2f})\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts) if context_parts else \"No relevant memories found.\"\n",
    "\n",
    "# Initialize memory tools\n",
    "memory_tools = MemoryTools(memory_store)\n",
    "print(\"âœ… Memory management tools initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– Section 4: Memory-Enhanced Agent Implementation\n",
    "\n",
    "Now let's create an agent that uses our memory system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryAgent:\n",
    "    \"\"\"LangGraph agent with comprehensive memory capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, memory_tools: MemoryTools, model: str = \"gpt-4o-mini\"):\n",
    "        self.memory_tools = memory_tools\n",
    "        self.model = model\n",
    "        self.client = OpenAI()\n",
    "        \n",
    "        # Create the graph\n",
    "        self.graph = self._create_graph()\n",
    "    \n",
    "    def _create_graph(self) -> StateGraph:\n",
    "        \"\"\"Create the memory agent graph\"\"\"\n",
    "        graph = StateGraph(MemoryAgentState)\n",
    "        \n",
    "        # Add nodes\n",
    "        graph.add_node(\"memory_retrieval\", self._memory_retrieval_node)\n",
    "        graph.add_node(\"agent_response\", self._agent_response_node)\n",
    "        graph.add_node(\"memory_storage\", self._memory_storage_node)\n",
    "        \n",
    "        # Add edges\n",
    "        graph.set_entry_point(\"memory_retrieval\")\n",
    "        graph.add_edge(\"memory_retrieval\", \"agent_response\")\n",
    "        graph.add_edge(\"agent_response\", \"memory_storage\")\n",
    "        graph.add_edge(\"memory_storage\", END)\n",
    "        \n",
    "        return graph.compile()\n",
    "    \n",
    "    async def _memory_retrieval_node(self, state: MemoryAgentState) -> MemoryAgentState:\n",
    "        \"\"\"Retrieve relevant memories for the current task\"\"\"\n",
    "        try:\n",
    "            if not state[\"messages\"]:\n",
    "                return state\n",
    "            \n",
    "            # Get the latest message as query\n",
    "            query = state[\"messages\"][-1]\n",
    "            namespace = f\"user:{state['user_id']}\"\n",
    "            \n",
    "            # Comprehensive memory recall\n",
    "            memories = await self.memory_tools.comprehensive_recall(query, namespace)\n",
    "            \n",
    "            # Format memory context\n",
    "            memory_context = self.memory_tools.format_memory_context(memories)\n",
    "            \n",
    "            # Update state\n",
    "            state[\"memory_context\"] = memory_context\n",
    "            state[\"last_retrieval\"] = datetime.now()\n",
    "            \n",
    "            print(f\"ðŸ§  Retrieved memories for query: '{query[:50]}...'\")\n",
    "            print(f\"ðŸ“ Memory context length: {len(memory_context)} characters\")\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in memory retrieval: {e}\")\n",
    "            state[\"memory_context\"] = \"No memories retrieved due to error.\"\n",
    "            return state\n",
    "    \n",
    "    async def _agent_response_node(self, state: MemoryAgentState) -> MemoryAgentState:\n",
    "        \"\"\"Generate agent response using retrieved memories\"\"\"\n",
    "        try:\n",
    "            # Prepare system prompt with memory context\n",
    "            system_prompt = f\"\"\"\n",
    "You are an intelligent assistant with access to persistent memory. Use the following memory context to inform your responses:\n",
    "\n",
    "{state['memory_context']}\n",
    "\n",
    "Instructions:\n",
    "1. Reference relevant memories when answering\n",
    "2. Be specific about what you remember\n",
    "3. Ask clarifying questions if memory context is insufficient\n",
    "4. Acknowledge when you're learning something new\n",
    "5. Be helpful and conversational\n",
    "\n",
    "Current user: {state['user_id']}\n",
    "Session: {state['session_id']}\n",
    "\"\"\"\n",
    "            \n",
    "            # Prepare conversation history\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": state[\"messages\"][-1]}\n",
    "            ]\n",
    "            \n",
    "            # Get response from OpenAI\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            \n",
    "            assistant_response = response.choices[0].message.content\n",
    "            \n",
    "            # Add response to messages\n",
    "            state[\"messages\"].append(assistant_response)\n",
    "            \n",
    "            print(f\"ðŸ¤– Generated response: '{assistant_response[:100]}...'\")\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in agent response: {e}\")\n",
    "            error_response = \"I apologize, but I encountered an error while processing your request.\"\n",
    "            state[\"messages\"].append(error_response)\n",
    "            return state\n",
    "    \n",
    "    async def _memory_storage_node(self, state: MemoryAgentState) -> MemoryAgentState:\n",
    "        \"\"\"Store new information in memory\"\"\"\n",
    "        try:\n",
    "            if len(state[\"messages\"]) < 2:\n",
    "                return state\n",
    "            \n",
    "            user_message = state[\"messages\"][-2]\n",
    "            assistant_response = state[\"messages\"][-1]\n",
    "            namespace = f\"user:{state['user_id']}\"\n",
    "            \n",
    "            # Store the interaction as episodic memory\n",
    "            interaction_content = f\"User: {user_message}\\nAssistant: {assistant_response}\"\n",
    "            await self.memory_tools.store_experience(\n",
    "                content=interaction_content,\n",
    "                event_type=\"conversation\",\n",
    "                participants=[state[\"user_id\"], \"assistant\"],\n",
    "                namespace=namespace,\n",
    "                context={\n",
    "                    \"session_id\": state[\"session_id\"],\n",
    "                    \"task\": state.get(\"current_task\", \"general_conversation\")\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Extract and store any facts mentioned by the user\n",
    "            await self._extract_and_store_facts(user_message, namespace)\n",
    "            \n",
    "            print(f\"ðŸ’¾ Stored interaction in episodic memory\")\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in memory storage: {e}\")\n",
    "            return state\n",
    "    \n",
    "    async def _extract_and_store_facts(self, user_message: str, namespace: str):\n",
    "        \"\"\"Extract and store factual information from user message\"\"\"\n",
    "        try:\n",
    "            # Use OpenAI to extract facts\n",
    "            extraction_prompt = f\"\"\"\n",
    "Extract any factual statements or personal information from this message that should be remembered:\n",
    "\n",
    "Message: \"{user_message}\"\n",
    "\n",
    "Return ONLY facts that are:\n",
    "1. Factual statements (not opinions)\n",
    "2. Personal information about the user\n",
    "3. Preferences or settings\n",
    "4. Important details to remember\n",
    "\n",
    "Format as a simple list, one fact per line. If no facts, return \"None\".\n",
    "\"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # Use cheaper model for extraction\n",
    "                messages=[{\"role\": \"user\", \"content\": extraction_prompt}],\n",
    "                temperature=0.1,\n",
    "                max_tokens=300\n",
    "            )\n",
    "            \n",
    "            facts_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            if facts_text and facts_text.lower() != \"none\":\n",
    "                facts = [f.strip() for f in facts_text.split('\\n') if f.strip()]\n",
    "                \n",
    "                for fact in facts:\n",
    "                    await self.memory_tools.store_fact(\n",
    "                        content=fact,\n",
    "                        topic=\"user_info\",\n",
    "                        namespace=namespace,\n",
    "                        confidence=0.9,\n",
    "                        source=\"user_conversation\"\n",
    "                    )\n",
    "                \n",
    "                print(f\"ðŸ“š Extracted and stored {len(facts)} facts\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error extracting facts: {e}\")\n",
    "    \n",
    "    async def chat(self, message: str, user_id: str, session_id: str = None) -> str:\n",
    "        \"\"\"Chat with the memory-enhanced agent\"\"\"\n",
    "        if not session_id:\n",
    "            session_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = MemoryAgentState(\n",
    "            messages=[message],\n",
    "            current_task=None,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            active_memories=[],\n",
    "            memory_context=\"\",\n",
    "            last_retrieval=None\n",
    "        )\n",
    "        \n",
    "        # Run the graph\n",
    "        final_state = await self.graph.ainvoke(initial_state)\n",
    "        \n",
    "        # Return the assistant's response\n",
    "        return final_state[\"messages\"][-1]\n",
    "\n",
    "# Initialize the memory agent\n",
    "memory_agent = MemoryAgent(memory_tools)\n",
    "print(\"âœ… Memory-enhanced agent initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Section 5: Testing the Memory System\n",
    "\n",
    "Let's test our memory system with some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the memory system\n",
    "async def test_memory_system():\n",
    "    \"\"\"Test the memory system functionality\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª Testing Memory System...\\n\")\n",
    "    \n",
    "    # Test 1: Store some initial facts\n",
    "    print(\"ðŸ“š Storing initial knowledge...\")\n",
    "    await memory_tools.store_fact(\n",
    "        content=\"Python is a high-level programming language known for its readability\",\n",
    "        topic=\"programming\",\n",
    "        namespace=\"general\",\n",
    "        confidence=1.0\n",
    "    )\n",
    "    \n",
    "    await memory_tools.store_fact(\n",
    "        content=\"LangGraph is a library for building stateful multi-agent applications\",\n",
    "        topic=\"programming\",\n",
    "        namespace=\"general\",\n",
    "        confidence=0.95\n",
    "    )\n",
    "    \n",
    "    await memory_tools.store_procedure(\n",
    "        content=\"To deploy a Python application: 1) Test locally, 2) Build container, 3) Deploy to production\",\n",
    "        skill_name=\"python_deployment\",\n",
    "        steps=[\"Test locally\", \"Build container\", \"Deploy to production\"],\n",
    "        namespace=\"general\"\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Initial knowledge stored!\\n\")\n",
    "    \n",
    "    # Test 2: Chat with the agent\n",
    "    print(\"ðŸ’¬ Testing agent conversation...\")\n",
    "    \n",
    "    # First conversation\n",
    "    response1 = await memory_agent.chat(\n",
    "        message=\"Hi! My name is Alice and I'm learning Python programming.\",\n",
    "        user_id=\"alice_123\"\n",
    "    )\n",
    "    print(f\"ðŸ¤– Agent: {response1}\\n\")\n",
    "    \n",
    "    # Second conversation - should remember Alice\n",
    "    response2 = await memory_agent.chat(\n",
    "        message=\"Can you tell me about LangGraph?\",\n",
    "        user_id=\"alice_123\"\n",
    "    )\n",
    "    print(f\"ðŸ¤– Agent: {response2}\\n\")\n",
    "    \n",
    "    # Third conversation - should remember context\n",
    "    response3 = await memory_agent.chat(\n",
    "        message=\"How do I deploy Python applications?\",\n",
    "        user_id=\"alice_123\"\n",
    "    )\n",
    "    print(f\"ðŸ¤– Agent: {response3}\\n\")\n",
    "    \n",
    "    # Test with different user\n",
    "    response4 = await memory_agent.chat(\n",
    "        message=\"What do you know about me?\",\n",
    "        user_id=\"bob_456\"\n",
    "    )\n",
    "    print(f\"ðŸ¤– Agent (Bob): {response4}\\n\")\n",
    "    \n",
    "    # Alice again - should remember previous conversations\n",
    "    response5 = await memory_agent.chat(\n",
    "        message=\"What did we discuss earlier?\",\n",
    "        user_id=\"alice_123\"\n",
    "    )\n",
    "    print(f\"ðŸ¤– Agent (Alice): {response5}\\n\")\n",
    "    \n",
    "    # Display memory statistics\n",
    "    stats = memory_store.get_memory_stats()\n",
    "    print(f\"ðŸ“Š Final Memory Statistics: {stats}\")\n",
    "\n",
    "# Run the test\n",
    "await test_memory_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Section 6: Memory Query and Analysis Tools\n",
    "\n",
    "Let's add some tools for analyzing and querying our memory system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryAnalyzer:\n",
    "    \"\"\"Tools for analyzing and querying memory contents\"\"\"\n",
    "    \n",
    "    def __init__(self, memory_store: VectorMemoryStore):\n",
    "        self.memory_store = memory_store\n",
    "    \n",
    "    async def search_user_memories(self, user_id: str, query: str = \"\") -> Dict[str, List]:\n",
    "        \"\"\"Search all memories for a specific user\"\"\"\n",
    "        namespace = f\"user:{user_id}\"\n",
    "        \n",
    "        if query:\n",
    "            # Search with specific query\n",
    "            results = await self.memory_store.search_memories(\n",
    "                query=query,\n",
    "                namespace=namespace,\n",
    "                limit=10,\n",
    "                min_similarity=0.5\n",
    "            )\n",
    "        else:\n",
    "            # Get all memories for user (using a very general query)\n",
    "            results = await self.memory_store.search_memories(\n",
    "                query=\"conversation interaction user\",\n",
    "                namespace=namespace,\n",
    "                limit=20,\n",
    "                min_similarity=0.0\n",
    "            )\n",
    "        \n",
    "        # Organize by memory type\n",
    "        organized = {\"semantic\": [], \"episodic\": [], \"procedural\": []}\n",
    "        for result in results:\n",
    "            memory_type = result.get(\"memory_type\", \"semantic\")\n",
    "            if memory_type in organized:\n",
    "                organized[memory_type].append(result)\n",
    "        \n",
    "        return organized\n",
    "    \n",
    "    def display_user_memory_summary(self, memories: Dict[str, List], user_id: str):\n",
    "        \"\"\"Display a formatted summary of user memories\"\"\"\n",
    "        print(f\"\\nðŸ‘¤ Memory Summary for User: {user_id}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        total_memories = sum(len(memories[key]) for key in memories)\n",
    "        print(f\"ðŸ“Š Total Memories: {total_memories}\")\n",
    "        \n",
    "        for memory_type, items in memories.items():\n",
    "            if items:\n",
    "                print(f\"\\nðŸ§  {memory_type.upper()} MEMORIES ({len(items)}):\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "                for i, item in enumerate(items[:5], 1):  # Show top 5\n",
    "                    content = item['content'][:100] + \"...\" if len(item['content']) > 100 else item['content']\n",
    "                    timestamp = item.get('metadata', {}).get('timestamp', 'Unknown')\n",
    "                    similarity = item.get('similarity', 0)\n",
    "                    \n",
    "                    print(f\"{i}. {content}\")\n",
    "                    print(f\"   ðŸ“… {timestamp} | ðŸ”— Relevance: {similarity:.2f}\\n\")\n",
    "                \n",
    "                if len(items) > 5:\n",
    "                    print(f\"   ... and {len(items) - 5} more memories\\n\")\n",
    "    \n",
    "    async def analyze_user_interests(self, user_id: str) -> List[str]:\n",
    "        \"\"\"Analyze user interests based on their memory patterns\"\"\"\n",
    "        memories = await self.search_user_memories(user_id)\n",
    "        \n",
    "        # Extract topics and keywords\n",
    "        all_content = []\n",
    "        for memory_type in memories.values():\n",
    "            for memory in memory_type:\n",
    "                all_content.append(memory['content'])\n",
    "        \n",
    "        if not all_content:\n",
    "            return []\n",
    "        \n",
    "        # Use OpenAI to analyze interests\n",
    "        combined_content = \"\\n\".join(all_content[:10])  # Limit content\n",
    "        \n",
    "        analysis_prompt = f\"\"\"\n",
    "Analyze the following conversation history and memory content to identify the user's main interests and topics of discussion:\n",
    "\n",
    "{combined_content}\n",
    "\n",
    "Return a list of 3-5 main interests or topics, one per line. Be specific and concise.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            client = OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n",
    "                temperature=0.3,\n",
    "                max_tokens=200\n",
    "            )\n",
    "            \n",
    "            interests = [line.strip() for line in response.choices[0].message.content.strip().split('\\n') if line.strip()]\n",
    "            return interests\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error analyzing interests: {e}\")\n",
    "            return []\n",
    "    \n",
    "    async def memory_search_demo(self, query: str):\n",
    "        \"\"\"Demonstrate memory search capabilities\"\"\"\n",
    "        print(f\"\\nðŸ” Searching memories for: '{query}'\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        results = await self.memory_store.search_memories(\n",
    "            query=query,\n",
    "            limit=5,\n",
    "            min_similarity=0.3\n",
    "        )\n",
    "        \n",
    "        if results:\n",
    "            for i, result in enumerate(results, 1):\n",
    "                content = result['content'][:150] + \"...\" if len(result['content']) > 150 else result['content']\n",
    "                print(f\"{i}. [{result['memory_type'].upper()}] {content}\")\n",
    "                print(f\"   ðŸ”— Similarity: {result['similarity']:.3f} | ðŸ“… {result.get('metadata', {}).get('timestamp', 'Unknown')}\\n\")\n",
    "        else:\n",
    "            print(\"No relevant memories found.\")\n",
    "\n",
    "# Initialize memory analyzer\n",
    "memory_analyzer = MemoryAnalyzer(memory_store)\n",
    "print(\"âœ… Memory analyzer initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate memory analysis capabilities\n",
    "async def demo_memory_analysis():\n",
    "    \"\"\"Demonstrate memory analysis tools\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”¬ Memory Analysis Demo\\n\")\n",
    "    \n",
    "    # Analyze Alice's memories\n",
    "    alice_memories = await memory_analyzer.search_user_memories(\"alice_123\")\n",
    "    memory_analyzer.display_user_memory_summary(alice_memories, \"alice_123\")\n",
    "    \n",
    "    # Analyze Alice's interests\n",
    "    interests = await memory_analyzer.analyze_user_interests(\"alice_123\")\n",
    "    print(f\"\\nðŸŽ¯ Alice's Interests: {interests}\")\n",
    "    \n",
    "    # Demonstrate search capabilities\n",
    "    await memory_analyzer.memory_search_demo(\"Python programming\")\n",
    "    await memory_analyzer.memory_search_demo(\"deployment\")\n",
    "\n",
    "# Run the demo\n",
    "await demo_memory_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸŽ¯ Part 3: Practical Exercises (30 minutes)\n",
    "\n",
    "## Exercise 1: Personal Assistant with Memory\n",
    "\n",
    "**Goal**: Build a personal assistant that remembers user preferences and past interactions.\n",
    "\n",
    "**Your Task**: Complete the implementation below to create a sophisticated personal assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Personal Assistant with Memory\n",
    "\n",
    "class PersonalAssistant:\n",
    "    \"\"\"Personal assistant with comprehensive memory\"\"\"\n",
    "    \n",
    "    def __init__(self, memory_agent: MemoryAgent):\n",
    "        self.memory_agent = memory_agent\n",
    "        self.memory_tools = memory_agent.memory_tools\n",
    "    \n",
    "    async def setup_user_profile(self, user_id: str, profile_data: Dict[str, Any]):\n",
    "        \"\"\"Set up initial user profile in memory\"\"\"\n",
    "        namespace = f\"user:{user_id}\"\n",
    "        \n",
    "        # TODO: Store user profile information as semantic memories\n",
    "        # Hint: Use memory_tools.store_fact() for each piece of profile data\n",
    "        \n",
    "        for key, value in profile_data.items():\n",
    "            # YOUR CODE HERE\n",
    "            await self.memory_tools.store_fact(\n",
    "                content=f\"User's {key}: {value}\",\n",
    "                topic=\"user_profile\",\n",
    "                namespace=namespace,\n",
    "                confidence=1.0,\n",
    "                source=\"user_setup\"\n",
    "            )\n",
    "        \n",
    "        print(f\"âœ… User profile set up for {user_id}\")\n",
    "    \n",
    "    async def handle_request(self, request: str, user_id: str) -> str:\n",
    "        \"\"\"Handle user request with memory context\"\"\"\n",
    "        # TODO: Use the memory agent to process the request\n",
    "        # Hint: Use self.memory_agent.chat()\n",
    "        \n",
    "        response = await self.memory_agent.chat(request, user_id)\n",
    "        return response\n",
    "    \n",
    "    async def learn_preference(self, user_id: str, preference: str, category: str):\n",
    "        \"\"\"Learn and store a user preference\"\"\"\n",
    "        namespace = f\"user:{user_id}\"\n",
    "        \n",
    "        # TODO: Store the preference as a semantic memory\n",
    "        # Hint: Include the category in the topic or metadata\n",
    "        \n",
    "        await self.memory_tools.store_fact(\n",
    "            content=f\"User prefers: {preference}\",\n",
    "            topic=f\"preference_{category}\",\n",
    "            namespace=namespace,\n",
    "            confidence=0.9,\n",
    "            source=\"user_interaction\"\n",
    "        )\n",
    "        \n",
    "        print(f\"ðŸ“š Learned preference: {preference} (category: {category})\")\n",
    "\n",
    "# Test the Personal Assistant\n",
    "async def test_personal_assistant():\n",
    "    print(\"ðŸ¤– Testing Personal Assistant...\\n\")\n",
    "    \n",
    "    assistant = PersonalAssistant(memory_agent)\n",
    "    \n",
    "    # Set up user profile\n",
    "    profile = {\n",
    "        \"name\": \"Sarah\",\n",
    "        \"job\": \"Data Scientist\",\n",
    "        \"location\": \"San Francisco\",\n",
    "        \"interests\": \"Machine Learning, Python, Hiking\"\n",
    "    }\n",
    "    \n",
    "    await assistant.setup_user_profile(\"sarah_789\", profile)\n",
    "    \n",
    "    # Test conversations\n",
    "    requests = [\n",
    "        \"What's my name and what do I do for work?\",\n",
    "        \"I prefer coffee over tea\",\n",
    "        \"Recommend some weekend activities\",\n",
    "        \"What do you know about my preferences?\"\n",
    "    ]\n",
    "    \n",
    "    for request in requests:\n",
    "        if \"prefer coffee\" in request:\n",
    "            await assistant.learn_preference(\"sarah_789\", \"coffee over tea\", \"beverages\")\n",
    "        \n",
    "        response = await assistant.handle_request(request, \"sarah_789\")\n",
    "        print(f\"ðŸ‘¤ Sarah: {request}\")\n",
    "        print(f\"ðŸ¤– Assistant: {response}\\n\")\n",
    "\n",
    "# Run the test\n",
    "await test_personal_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Knowledge Extraction System\n",
    "\n",
    "**Goal**: Create a system that extracts and organizes knowledge from documents or conversations.\n",
    "\n",
    "**Your Task**: Implement a knowledge extraction and organization system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Knowledge Extraction System\n",
    "\n",
    "class KnowledgeExtractor:\n",
    "    \"\"\"System for extracting and organizing knowledge\"\"\"\n",
    "    \n",
    "    def __init__(self, memory_tools: MemoryTools):\n",
    "        self.memory_tools = memory_tools\n",
    "        self.client = OpenAI()\n",
    "    \n",
    "    async def extract_knowledge_from_text(self, text: str, domain: str = \"general\") -> Dict[str, List[str]]:\n",
    "        \"\"\"Extract different types of knowledge from text\"\"\"\n",
    "        \n",
    "        extraction_prompt = f\"\"\"\n",
    "Analyze the following text and extract knowledge in these categories:\n",
    "\n",
    "Text: \"{text}\"\n",
    "\n",
    "Extract:\n",
    "1. FACTS: Factual statements and information\n",
    "2. PROCEDURES: Step-by-step processes or instructions\n",
    "3. CONCEPTS: Important concepts or definitions\n",
    "\n",
    "Format as:\n",
    "FACTS:\n",
    "- fact 1\n",
    "- fact 2\n",
    "\n",
    "PROCEDURES:\n",
    "- procedure 1\n",
    "- procedure 2\n",
    "\n",
    "CONCEPTS:\n",
    "- concept 1\n",
    "- concept 2\n",
    "\n",
    "If a category has no items, write \"None\".\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # TODO: Use OpenAI to extract knowledge\n",
    "            # Hint: Use self.client.chat.completions.create()\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": extraction_prompt}],\n",
    "                temperature=0.1,\n",
    "                max_tokens=800\n",
    "            )\n",
    "            \n",
    "            # Parse the response\n",
    "            extracted_text = response.choices[0].message.content\n",
    "            knowledge = self._parse_extracted_knowledge(extracted_text)\n",
    "            \n",
    "            # Store the extracted knowledge\n",
    "            await self._store_extracted_knowledge(knowledge, domain)\n",
    "            \n",
    "            return knowledge\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error extracting knowledge: {e}\")\n",
    "            return {\"facts\": [], \"procedures\": [], \"concepts\": []}\n",
    "    \n",
    "    def _parse_extracted_knowledge(self, text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Parse the extracted knowledge text\"\"\"\n",
    "        knowledge = {\"facts\": [], \"procedures\": [], \"concepts\": []}\n",
    "        \n",
    "        # TODO: Parse the text to extract facts, procedures, and concepts\n",
    "        # Hint: Split by sections and extract items\n",
    "        \n",
    "        sections = text.split('\\n\\n')\n",
    "        current_section = None\n",
    "        \n",
    "        for line in text.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('FACTS:'):\n",
    "                current_section = 'facts'\n",
    "            elif line.startswith('PROCEDURES:'):\n",
    "                current_section = 'procedures'\n",
    "            elif line.startswith('CONCEPTS:'):\n",
    "                current_section = 'concepts'\n",
    "            elif line.startswith('- ') and current_section:\n",
    "                item = line[2:].strip()\n",
    "                if item.lower() != 'none':\n",
    "                    knowledge[current_section].append(item)\n",
    "        \n",
    "        return knowledge\n",
    "    \n",
    "    async def _store_extracted_knowledge(self, knowledge: Dict[str, List[str]], domain: str):\n",
    "        \"\"\"Store extracted knowledge in memory\"\"\"\n",
    "        namespace = f\"domain:{domain}\"\n",
    "        \n",
    "        # Store facts as semantic memories\n",
    "        for fact in knowledge[\"facts\"]:\n",
    "            await self.memory_tools.store_fact(\n",
    "                content=fact,\n",
    "                topic=domain,\n",
    "                namespace=namespace,\n",
    "                confidence=0.8,\n",
    "                source=\"knowledge_extraction\"\n",
    "            )\n",
    "        \n",
    "        # Store procedures as procedural memories\n",
    "        for i, procedure in enumerate(knowledge[\"procedures\"]):\n",
    "            # TODO: Store procedures using memory_tools.store_procedure()\n",
    "            # Hint: You might need to break down the procedure into steps\n",
    "            \n",
    "            steps = [step.strip() for step in procedure.split(',') if step.strip()]\n",
    "            if not steps:\n",
    "                steps = [procedure]\n",
    "            \n",
    "            await self.memory_tools.store_procedure(\n",
    "                content=procedure,\n",
    "                skill_name=f\"{domain}_procedure_{i+1}\",\n",
    "                steps=steps,\n",
    "                namespace=namespace\n",
    "            )\n",
    "        \n",
    "        # Store concepts as semantic memories with concept topic\n",
    "        for concept in knowledge[\"concepts\"]:\n",
    "            await self.memory_tools.store_fact(\n",
    "                content=concept,\n",
    "                topic=f\"{domain}_concepts\",\n",
    "                namespace=namespace,\n",
    "                confidence=0.9,\n",
    "                source=\"knowledge_extraction\"\n",
    "            )\n",
    "        \n",
    "        print(f\"ðŸ“š Stored: {len(knowledge['facts'])} facts, {len(knowledge['procedures'])} procedures, {len(knowledge['concepts'])} concepts\")\n",
    "\n",
    "# Test the Knowledge Extraction System\n",
    "async def test_knowledge_extraction():\n",
    "    print(\"ðŸ§  Testing Knowledge Extraction System...\\n\")\n",
    "    \n",
    "    extractor = KnowledgeExtractor(memory_tools)\n",
    "    \n",
    "    # Sample text about machine learning\n",
    "    sample_text = \"\"\"\n",
    "    Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed. \n",
    "    \n",
    "    To train a machine learning model, follow these steps: 1) Collect and clean your data, 2) Choose an appropriate algorithm, 3) Split data into training and testing sets, 4) Train the model on training data, 5) Evaluate performance on test data, 6) Fine-tune hyperparameters if needed.\n",
    "    \n",
    "    Key concepts include supervised learning (learning with labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through rewards and penalties). Neural networks are computational models inspired by biological neural networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract knowledge\n",
    "    knowledge = await extractor.extract_knowledge_from_text(sample_text, \"machine_learning\")\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nðŸ“Š Extracted Knowledge:\")\n",
    "    for category, items in knowledge.items():\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        for item in items:\n",
    "            print(f\"  - {item}\")\n",
    "    \n",
    "    # Test retrieval\n",
    "    print(\"\\nðŸ” Testing knowledge retrieval...\")\n",
    "    ml_knowledge = await memory_tools.recall_knowledge(\"machine learning training\", \"domain:machine_learning\")\n",
    "    for knowledge in ml_knowledge:\n",
    "        print(f\"  ðŸ“ {knowledge['content'][:100]}...\")\n",
    "\n",
    "# Run the test\n",
    "await test_knowledge_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ† Challenge Exercise: Multi-Domain Memory Agent\n",
    "\n",
    "**Goal**: Create an advanced agent that can manage memories across multiple domains and provide domain-specific expertise.\n",
    "\n",
    "**Your Task**: Implement a sophisticated multi-domain memory system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge Exercise: Multi-Domain Memory Agent\n",
    "\n",
    "class MultiDomainMemoryAgent:\n",
    "    \"\"\"Advanced agent with multi-domain memory management\"\"\"\n",
    "    \n",
    "    def __init__(self, memory_tools: MemoryTools):\n",
    "        self.memory_tools = memory_tools\n",
    "        self.client = OpenAI()\n",
    "        self.domains = [\"technology\", \"business\", \"science\", \"arts\", \"sports\"]\n",
    "    \n",
    "    async def classify_domain(self, query: str) -> str:\n",
    "        \"\"\"Classify the domain of a query\"\"\"\n",
    "        # TODO: Use OpenAI to classify the domain of the query\n",
    "        # Hint: Create a prompt that asks GPT to classify the query into one of the domains\n",
    "        \n",
    "        classification_prompt = f\"\"\"\n",
    "Classify the following query into one of these domains: {', '.join(self.domains)}\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Return only the domain name, nothing else.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n",
    "                temperature=0.1,\n",
    "                max_tokens=20\n",
    "            )\n",
    "            \n",
    "            domain = response.choices[0].message.content.strip().lower()\n",
    "            return domain if domain in self.domains else \"technology\"  # Default\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error classifying domain: {e}\")\n",
    "            return \"technology\"  # Default domain\n",
    "    \n",
    "    async def provide_domain_expertise(self, query: str, user_id: str) -> str:\n",
    "        \"\"\"Provide domain-specific expertise\"\"\"\n",
    "        # TODO: Implement domain-specific expertise\n",
    "        # 1. Classify the domain\n",
    "        # 2. Retrieve domain-specific memories\n",
    "        # 3. Retrieve user-specific memories\n",
    "        # 4. Generate a response using both contexts\n",
    "        \n",
    "        # Step 1: Classify domain\n",
    "        domain = await self.classify_domain(query)\n",
    "        print(f\"ðŸŽ¯ Classified domain: {domain}\")\n",
    "        \n",
    "        # Step 2: Retrieve domain-specific knowledge\n",
    "        domain_namespace = f\"domain:{domain}\"\n",
    "        domain_memories = await self.memory_tools.comprehensive_recall(query, domain_namespace)\n",
    "        \n",
    "        # Step 3: Retrieve user-specific memories\n",
    "        user_namespace = f\"user:{user_id}\"\n",
    "        user_memories = await self.memory_tools.comprehensive_recall(query, user_namespace)\n",
    "        \n",
    "        # Step 4: Generate response\n",
    "        domain_context = self.memory_tools.format_memory_context(domain_memories)\n",
    "        user_context = self.memory_tools.format_memory_context(user_memories)\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "You are a domain expert in {domain}. Use the following contexts to provide a comprehensive answer:\n",
    "\n",
    "DOMAIN EXPERTISE ({domain}):\n",
    "{domain_context}\n",
    "\n",
    "USER CONTEXT:\n",
    "{user_context}\n",
    "\n",
    "Provide a detailed, expert-level response that:\n",
    "1. Leverages domain-specific knowledge\n",
    "2. Considers the user's background and interests\n",
    "3. Provides actionable insights\n",
    "4. Asks relevant follow-up questions if appropriate\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": query}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error generating response: {e}\")\n",
    "            return \"I apologize, but I encountered an error while processing your request.\"\n",
    "    \n",
    "    async def add_domain_knowledge(self, domain: str, content: str, knowledge_type: str = \"fact\"):\n",
    "        \"\"\"Add knowledge to a specific domain\"\"\"\n",
    "        namespace = f\"domain:{domain}\"\n",
    "        \n",
    "        if knowledge_type == \"fact\":\n",
    "            await self.memory_tools.store_fact(\n",
    "                content=content,\n",
    "                topic=domain,\n",
    "                namespace=namespace,\n",
    "                confidence=0.9,\n",
    "                source=\"domain_knowledge\"\n",
    "            )\n",
    "        elif knowledge_type == \"procedure\":\n",
    "            # Parse procedure into steps\n",
    "            steps = [step.strip() for step in content.split('.') if step.strip()]\n",
    "            await self.memory_tools.store_procedure(\n",
    "                content=content,\n",
    "                skill_name=f\"{domain}_procedure\",\n",
    "                steps=steps,\n",
    "                namespace=namespace\n",
    "            )\n",
    "        \n",
    "        print(f\"ðŸ“š Added {knowledge_type} to {domain} domain\")\n",
    "\n",
    "# Test the Multi-Domain Memory Agent\n",
    "async def test_multi_domain_agent():\n",
    "    print(\"ðŸŒ Testing Multi-Domain Memory Agent...\\n\")\n",
    "    \n",
    "    agent = MultiDomainMemoryAgent(memory_tools)\n",
    "    \n",
    "    # Add some domain-specific knowledge\n",
    "    await agent.add_domain_knowledge(\n",
    "        \"technology\",\n",
    "        \"Cloud computing provides on-demand access to computing resources over the internet\",\n",
    "        \"fact\"\n",
    "    )\n",
    "    \n",
    "    await agent.add_domain_knowledge(\n",
    "        \"business\",\n",
    "        \"A successful startup requires: market research, product development, funding, team building, and customer acquisition\",\n",
    "        \"procedure\"\n",
    "    )\n",
    "    \n",
    "    await agent.add_domain_knowledge(\n",
    "        \"science\",\n",
    "        \"CRISPR-Cas9 is a revolutionary gene-editing technology that allows precise modifications to DNA\",\n",
    "        \"fact\"\n",
    "    )\n",
    "    \n",
    "    # Test domain classification and expertise\n",
    "    test_queries = [\n",
    "        \"How does cloud computing work and what are its benefits?\",\n",
    "        \"What steps should I take to start a tech startup?\",\n",
    "        \"Explain how CRISPR gene editing technology works\",\n",
    "        \"What are the latest trends in artificial intelligence?\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nðŸ‘¤ User: {query}\")\n",
    "        response = await agent.provide_domain_expertise(query, \"expert_user_001\")\n",
    "        print(f\"ðŸ¤– Expert Agent: {response[:200]}...\\n\")\n",
    "\n",
    "# Run the test\n",
    "await test_multi_domain_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸŽ¯ Summary and Next Steps\n",
    "\n",
    "## ðŸ“š What You've Learned Today\n",
    "\n",
    "### âœ… Key Concepts Mastered:\n",
    "1. **Memory Types**: Semantic, episodic, and procedural memory systems\n",
    "2. **Vector Storage**: Integration with OpenAI embeddings for semantic search\n",
    "3. **Memory Management**: Tools for storing, retrieving, and organizing memories\n",
    "4. **Cross-Session Persistence**: Maintaining memory across agent interactions\n",
    "5. **Domain-Specific Knowledge**: Organizing memory by namespaces and domains\n",
    "\n",
    "### ðŸ› ï¸ Technical Skills Developed:\n",
    "- ChromaDB vector storage implementation\n",
    "- OpenAI embeddings integration\n",
    "- Memory-enhanced LangGraph agents\n",
    "- Knowledge extraction and organization\n",
    "- Multi-domain memory management\n",
    "\n",
    "### ðŸ—ï¸ Projects Completed:\n",
    "1. **Vector Memory Store**: Full implementation with ChromaDB and OpenAI\n",
    "2. **Memory-Enhanced Agent**: LangGraph agent with comprehensive memory\n",
    "3. **Personal Assistant**: Agent that remembers user preferences and history\n",
    "4. **Knowledge Extractor**: System for extracting and organizing information\n",
    "5. **Multi-Domain Agent**: Advanced agent with domain-specific expertise\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "### Tomorrow's Focus (Day 4):\n",
    "- **Multi-Agent Communication**: Learn how agents communicate and coordinate\n",
    "- **Handoff Mechanisms**: Implement agent-to-agent task handoffs\n",
    "- **Command Objects**: Structured communication patterns\n",
    "- **Supervisor Patterns**: Orchestrating multiple specialized agents\n",
    "- **Security**: Secure data injection and validation\n",
    "\n",
    "### ðŸ’¡ Homework Suggestions:\n",
    "1. Extend the personal assistant with more sophisticated preference learning\n",
    "2. Implement memory aging and forgetting mechanisms\n",
    "3. Add memory compression for long-term storage efficiency\n",
    "4. Experiment with different embedding models and vector databases\n",
    "5. Build a domain-specific knowledge base for your area of expertise\n",
    "\n",
    "### ðŸ“– Additional Resources:\n",
    "- [Vector Database Comparison Guide](https://example.com/vector-db-guide)\n",
    "- [OpenAI Embeddings Best Practices](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)\n",
    "- [Memory Systems in AI Research](https://example.com/memory-systems-research)\n",
    "- [LangGraph Memory Documentation](https://langchain-ai.github.io/langgraph/concepts/memory/)\n",
    "\n",
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully implemented a comprehensive memory system for AI agents! You now understand how to:\n",
    "- Store and retrieve different types of memories\n",
    "- Use vector databases for semantic search\n",
    "- Build agents that learn and remember across sessions\n",
    "- Extract and organize knowledge from text\n",
    "- Manage domain-specific expertise\n",
    "\n",
    "**Ready for Day 4?** Tomorrow we'll explore how multiple agents can work together, communicate effectively, and hand off tasks to create powerful multi-agent systems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}