{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: Multi-Agent Communication & Handoffs in LangGraph\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "By the end of this session, you will:\n",
    "- Master multi-agent communication patterns in LangGraph\n",
    "- Implement agent handoffs using Command objects\n",
    "- Build supervisor patterns with OpenAI for coordinating multiple agents\n",
    "- Understand network communication and secure data injection\n",
    "- Implement robust message validation between agents\n",
    "- Design scalable multi-agent architectures\n",
    "\n",
    "## ⏱️ Session Structure (2 hours)\n",
    "- **Learning Materials** (30 min): Theory and communication patterns\n",
    "- **Hands-on Code** (60 min): Implementation and examples  \n",
    "- **Practical Exercises** (30 min): Build multi-agent systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📖 Learning Materials (30 minutes)\n",
    "\n",
    "### 📺 Video Resources\n",
    "- [LangGraph Multi-Agent Guide](https://langchain-ai.github.io/langgraph/concepts/multi_agent/) - Official documentation\n",
    "- [DeepLearning.AI - AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/) - Module 4: Multi-Agent Systems\n",
    "- [LangChain Academy - Agent Communication](https://academy.langchain.com/) - Handoff patterns deep dive\n",
    "\n",
    "### 🧠 Theory: Multi-Agent Communication\n",
    "\n",
    "#### What are Multi-Agent Systems?\n",
    "Multi-agent systems in LangGraph involve multiple specialized agents that collaborate to solve complex problems. Each agent has specific responsibilities and can communicate with others through structured handoffs.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Agent Handoffs**: Transferring control from one agent to another\n",
    "- **Command Objects**: Structured way to pass control and data\n",
    "- **Supervisor Patterns**: Central coordinator managing multiple worker agents\n",
    "- **Network Communication**: Agents communicating across different processes/systems\n",
    "- **Message Validation**: Ensuring data integrity and security\n",
    "\n",
    "#### Communication Patterns\n",
    "\n",
    "1. **Sequential Handoffs**: Agent A → Agent B → Agent C\n",
    "2. **Supervisor-Worker**: Central supervisor delegates to specialized workers\n",
    "3. **Peer-to-Peer**: Agents communicate directly with each other\n",
    "4. **Hierarchical**: Multi-level agent structures\n",
    "5. **Event-Driven**: Agents respond to events and messages\n",
    "\n",
    "#### Command Objects\n",
    "Commands are the primary mechanism for agent handoffs:\n",
    "- **goto**: Transfer control to another node\n",
    "- **update**: Modify state and continue\n",
    "- **finish**: Complete the workflow\n",
    "\n",
    "#### Security Considerations\n",
    "- Input validation and sanitization\n",
    "- Authentication between agents\n",
    "- Secure data transmission\n",
    "- Access control and permissions\n",
    "- Audit logging for agent interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 💻 Hands-on Code (60 minutes)\n",
    "\n",
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langgraph langchain langchain-openai pydantic python-dotenv\n",
    "!pip install langgraph-checkpoint-sqlite httpx aiohttp\n",
    "!pip install cryptography  # For secure communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import TypedDict, Literal, List, Optional, Dict, Any, Union\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.constants import INTERRUPT\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    print(\"⚠️ Please set OPENAI_API_KEY in your .env file\")\n",
    "    print(\"Example: OPENAI_API_KEY=sk-...\")\n",
    "else:\n",
    "    print(\"✅ OpenAI API key loaded successfully\")\n",
    "\n",
    "# Initialize models\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=openai_api_key)\n",
    "fast_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Command Objects and Handoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentRole(str, Enum):\n",
    "    \"\"\"Define different agent roles\"\"\"\n",
    "    COORDINATOR = \"coordinator\"\n",
    "    RESEARCHER = \"researcher\"\n",
    "    ANALYST = \"analyst\"\n",
    "    WRITER = \"writer\"\n",
    "    REVIEWER = \"reviewer\"\n",
    "\n",
    "class MessageType(str, Enum):\n",
    "    \"\"\"Types of messages between agents\"\"\"\n",
    "    TASK_REQUEST = \"task_request\"\n",
    "    TASK_RESPONSE = \"task_response\"\n",
    "    HANDOFF = \"handoff\"\n",
    "    ERROR = \"error\"\n",
    "    STATUS_UPDATE = \"status_update\"\n",
    "\n",
    "class AgentMessage(BaseModel):\n",
    "    \"\"\"Structured message between agents\"\"\"\n",
    "    from_agent: AgentRole\n",
    "    to_agent: AgentRole\n",
    "    message_type: MessageType\n",
    "    content: str\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())\n",
    "    message_id: str = Field(default_factory=lambda: f\"msg_{datetime.now().timestamp()}\")\n",
    "\n",
    "class MultiAgentState(BaseModel):\n",
    "    \"\"\"State for multi-agent communication\"\"\"\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    agent_messages: List[AgentMessage] = Field(default_factory=list)\n",
    "    current_agent: AgentRole = AgentRole.COORDINATOR\n",
    "    task_description: str = \"\"\n",
    "    research_data: Dict[str, Any] = Field(default_factory=dict)\n",
    "    analysis_results: Dict[str, Any] = Field(default_factory=dict)\n",
    "    final_output: str = \"\"\n",
    "    workflow_status: str = \"pending\"\n",
    "    error_log: List[str] = Field(default_factory=list)\n",
    "\n",
    "# Basic handoff functions\n",
    "def coordinator_node(state: MultiAgentState) -> Command:\n",
    "    \"\"\"Coordinator agent that manages the workflow\"\"\"\n",
    "    print(f\"🎯 Coordinator: Processing task - {state.task_description}\")\n",
    "    \n",
    "    # Create handoff message\n",
    "    handoff_msg = AgentMessage(\n",
    "        from_agent=AgentRole.COORDINATOR,\n",
    "        to_agent=AgentRole.RESEARCHER,\n",
    "        message_type=MessageType.HANDOFF,\n",
    "        content=f\"Please research: {state.task_description}\",\n",
    "        metadata={\"priority\": \"high\", \"deadline\": \"1 hour\"}\n",
    "    )\n",
    "    \n",
    "    state.agent_messages.append(handoff_msg)\n",
    "    state.current_agent = AgentRole.RESEARCHER\n",
    "    \n",
    "    # Use Command to transfer control\n",
    "    return Command(goto=\"researcher\", update=state.model_dump())\n",
    "\n",
    "def researcher_node(state: MultiAgentState) -> Command:\n",
    "    \"\"\"Research agent that gathers information\"\"\"\n",
    "    print(f\"🔍 Researcher: Gathering information about - {state.task_description}\")\n",
    "    \n",
    "    # Simulate research using LLM\n",
    "    research_prompt = f\"\"\"\n",
    "    You are a research agent. Gather key information about: {state.task_description}\n",
    "    Provide a structured research summary with key points and sources.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = fast_llm.invoke([HumanMessage(content=research_prompt)])\n",
    "    \n",
    "    # Store research data\n",
    "    state.research_data = {\n",
    "        \"summary\": response.content,\n",
    "        \"completed_at\": datetime.now().isoformat(),\n",
    "        \"agent\": AgentRole.RESEARCHER\n",
    "    }\n",
    "    \n",
    "    # Create handoff to analyst\n",
    "    handoff_msg = AgentMessage(\n",
    "        from_agent=AgentRole.RESEARCHER,\n",
    "        to_agent=AgentRole.ANALYST,\n",
    "        message_type=MessageType.HANDOFF,\n",
    "        content=\"Research completed. Please analyze the findings.\",\n",
    "        metadata={\"research_summary\": response.content[:200]}\n",
    "    )\n",
    "    \n",
    "    state.agent_messages.append(handoff_msg)\n",
    "    state.current_agent = AgentRole.ANALYST\n",
    "    \n",
    "    return Command(goto=\"analyst\", update=state.model_dump())\n",
    "\n",
    "def analyst_node(state: MultiAgentState) -> Command:\n",
    "    \"\"\"Analyst agent that processes research data\"\"\"\n",
    "    print(f\"📊 Analyst: Analyzing research data\")\n",
    "    \n",
    "    # Analyze the research data\n",
    "    analysis_prompt = f\"\"\"\n",
    "    You are an analyst agent. Analyze this research data and provide insights:\n",
    "    \n",
    "    Research Summary:\n",
    "    {state.research_data.get('summary', 'No research data available')}\n",
    "    \n",
    "    Provide key insights, trends, and recommendations.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "    \n",
    "    # Store analysis results\n",
    "    state.analysis_results = {\n",
    "        \"insights\": response.content,\n",
    "        \"completed_at\": datetime.now().isoformat(),\n",
    "        \"agent\": AgentRole.ANALYST\n",
    "    }\n",
    "    \n",
    "    # Create handoff to writer\n",
    "    handoff_msg = AgentMessage(\n",
    "        from_agent=AgentRole.ANALYST,\n",
    "        to_agent=AgentRole.WRITER,\n",
    "        message_type=MessageType.HANDOFF,\n",
    "        content=\"Analysis completed. Please create final report.\",\n",
    "        metadata={\"analysis_summary\": response.content[:200]}\n",
    "    )\n",
    "    \n",
    "    state.agent_messages.append(handoff_msg)\n",
    "    state.current_agent = AgentRole.WRITER\n",
    "    \n",
    "    return Command(goto=\"writer\", update=state.model_dump())\n",
    "\n",
    "def writer_node(state: MultiAgentState) -> Command:\n",
    "    \"\"\"Writer agent that creates final output\"\"\"\n",
    "    print(f\"✍️ Writer: Creating final report\")\n",
    "    \n",
    "    # Create final report\n",
    "    writing_prompt = f\"\"\"\n",
    "    You are a writer agent. Create a comprehensive report based on:\n",
    "    \n",
    "    Task: {state.task_description}\n",
    "    \n",
    "    Research Data:\n",
    "    {state.research_data.get('summary', 'No research available')}\n",
    "    \n",
    "    Analysis:\n",
    "    {state.analysis_results.get('insights', 'No analysis available')}\n",
    "    \n",
    "    Create a well-structured, professional report.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=writing_prompt)])\n",
    "    \n",
    "    # Store final output\n",
    "    state.final_output = response.content\n",
    "    state.workflow_status = \"completed\"\n",
    "    \n",
    "    # Final status message\n",
    "    status_msg = AgentMessage(\n",
    "        from_agent=AgentRole.WRITER,\n",
    "        to_agent=AgentRole.COORDINATOR,\n",
    "        message_type=MessageType.STATUS_UPDATE,\n",
    "        content=\"Final report completed successfully.\",\n",
    "        metadata={\"output_length\": len(response.content)}\n",
    "    )\n",
    "    \n",
    "    state.agent_messages.append(status_msg)\n",
    "    \n",
    "    return Command(finish=state.model_dump())\n",
    "\n",
    "print(\"🎭 Multi-agent nodes defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building the Multi-Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_agent_graph():\n",
    "    \"\"\"Create a multi-agent graph with handoffs\"\"\"\n",
    "    \n",
    "    # Create the graph\n",
    "    graph = StateGraph(MultiAgentState)\n",
    "    \n",
    "    # Add agent nodes\n",
    "    graph.add_node(\"coordinator\", coordinator_node)\n",
    "    graph.add_node(\"researcher\", researcher_node)\n",
    "    graph.add_node(\"analyst\", analyst_node)\n",
    "    graph.add_node(\"writer\", writer_node)\n",
    "    \n",
    "    # Add edges (Command objects handle the actual routing)\n",
    "    graph.add_edge(START, \"coordinator\")\n",
    "    \n",
    "    # Compile with persistence\n",
    "    saver = SqliteSaver.from_conn_string(\"multi_agent.db\")\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create and test the multi-agent system\n",
    "multi_agent_app = create_multi_agent_graph()\n",
    "print(\"🏗️ Multi-agent graph created successfully\")\n",
    "\n",
    "# Test with a sample task\n",
    "initial_state = MultiAgentState(\n",
    "    task_description=\"Analyze the impact of AI on software development workflows\",\n",
    "    messages=[HumanMessage(content=\"Please analyze the impact of AI on software development workflows\")]\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"multi-agent-test\"}}\n",
    "\n",
    "print(\"\\n🚀 Running multi-agent workflow...\")\n",
    "result = multi_agent_app.invoke(initial_state, config=config)\n",
    "\n",
    "print(f\"\\n📊 Workflow Status: {result.workflow_status}\")\n",
    "print(f\"💬 Agent Messages: {len(result.agent_messages)}\")\n",
    "print(f\"📝 Final Output Length: {len(result.final_output)} characters\")\n",
    "print(f\"\\n🎯 Final Report Preview: {result.final_output[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Supervisor Pattern with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisorState(BaseModel):\n",
    "    \"\"\"State for supervisor pattern\"\"\"\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    task_queue: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "    worker_status: Dict[str, str] = Field(default_factory=dict)\n",
    "    completed_tasks: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "    current_task: Optional[Dict[str, Any]] = None\n",
    "    supervisor_decisions: List[str] = Field(default_factory=list)\n",
    "\n",
    "# Define specialized worker agents\n",
    "def web_researcher_worker(state: SupervisorState) -> Command:\n",
    "    \"\"\"Specialized worker for web research tasks\"\"\"\n",
    "    print(\"🌐 Web Researcher: Starting web research task\")\n",
    "    \n",
    "    if state.current_task:\n",
    "        task = state.current_task\n",
    "        \n",
    "        # Simulate web research\n",
    "        research_prompt = f\"\"\"\n",
    "        You are a web research specialist. Research the following topic:\n",
    "        {task.get('description', '')}\n",
    "        \n",
    "        Focus on finding recent developments, key statistics, and authoritative sources.\n",
    "        Provide a structured summary with source citations.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = fast_llm.invoke([HumanMessage(content=research_prompt)])\n",
    "        \n",
    "        # Complete the task\n",
    "        completed_task = {\n",
    "            **task,\n",
    "            \"result\": response.content,\n",
    "            \"completed_by\": \"web_researcher\",\n",
    "            \"completed_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        state.completed_tasks.append(completed_task)\n",
    "        state.worker_status[\"web_researcher\"] = \"completed\"\n",
    "        state.current_task = None\n",
    "    \n",
    "    return Command(goto=\"supervisor\", update=state.model_dump())\n",
    "\n",
    "def data_analyst_worker(state: SupervisorState) -> Command:\n",
    "    \"\"\"Specialized worker for data analysis tasks\"\"\"\n",
    "    print(\"📈 Data Analyst: Starting data analysis task\")\n",
    "    \n",
    "    if state.current_task:\n",
    "        task = state.current_task\n",
    "        \n",
    "        # Simulate data analysis\n",
    "        analysis_prompt = f\"\"\"\n",
    "        You are a data analysis specialist. Analyze the following:\n",
    "        {task.get('description', '')}\n",
    "        \n",
    "        Focus on identifying patterns, trends, and statistical insights.\n",
    "        Provide quantitative analysis with supporting evidence.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "        \n",
    "        # Complete the task\n",
    "        completed_task = {\n",
    "            **task,\n",
    "            \"result\": response.content,\n",
    "            \"completed_by\": \"data_analyst\",\n",
    "            \"completed_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        state.completed_tasks.append(completed_task)\n",
    "        state.worker_status[\"data_analyst\"] = \"completed\"\n",
    "        state.current_task = None\n",
    "    \n",
    "    return Command(goto=\"supervisor\", update=state.model_dump())\n",
    "\n",
    "def content_writer_worker(state: SupervisorState) -> Command:\n",
    "    \"\"\"Specialized worker for content writing tasks\"\"\"\n",
    "    print(\"✍️ Content Writer: Starting content creation task\")\n",
    "    \n",
    "    if state.current_task:\n",
    "        task = state.current_task\n",
    "        \n",
    "        # Simulate content writing\n",
    "        writing_prompt = f\"\"\"\n",
    "        You are a professional content writer. Create content for:\n",
    "        {task.get('description', '')}\n",
    "        \n",
    "        Focus on clarity, engagement, and professional tone.\n",
    "        Structure the content with appropriate headings and sections.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=writing_prompt)])\n",
    "        \n",
    "        # Complete the task\n",
    "        completed_task = {\n",
    "            **task,\n",
    "            \"result\": response.content,\n",
    "            \"completed_by\": \"content_writer\",\n",
    "            \"completed_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        state.completed_tasks.append(completed_task)\n",
    "        state.worker_status[\"content_writer\"] = \"completed\"\n",
    "        state.current_task = None\n",
    "    \n",
    "    return Command(goto=\"supervisor\", update=state.model_dump())\n",
    "\n",
    "def supervisor_node(state: SupervisorState) -> Command:\n",
    "    \"\"\"Supervisor that delegates tasks to appropriate workers\"\"\"\n",
    "    print(\"👔 Supervisor: Managing task delegation\")\n",
    "    \n",
    "    # If no current task and tasks in queue, assign next task\n",
    "    if not state.current_task and state.task_queue:\n",
    "        next_task = state.task_queue.pop(0)\n",
    "        state.current_task = next_task\n",
    "        \n",
    "        # Use OpenAI to determine best worker for the task\n",
    "        delegation_prompt = f\"\"\"\n",
    "        You are a supervisor managing specialized workers. Determine which worker is best suited for this task:\n",
    "        \n",
    "        Task: {next_task.get('description', '')}\n",
    "        Task Type: {next_task.get('type', 'general')}\n",
    "        \n",
    "        Available workers:\n",
    "        1. web_researcher - Specializes in web research and information gathering\n",
    "        2. data_analyst - Specializes in data analysis and statistical insights\n",
    "        3. content_writer - Specializes in content creation and writing\n",
    "        \n",
    "        Respond with only the worker name (web_researcher, data_analyst, or content_writer).\n",
    "        \"\"\"\n",
    "        \n",
    "        response = fast_llm.invoke([HumanMessage(content=delegation_prompt)])\n",
    "        selected_worker = response.content.strip().lower()\n",
    "        \n",
    "        # Validate worker selection\n",
    "        valid_workers = [\"web_researcher\", \"data_analyst\", \"content_writer\"]\n",
    "        if selected_worker not in valid_workers:\n",
    "            selected_worker = \"web_researcher\"  # Default fallback\n",
    "        \n",
    "        state.supervisor_decisions.append(f\"Assigned task '{next_task['description'][:50]}...' to {selected_worker}\")\n",
    "        state.worker_status[selected_worker] = \"working\"\n",
    "        \n",
    "        print(f\"📋 Supervisor: Delegating to {selected_worker}\")\n",
    "        return Command(goto=selected_worker, update=state.model_dump())\n",
    "    \n",
    "    # If all tasks completed, finish\n",
    "    elif not state.task_queue and not state.current_task:\n",
    "        print(\"✅ Supervisor: All tasks completed\")\n",
    "        return Command(finish=state.model_dump())\n",
    "    \n",
    "    # Continue supervising\n",
    "    else:\n",
    "        print(\"⏳ Supervisor: Waiting for task completion\")\n",
    "        return Command(goto=\"supervisor\", update=state.model_dump())\n",
    "\n",
    "print(\"👔 Supervisor pattern nodes defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Building and Testing the Supervisor System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_supervisor_graph():\n",
    "    \"\"\"Create supervisor-worker graph\"\"\"\n",
    "    \n",
    "    graph = StateGraph(SupervisorState)\n",
    "    \n",
    "    # Add supervisor and worker nodes\n",
    "    graph.add_node(\"supervisor\", supervisor_node)\n",
    "    graph.add_node(\"web_researcher\", web_researcher_worker)\n",
    "    graph.add_node(\"data_analyst\", data_analyst_worker)\n",
    "    graph.add_node(\"content_writer\", content_writer_worker)\n",
    "    \n",
    "    # Start with supervisor\n",
    "    graph.add_edge(START, \"supervisor\")\n",
    "    \n",
    "    # Compile with persistence\n",
    "    saver = SqliteSaver.from_conn_string(\"supervisor.db\")\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create supervisor system\n",
    "supervisor_app = create_supervisor_graph()\n",
    "print(\"🏭 Supervisor system created successfully\")\n",
    "\n",
    "# Create test tasks\n",
    "test_tasks = [\n",
    "    {\n",
    "        \"id\": \"task_1\",\n",
    "        \"description\": \"Research the latest trends in machine learning for 2025\",\n",
    "        \"type\": \"research\",\n",
    "        \"priority\": \"high\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"task_2\",\n",
    "        \"description\": \"Analyze user engagement data from the past quarter\",\n",
    "        \"type\": \"analysis\",\n",
    "        \"priority\": \"medium\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"task_3\",\n",
    "        \"description\": \"Write a blog post about AI safety best practices\",\n",
    "        \"type\": \"content\",\n",
    "        \"priority\": \"medium\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test supervisor system\n",
    "supervisor_state = SupervisorState(\n",
    "    task_queue=test_tasks,\n",
    "    worker_status={worker: \"idle\" for worker in [\"web_researcher\", \"data_analyst\", \"content_writer\"]}\n",
    ")\n",
    "\n",
    "supervisor_config = {\"configurable\": {\"thread_id\": \"supervisor-test\"}}\n",
    "\n",
    "print(\"\\n🚀 Running supervisor workflow...\")\n",
    "supervisor_result = supervisor_app.invoke(supervisor_state, config=supervisor_config)\n",
    "\n",
    "print(f\"\\n📊 Supervisor Results:\")\n",
    "print(f\"✅ Completed Tasks: {len(supervisor_result.completed_tasks)}\")\n",
    "print(f\"📋 Supervisor Decisions: {len(supervisor_result.supervisor_decisions)}\")\n",
    "print(f\"👥 Worker Status: {supervisor_result.worker_status}\")\n",
    "\n",
    "# Show completed tasks\n",
    "for i, task in enumerate(supervisor_result.completed_tasks):\n",
    "    print(f\"\\n📝 Task {i+1}: {task['description'][:50]}...\")\n",
    "    print(f\"   Completed by: {task['completed_by']}\")\n",
    "    print(f\"   Result preview: {task['result'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Network Communication and Secure Data Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import hmac\n",
    "import base64\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "class SecureMessage(BaseModel):\n",
    "    \"\"\"Secure message with validation and encryption\"\"\"\n",
    "    sender_id: str\n",
    "    receiver_id: str\n",
    "    message_type: str\n",
    "    payload: str  # Encrypted content\n",
    "    signature: str\n",
    "    timestamp: str\n",
    "    nonce: str = Field(default_factory=lambda: os.urandom(16).hex())\n",
    "    \n",
    "    @validator('timestamp')\n",
    "    def validate_timestamp(cls, v):\n",
    "        try:\n",
    "            datetime.fromisoformat(v)\n",
    "            return v\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Invalid timestamp format\")\n",
    "\n",
    "class SecureAgentCommunication:\n",
    "    \"\"\"Handles secure communication between agents\"\"\"\n",
    "    \n",
    "    def __init__(self, secret_key: str):\n",
    "        self.secret_key = secret_key.encode()\n",
    "        # Generate encryption key from secret\n",
    "        key = base64.urlsafe_b64encode(hashlib.sha256(self.secret_key).digest())\n",
    "        self.cipher = Fernet(key)\n",
    "        \n",
    "    def create_secure_message(self, sender_id: str, receiver_id: str, \n",
    "                            message_type: str, content: str) -> SecureMessage:\n",
    "        \"\"\"Create a secure, signed message\"\"\"\n",
    "        \n",
    "        # Encrypt the content\n",
    "        encrypted_content = self.cipher.encrypt(content.encode())\n",
    "        payload = base64.b64encode(encrypted_content).decode()\n",
    "        \n",
    "        # Create timestamp\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        # Create message data for signing\n",
    "        message_data = f\"{sender_id}:{receiver_id}:{message_type}:{payload}:{timestamp}\"\n",
    "        \n",
    "        # Create HMAC signature\n",
    "        signature = hmac.new(\n",
    "            self.secret_key,\n",
    "            message_data.encode(),\n",
    "            hashlib.sha256\n",
    "        ).hexdigest()\n",
    "        \n",
    "        return SecureMessage(\n",
    "            sender_id=sender_id,\n",
    "            receiver_id=receiver_id,\n",
    "            message_type=message_type,\n",
    "            payload=payload,\n",
    "            signature=signature,\n",
    "            timestamp=timestamp\n",
    "        )\n",
    "    \n",
    "    def verify_and_decrypt_message(self, message: SecureMessage) -> tuple[bool, str]:\n",
    "        \"\"\"Verify message signature and decrypt content\"\"\"\n",
    "        \n",
    "        # Recreate message data for verification\n",
    "        message_data = f\"{message.sender_id}:{message.receiver_id}:{message.message_type}:{message.payload}:{message.timestamp}\"\n",
    "        \n",
    "        # Verify signature\n",
    "        expected_signature = hmac.new(\n",
    "            self.secret_key,\n",
    "            message_data.encode(),\n",
    "            hashlib.sha256\n",
    "        ).hexdigest()\n",
    "        \n",
    "        if not hmac.compare_digest(expected_signature, message.signature):\n",
    "            return False, \"Invalid signature\"\n",
    "        \n",
    "        # Check timestamp (prevent replay attacks)\n",
    "        msg_time = datetime.fromisoformat(message.timestamp)\n",
    "        current_time = datetime.now()\n",
    "        if (current_time - msg_time).total_seconds() > 3600:  # 1 hour expiry\n",
    "            return False, \"Message expired\"\n",
    "        \n",
    "        # Decrypt content\n",
    "        try:\n",
    "            encrypted_content = base64.b64decode(message.payload)\n",
    "            decrypted_content = self.cipher.decrypt(encrypted_content).decode()\n",
    "            return True, decrypted_content\n",
    "        except Exception as e:\n",
    "            return False, f\"Decryption failed: {str(e)}\"\n",
    "\n",
    "class NetworkAgentState(BaseModel):\n",
    "    \"\"\"State for network-based agent communication\"\"\"\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    secure_messages: List[SecureMessage] = Field(default_factory=list)\n",
    "    agent_id: str\n",
    "    trusted_agents: List[str] = Field(default_factory=list)\n",
    "    message_log: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "    security_violations: List[str] = Field(default_factory=list)\n",
    "\n",
    "# Create secure communication instance\n",
    "secure_comm = SecureAgentCommunication(\"my_secret_key_12345\")\n",
    "\n",
    "def secure_sender_agent(state: NetworkAgentState) -> Command:\n",
    "    \"\"\"Agent that sends secure messages\"\"\"\n",
    "    print(f\"📡 Secure Sender ({state.agent_id}): Preparing secure message\")\n",
    "    \n",
    "    # Create secure message\n",
    "    content = \"This is a confidential message containing sensitive agent data.\"\n",
    "    secure_msg = secure_comm.create_secure_message(\n",
    "        sender_id=state.agent_id,\n",
    "        receiver_id=\"receiver_agent\",\n",
    "        message_type=\"task_data\",\n",
    "        content=content\n",
    "    )\n",
    "    \n",
    "    state.secure_messages.append(secure_msg)\n",
    "    state.message_log.append({\n",
    "        \"action\": \"message_sent\",\n",
    "        \"to\": \"receiver_agent\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"message_id\": secure_msg.nonce\n",
    "    })\n",
    "    \n",
    "    print(f\"✅ Secure message sent with signature: {secure_msg.signature[:20]}...\")\n",
    "    \n",
    "    return Command(goto=\"receiver\", update=state.model_dump())\n",
    "\n",
    "def secure_receiver_agent(state: NetworkAgentState) -> Command:\n",
    "    \"\"\"Agent that receives and validates secure messages\"\"\"\n",
    "    print(f\"📨 Secure Receiver: Processing incoming messages\")\n",
    "    \n",
    "    for secure_msg in state.secure_messages:\n",
    "        if secure_msg.receiver_id == \"receiver_agent\":\n",
    "            # Verify and decrypt message\n",
    "            is_valid, content = secure_comm.verify_and_decrypt_message(secure_msg)\n",
    "            \n",
    "            if is_valid:\n",
    "                print(f\"✅ Message verified and decrypted successfully\")\n",
    "                print(f\"📄 Content: {content[:50]}...\")\n",
    "                \n",
    "                # Log successful message processing\n",
    "                state.message_log.append({\n",
    "                    \"action\": \"message_received\",\n",
    "                    \"from\": secure_msg.sender_id,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"status\": \"verified\",\n",
    "                    \"content_preview\": content[:50]\n",
    "                })\n",
    "                \n",
    "                # Process the secure content with LLM\n",
    "                processing_prompt = f\"\"\"\n",
    "                You received a secure message from another agent:\n",
    "                {content}\n",
    "                \n",
    "                Generate an appropriate response acknowledging the message.\n",
    "                \"\"\"\n",
    "                \n",
    "                response = fast_llm.invoke([HumanMessage(content=processing_prompt)])\n",
    "                state.messages.append(response)\n",
    "                \n",
    "            else:\n",
    "                print(f\"❌ Message verification failed: {content}\")\n",
    "                state.security_violations.append(f\"Invalid message from {secure_msg.sender_id}: {content}\")\n",
    "    \n",
    "    return Command(finish=state.model_dump())\n",
    "\n",
    "print(\"🔐 Secure communication agents defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Testing Secure Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_secure_communication_graph():\n",
    "    \"\"\"Create graph for secure agent communication\"\"\"\n",
    "    \n",
    "    graph = StateGraph(NetworkAgentState)\n",
    "    \n",
    "    graph.add_node(\"sender\", secure_sender_agent)\n",
    "    graph.add_node(\"receiver\", secure_receiver_agent)\n",
    "    \n",
    "    graph.add_edge(START, \"sender\")\n",
    "    \n",
    "    # Compile with persistence\n",
    "    saver = SqliteSaver.from_conn_string(\"secure_comm.db\")\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Test secure communication\n",
    "secure_app = create_secure_communication_graph()\n",
    "print(\"🔐 Secure communication graph created\")\n",
    "\n",
    "# Create test state\n",
    "secure_state = NetworkAgentState(\n",
    "    agent_id=\"sender_agent\",\n",
    "    trusted_agents=[\"receiver_agent\"]\n",
    ")\n",
    "\n",
    "secure_config = {\"configurable\": {\"thread_id\": \"secure-comm-test\"}}\n",
    "\n",
    "print(\"\\n🚀 Testing secure communication...\")\n",
    "secure_result = secure_app.invoke(secure_state, config=secure_config)\n",
    "\n",
    "print(f\"\\n📊 Secure Communication Results:\")\n",
    "print(f\"📧 Secure Messages: {len(secure_result.secure_messages)}\")\n",
    "print(f\"📝 Message Log Entries: {len(secure_result.message_log)}\")\n",
    "print(f\"⚠️ Security Violations: {len(secure_result.security_violations)}\")\n",
    "print(f\"💬 Generated Responses: {len(secure_result.messages)}\")\n",
    "\n",
    "# Show message log\n",
    "for log_entry in secure_result.message_log:\n",
    "    print(f\"\\n📋 {log_entry['action']}: {log_entry.get('status', 'N/A')}\")\n",
    "    if 'content_preview' in log_entry:\n",
    "        print(f\"   Preview: {log_entry['content_preview']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Message Validation and Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageValidator:\n",
    "    \"\"\"Validates messages between agents\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_agent_message(message: AgentMessage) -> tuple[bool, List[str]]:\n",
    "        \"\"\"Validate agent message structure and content\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Check required fields\n",
    "        if not message.from_agent:\n",
    "            errors.append(\"Missing from_agent\")\n",
    "        if not message.to_agent:\n",
    "            errors.append(\"Missing to_agent\")\n",
    "        if not message.content:\n",
    "            errors.append(\"Missing content\")\n",
    "        \n",
    "        # Validate content length\n",
    "        if len(message.content) > 10000:\n",
    "            errors.append(\"Content too long (max 10000 characters)\")\n",
    "        \n",
    "        # Check for malicious content patterns\n",
    "        malicious_patterns = [\n",
    "            \"<script\", \"javascript:\", \"eval(\", \"exec(\",\n",
    "            \"system(\", \"os.system\", \"subprocess\", \"__import__\"\n",
    "        ]\n",
    "        \n",
    "        content_lower = message.content.lower()\n",
    "        for pattern in malicious_patterns:\n",
    "            if pattern in content_lower:\n",
    "                errors.append(f\"Potentially malicious content detected: {pattern}\")\n",
    "        \n",
    "        # Validate timestamp\n",
    "        try:\n",
    "            msg_time = datetime.fromisoformat(message.timestamp)\n",
    "            current_time = datetime.now()\n",
    "            if msg_time > current_time:\n",
    "                errors.append(\"Message timestamp is in the future\")\n",
    "        except ValueError:\n",
    "            errors.append(\"Invalid timestamp format\")\n",
    "        \n",
    "        return len(errors) == 0, errors\n",
    "    \n",
    "    @staticmethod\n",
    "    def sanitize_content(content: str) -> str:\n",
    "        \"\"\"Sanitize message content\"\"\"\n",
    "        # Remove potentially dangerous characters\n",
    "        import re\n",
    "        # Remove HTML tags\n",
    "        content = re.sub(r'<[^>]+>', '', content)\n",
    "        # Remove script-like patterns\n",
    "        content = re.sub(r'(javascript:|data:text/html)', '', content, flags=re.IGNORECASE)\n",
    "        # Limit length\n",
    "        content = content[:5000]\n",
    "        return content.strip()\n",
    "\n",
    "class ValidatedAgentState(BaseModel):\n",
    "    \"\"\"State with message validation\"\"\"\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    agent_messages: List[AgentMessage] = Field(default_factory=list)\n",
    "    validation_log: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "    rejected_messages: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "    current_agent: str = \"validator\"\n",
    "    task_status: str = \"pending\"\n",
    "\n",
    "def message_validator_node(state: ValidatedAgentState) -> Command:\n",
    "    \"\"\"Validates incoming messages\"\"\"\n",
    "    print(\"🔍 Message Validator: Checking message integrity\")\n",
    "    \n",
    "    validator = MessageValidator()\n",
    "    \n",
    "    # Create test messages to validate\n",
    "    test_messages = [\n",
    "        AgentMessage(\n",
    "            from_agent=AgentRole.COORDINATOR,\n",
    "            to_agent=AgentRole.RESEARCHER,\n",
    "            message_type=MessageType.TASK_REQUEST,\n",
    "            content=\"Please research AI safety protocols\"\n",
    "        ),\n",
    "        AgentMessage(\n",
    "            from_agent=AgentRole.RESEARCHER,\n",
    "            to_agent=AgentRole.ANALYST,\n",
    "            message_type=MessageType.TASK_RESPONSE,\n",
    "            content=\"<script>alert('malicious')</script>Research completed\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    for msg in test_messages:\n",
    "        is_valid, errors = validator.validate_agent_message(msg)\n",
    "        \n",
    "        validation_entry = {\n",
    "            \"message_id\": msg.message_id,\n",
    "            \"from_agent\": msg.from_agent,\n",
    "            \"to_agent\": msg.to_agent,\n",
    "            \"is_valid\": is_valid,\n",
    "            \"errors\": errors,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        state.validation_log.append(validation_entry)\n",
    "        \n",
    "        if is_valid:\n",
    "            # Sanitize and add to valid messages\n",
    "            msg.content = validator.sanitize_content(msg.content)\n",
    "            state.agent_messages.append(msg)\n",
    "            print(f\"✅ Message validated: {msg.message_id[:8]}...\")\n",
    "        else:\n",
    "            # Reject invalid message\n",
    "            state.rejected_messages.append({\n",
    "                \"message\": msg.model_dump(),\n",
    "                \"errors\": errors,\n",
    "                \"rejected_at\": datetime.now().isoformat()\n",
    "            })\n",
    "            print(f\"❌ Message rejected: {', '.join(errors)}\")\n",
    "    \n",
    "    state.task_status = \"validation_complete\"\n",
    "    \n",
    "    return Command(goto=\"processor\", update=state.model_dump())\n",
    "\n",
    "def secure_processor_node(state: ValidatedAgentState) -> Command:\n",
    "    \"\"\"Processes validated messages securely\"\"\"\n",
    "    print(\"🛡️ Secure Processor: Processing validated messages\")\n",
    "    \n",
    "    valid_messages_count = len(state.agent_messages)\n",
    "    rejected_messages_count = len(state.rejected_messages)\n",
    "    \n",
    "    # Process valid messages with OpenAI\n",
    "    if state.agent_messages:\n",
    "        messages_summary = \"\\n\".join([f\"- {msg.content[:100]}...\" for msg in state.agent_messages])\n",
    "        \n",
    "        processing_prompt = f\"\"\"\n",
    "        You are processing validated inter-agent messages. Summary of {valid_messages_count} valid messages:\n",
    "        \n",
    "        {messages_summary}\n",
    "        \n",
    "        Generate a summary of the communication flow and any insights.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=processing_prompt)])\n",
    "        state.messages.append(response)\n",
    "    \n",
    "    state.task_status = \"completed\"\n",
    "    \n",
    "    print(f\"📊 Processed {valid_messages_count} valid messages, rejected {rejected_messages_count}\")\n",
    "    \n",
    "    return Command(finish=state.model_dump())\n",
    "\n",
    "# Create validation graph\n",
    "def create_validation_graph():\n",
    "    \"\"\"Create message validation graph\"\"\"\n",
    "    \n",
    "    graph = StateGraph(ValidatedAgentState)\n",
    "    \n",
    "    graph.add_node(\"validator\", message_validator_node)\n",
    "    graph.add_node(\"processor\", secure_processor_node)\n",
    "    \n",
    "    graph.add_edge(START, \"validator\")\n",
    "    \n",
    "    # Compile with persistence\n",
    "    saver = SqliteSaver.from_conn_string(\"validation.db\")\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Test message validation\n",
    "validation_app = create_validation_graph()\n",
    "print(\"\\n🔍 Message validation graph created\")\n",
    "\n",
    "validation_state = ValidatedAgentState()\n",
    "validation_config = {\"configurable\": {\"thread_id\": \"validation-test\"}}\n",
    "\n",
    "print(\"\\n🚀 Testing message validation...\")\n",
    "validation_result = validation_app.invoke(validation_state, config=validation_config)\n",
    "\n",
    "print(f\"\\n📊 Validation Results:\")\n",
    "print(f\"✅ Valid Messages: {len(validation_result.agent_messages)}\")\n",
    "print(f\"❌ Rejected Messages: {len(validation_result.rejected_messages)}\")\n",
    "print(f\"📝 Validation Log Entries: {len(validation_result.validation_log)}\")\n",
    "\n",
    "# Show validation details\n",
    "for log_entry in validation_result.validation_log:\n",
    "    status = \"✅ VALID\" if log_entry['is_valid'] else \"❌ INVALID\"\n",
    "    print(f\"\\n{status} - {log_entry['from_agent']} → {log_entry['to_agent']}\")\n",
    "    if log_entry['errors']:\n",
    "        print(f\"   Errors: {', '.join(log_entry['errors'])}\")\n",
    "\n",
    "print(\"\\n🔐 Message validation and security testing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🛠️ Practical Exercises (30 minutes)\n",
    "\n",
    "### Exercise 1: Build a Customer Support Multi-Agent System\n",
    "**Goal**: Create a customer support system with multiple specialized agents.\n",
    "\n",
    "**Requirements**:\n",
    "- Initial classifier agent that routes tickets\n",
    "- Technical support agent for technical issues\n",
    "- Billing agent for payment issues\n",
    "- Escalation agent for complex problems\n",
    "- Use Command objects for handoffs\n",
    "- Implement proper message validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your implementation here\n",
    "class SupportTicket(BaseModel):\n",
    "    \"\"\"Support ticket data structure\"\"\"\n",
    "    # TODO: Define your support ticket schema\n",
    "    pass\n",
    "\n",
    "class SupportAgentState(BaseModel):\n",
    "    \"\"\"State for customer support system\"\"\"\n",
    "    # TODO: Define your support system state\n",
    "    pass\n",
    "\n",
    "def ticket_classifier_agent(state: SupportAgentState) -> Command:\n",
    "    \"\"\"Classifies and routes support tickets\"\"\"\n",
    "    # TODO: Implement ticket classification logic\n",
    "    pass\n",
    "\n",
    "def technical_support_agent(state: SupportAgentState) -> Command:\n",
    "    \"\"\"Handles technical support issues\"\"\"\n",
    "    # TODO: Implement technical support logic\n",
    "    pass\n",
    "\n",
    "# TODO: Create and test your customer support system\n",
    "print(\"🎫 Exercise 1: Implement your customer support multi-agent system here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement a Distributed Task Processing System\n",
    "**Goal**: Build a system where multiple worker agents process tasks in parallel.\n",
    "\n",
    "**Requirements**:\n",
    "- Task dispatcher that distributes work\n",
    "- Multiple worker agents that can run in parallel\n",
    "- Results aggregator that combines outputs\n",
    "- Implement secure communication between agents\n",
    "- Handle worker failures and task redistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your implementation here\n",
    "class DistributedTask(BaseModel):\n",
    "    \"\"\"Task for distributed processing\"\"\"\n",
    "    # TODO: Define your task structure\n",
    "    pass\n",
    "\n",
    "class DistributedSystemState(BaseModel):\n",
    "    \"\"\"State for distributed task processing\"\"\"\n",
    "    # TODO: Define your distributed system state\n",
    "    pass\n",
    "\n",
    "def task_dispatcher_agent(state: DistributedSystemState) -> Command:\n",
    "    \"\"\"Dispatches tasks to available workers\"\"\"\n",
    "    # TODO: Implement task dispatch logic\n",
    "    pass\n",
    "\n",
    "def parallel_worker_agent(state: DistributedSystemState) -> Command:\n",
    "    \"\"\"Processes tasks in parallel\"\"\"\n",
    "    # TODO: Implement parallel processing logic\n",
    "    pass\n",
    "\n",
    "# TODO: Create and test your distributed processing system\n",
    "print(\"🔄 Exercise 2: Implement your distributed task processing system here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Create an AI Research Collaboration Network\n",
    "**Goal**: Build an advanced multi-agent system that simulates AI research collaboration.\n",
    "\n",
    "**Advanced Requirements**:\n",
    "- Research proposal agent that generates research ideas\n",
    "- Peer review agents that evaluate proposals\n",
    "- Collaboration matching agent that pairs researchers\n",
    "- Progress tracking and milestone management\n",
    "- Secure sharing of research data\n",
    "- Dynamic agent roles and permissions\n",
    "- Cross-network communication protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Your implementation here\n",
    "class ResearchProposal(BaseModel):\n",
    "    \"\"\"Research proposal structure\"\"\"\n",
    "    # TODO: Design comprehensive research proposal schema\n",
    "    pass\n",
    "\n",
    "class ResearchNetworkState(BaseModel):\n",
    "    \"\"\"State for research collaboration network\"\"\"\n",
    "    # TODO: Design complex research network state\n",
    "    pass\n",
    "\n",
    "# TODO: Implement your AI research collaboration network\n",
    "print(\"🎯 Challenge: Build your AI research collaboration network here\")\n",
    "print(\"💡 Hint: Consider research lifecycle, peer review, and collaboration dynamics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 📚 Solutions and Best Practices\n",
    "\n",
    "### Exercise 1 Solution: Customer Support System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete solution for Exercise 1\n",
    "class TicketPriority(str, Enum):\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    URGENT = \"urgent\"\n",
    "\n",
    "class TicketCategory(str, Enum):\n",
    "    TECHNICAL = \"technical\"\n",
    "    BILLING = \"billing\"\n",
    "    GENERAL = \"general\"\n",
    "    ESCALATION = \"escalation\"\n",
    "\n",
    "class SupportTicket(BaseModel):\n",
    "    ticket_id: str\n",
    "    customer_id: str\n",
    "    title: str\n",
    "    description: str\n",
    "    category: Optional[TicketCategory] = None\n",
    "    priority: TicketPriority = TicketPriority.MEDIUM\n",
    "    status: str = \"open\"\n",
    "    assigned_agent: Optional[str] = None\n",
    "    resolution: Optional[str] = None\n",
    "    created_at: str = Field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "class SupportAgentState(BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    tickets: List[SupportTicket] = Field(default_factory=list)\n",
    "    current_ticket: Optional[SupportTicket] = None\n",
    "    agent_workload: Dict[str, int] = Field(default_factory=dict)\n",
    "    escalation_log: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "\n",
    "def ticket_classifier_agent(state: SupportAgentState) -> Command:\n",
    "    \"\"\"Classifies and routes support tickets\"\"\"\n",
    "    print(\"🎫 Ticket Classifier: Analyzing incoming ticket\")\n",
    "    \n",
    "    if state.current_ticket:\n",
    "        ticket = state.current_ticket\n",
    "        \n",
    "        # Use OpenAI to classify the ticket\n",
    "        classification_prompt = f\"\"\"\n",
    "        Classify this support ticket into one of these categories:\n",
    "        - technical: Technical issues, bugs, software problems\n",
    "        - billing: Payment issues, subscription problems, refunds\n",
    "        - general: General inquiries, feature requests, information\n",
    "        - escalation: Complex issues requiring senior support\n",
    "        \n",
    "        Ticket: {ticket.title}\n",
    "        Description: {ticket.description}\n",
    "        \n",
    "        Respond with only the category name.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = fast_llm.invoke([HumanMessage(content=classification_prompt)])\n",
    "        category = response.content.strip().lower()\n",
    "        \n",
    "        # Validate and assign category\n",
    "        if category in [\"technical\", \"billing\", \"general\", \"escalation\"]:\n",
    "            ticket.category = TicketCategory(category)\n",
    "        else:\n",
    "            ticket.category = TicketCategory.GENERAL\n",
    "        \n",
    "        print(f\"📋 Ticket classified as: {ticket.category}\")\n",
    "        \n",
    "        # Route to appropriate agent\n",
    "        if ticket.category == TicketCategory.TECHNICAL:\n",
    "            return Command(goto=\"technical_agent\", update=state.model_dump())\n",
    "        elif ticket.category == TicketCategory.BILLING:\n",
    "            return Command(goto=\"billing_agent\", update=state.model_dump())\n",
    "        else:\n",
    "            return Command(goto=\"general_agent\", update=state.model_dump())\n",
    "    \n",
    "    return Command(finish=state.model_dump())\n",
    "\n",
    "def technical_support_agent(state: SupportAgentState) -> Command:\n",
    "    \"\"\"Handles technical support issues\"\"\"\n",
    "    print(\"🔧 Technical Support: Processing technical issue\")\n",
    "    \n",
    "    if state.current_ticket:\n",
    "        ticket = state.current_ticket\n",
    "        \n",
    "        # Generate technical solution\n",
    "        tech_prompt = f\"\"\"\n",
    "        You are a technical support specialist. Provide a solution for:\n",
    "        \n",
    "        Issue: {ticket.title}\n",
    "        Details: {ticket.description}\n",
    "        \n",
    "        Provide step-by-step troubleshooting instructions.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=tech_prompt)])\n",
    "        \n",
    "        ticket.resolution = response.content\n",
    "        ticket.assigned_agent = \"technical_support\"\n",
    "        ticket.status = \"resolved\"\n",
    "        \n",
    "        state.messages.append(response)\n",
    "        print(f\"✅ Technical issue resolved\")\n",
    "    \n",
    "    return Command(finish=state.model_dump())\n",
    "\n",
    "# Create support system\n",
    "def create_support_system():\n",
    "    graph = StateGraph(SupportAgentState)\n",
    "    \n",
    "    graph.add_node(\"classifier\", ticket_classifier_agent)\n",
    "    graph.add_node(\"technical_agent\", technical_support_agent)\n",
    "    # Add other agents...\n",
    "    \n",
    "    graph.add_edge(START, \"classifier\")\n",
    "    \n",
    "    saver = SqliteSaver.from_conn_string(\"support_system.db\")\n",
    "    return graph.compile(checkpointer=saver)\n",
    "\n",
    "# Test the support system\n",
    "support_app = create_support_system()\n",
    "\n",
    "test_ticket = SupportTicket(\n",
    "    ticket_id=\"TKT-001\",\n",
    "    customer_id=\"CUST-123\",\n",
    "    title=\"Application crashes on startup\",\n",
    "    description=\"The application crashes immediately when I try to open it. Error message shows 'Memory access violation'.\"\n",
    ")\n",
    "\n",
    "support_state = SupportAgentState(current_ticket=test_ticket)\n",
    "support_config = {\"configurable\": {\"thread_id\": \"support-test\"}}\n",
    "\n",
    "print(\"\\n🎫 Testing customer support system...\")\n",
    "support_result = support_app.invoke(support_state, config=support_config)\n",
    "\n",
    "if support_result.current_ticket:\n",
    "    ticket = support_result.current_ticket\n",
    "    print(f\"✅ Support System Solution: Ticket {ticket.ticket_id}\")\n",
    "    print(f\"📋 Category: {ticket.category}, Status: {ticket.status}\")\n",
    "    print(f\"👤 Assigned to: {ticket.assigned_agent}\")\n",
    "    print(f\"🔧 Resolution preview: {ticket.resolution[:200] if ticket.resolution else 'No resolution'}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🔧 Troubleshooting Common Issues\n",
    "\n",
    "### Command Object Issues\n",
    "```python\n",
    "# ❌ Common issue: Invalid Command usage\n",
    "return Command(\"next_node\")  # Wrong syntax\n",
    "\n",
    "# ✅ Correct Command usage\n",
    "return Command(goto=\"next_node\", update=state.model_dump())\n",
    "return Command(finish=state.model_dump())\n",
    "```\n",
    "\n",
    "### Message Validation Errors\n",
    "```python\n",
    "# ✅ Always validate messages before processing\n",
    "def validate_message(msg: AgentMessage) -> bool:\n",
    "    try:\n",
    "        # Validate required fields\n",
    "        return all([msg.from_agent, msg.to_agent, msg.content])\n",
    "    except Exception:\n",
    "        return False\n",
    "```\n",
    "\n",
    "### Secure Communication Setup\n",
    "```python\n",
    "# ✅ Proper secret key management\n",
    "SECRET_KEY = os.getenv(\"AGENT_SECRET_KEY\", \"fallback-key-for-dev\")\n",
    "secure_comm = SecureAgentCommunication(SECRET_KEY)\n",
    "```\n",
    "\n",
    "### State Synchronization\n",
    "```python\n",
    "# ✅ Always update state consistently\n",
    "def agent_node(state: MultiAgentState) -> Command:\n",
    "    # Modify state\n",
    "    state.current_agent = \"new_agent\"\n",
    "    \n",
    "    # Always return updated state\n",
    "    return Command(goto=\"next_node\", update=state.model_dump())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 📖 Summary and Next Steps\n",
    "\n",
    "### What You've Learned:\n",
    "✅ **Multi-Agent Communication**: Agent handoffs and coordination patterns  \n",
    "✅ **Command Objects**: Structured control transfer between agents  \n",
    "✅ **Supervisor Patterns**: Central coordination with OpenAI decision making  \n",
    "✅ **Secure Communication**: Encryption, signing, and validation  \n",
    "✅ **Message Validation**: Input sanitization and security checks  \n",
    "✅ **Network Patterns**: Distributed agent communication  \n",
    "\n",
    "### Best Practices Covered:\n",
    "- Use Command objects for clean agent handoffs\n",
    "- Implement proper message validation and sanitization\n",
    "- Secure inter-agent communication with encryption\n",
    "- Design supervisor patterns for complex coordination\n",
    "- Handle errors gracefully in multi-agent systems\n",
    "- Log all agent interactions for debugging\n",
    "\n",
    "### Tomorrow's Preview (Day 5):\n",
    "🏗️ **Advanced Architectures & Tool Integration**\n",
    "- Hierarchical multi-agent systems\n",
    "- Parallel execution and map-reduce patterns\n",
    "- Tool integration (Tavily, APIs) with OpenAI\n",
    "- Performance and cost optimization\n",
    "- Production deployment strategies\n",
    "\n",
    "### Resources for Further Learning:\n",
    "- [LangGraph Multi-Agent Documentation](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)\n",
    "- [Command Objects Reference](https://langchain-ai.github.io/langgraph/reference/types/)\n",
    "- [Agent Communication Patterns](https://langchain-ai.github.io/langgraph/how-tos/)\n",
    "\n",
    "**🎯 You're now ready to build sophisticated multi-agent systems with secure communication!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "print(\"🧹 Session complete! Database files created:\")\n",
    "import os\n",
    "db_files = [f for f in os.listdir('.') if f.endswith('.db')]\n",
    "for db_file in db_files:\n",
    "    if any(x in db_file for x in ['multi_agent', 'supervisor', 'secure_comm', 'validation']):\n",
    "        print(f\"  📁 {db_file}\")\n",
    "\n",
    "print(\"\\n🎉 Day 4 Complete! You've mastered multi-agent communication and handoffs in LangGraph.\")\n",
    "print(\"🚀 Ready for Day 5: Advanced Architectures & Tool Integration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}