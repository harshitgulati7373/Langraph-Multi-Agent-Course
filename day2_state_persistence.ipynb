{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: State Management & Persistence in LangGraph\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "By the end of this session, you will:\n",
    "- Master LangGraph's graph architecture (nodes, edges, conditional routing)\n",
    "- Implement state persistence with different checkpointer types\n",
    "- Understand state serialization and recovery mechanisms\n",
    "- Handle errors and implement recovery patterns\n",
    "- Build stateful agents that persist across sessions\n",
    "\n",
    "## â±ï¸ Session Structure (2 hours)\n",
    "- **Learning Materials** (30 min): Theory and concepts\n",
    "- **Hands-on Code** (60 min): Implementation and examples  \n",
    "- **Practical Exercises** (30 min): Build and extend functionality\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“– Learning Materials (30 minutes)\n",
    "\n",
    "### ğŸ“º Video Resources\n",
    "- [LangGraph Persistence Guide](https://langchain-ai.github.io/langgraph/concepts/persistence/) - Official documentation\n",
    "- [DeepLearning.AI - AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/) - Module 2: State Management\n",
    "- [LangChain Academy - Persistence Patterns](https://academy.langchain.com/) - Checkpointer deep dive\n",
    "\n",
    "### ğŸ§  Theory: Graph State Management\n",
    "\n",
    "#### What is State in LangGraph?\n",
    "State in LangGraph represents the current data and context of your agent workflow. It flows through nodes and gets modified at each step.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Nodes**: Individual processing units that modify state\n",
    "- **Edges**: Define how state flows between nodes\n",
    "- **Conditional Edges**: Route state based on conditions\n",
    "- **State Schema**: Defines the structure of your state (Pydantic, TypedDict, or dataclass)\n",
    "\n",
    "#### Why Persistence?\n",
    "Persistence allows agents to:\n",
    "- Resume from interruptions\n",
    "- Maintain conversation history\n",
    "- Enable human-in-the-loop workflows\n",
    "- Support debugging and replay\n",
    "- Scale to long-running processes\n",
    "\n",
    "#### Checkpointer Types\n",
    "1. **InMemorySaver**: For testing and development\n",
    "2. **SqliteSaver**: For local persistence and prototyping\n",
    "3. **PostgresSaver**: For production environments\n",
    "\n",
    "#### State Serialization\n",
    "LangGraph uses `JsonPlusSerializer` to handle:\n",
    "- LangChain objects (messages, documents)\n",
    "- Pydantic models\n",
    "- Python primitives\n",
    "- Custom serializable objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ’» Hands-on Code (60 minutes)\n",
    "\n",
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langgraph langchain langchain-openai pydantic python-dotenv\n",
    "!pip install langgraph-checkpoint-sqlite  # For SQLite persistence\n",
    "!pip install psycopg2-binary  # For PostgreSQL (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Literal, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    print(\"âš ï¸ Please set OPENAI_API_KEY in your .env file\")\n",
    "    print(\"Example: OPENAI_API_KEY=sk-...\")\n",
    "else:\n",
    "    print(\"âœ… OpenAI API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic State Schema with Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state using Pydantic for type safety\n",
    "class AgentState(BaseModel):\n",
    "    \"\"\"State schema for our agent with type validation\"\"\"\n",
    "    messages: List[BaseMessage] = Field(default_factory=list, description=\"Conversation history\")\n",
    "    user_id: str = Field(description=\"User identifier\")\n",
    "    session_id: str = Field(description=\"Session identifier\")\n",
    "    task_status: Literal[\"pending\", \"processing\", \"completed\", \"error\"] = Field(default=\"pending\")\n",
    "    metadata: dict = Field(default_factory=dict, description=\"Additional metadata\")\n",
    "    step_count: int = Field(default=0, description=\"Number of processing steps\")\n",
    "\n",
    "# Alternative: Using TypedDict (more performant, less validation)\n",
    "class SimpleState(TypedDict):\n",
    "    \"\"\"Simpler state using TypedDict\"\"\"\n",
    "    messages: List[BaseMessage]\n",
    "    task_status: str\n",
    "    step_count: int\n",
    "\n",
    "print(\"ğŸ“‹ State schemas defined successfully\")\n",
    "print(f\"AgentState fields: {list(AgentState.model_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building a Basic Graph with State Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "def process_input(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process user input and update state\"\"\"\n",
    "    print(f\"ğŸ“ Processing input for user: {state.user_id}\")\n",
    "    \n",
    "    # Get the last message\n",
    "    if state.messages:\n",
    "        last_message = state.messages[-1]\n",
    "        if isinstance(last_message, HumanMessage):\n",
    "            # Generate AI response\n",
    "            response = llm.invoke([last_message])\n",
    "            \n",
    "            # Update state\n",
    "            state.messages.append(response)\n",
    "            state.step_count += 1\n",
    "            state.task_status = \"processing\"\n",
    "            \n",
    "            print(f\"ğŸ¤– Generated response: {response.content[:100]}...\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def finalize_response(state: AgentState) -> AgentState:\n",
    "    \"\"\"Finalize the response and mark as completed\"\"\"\n",
    "    print(f\"âœ… Finalizing response for session: {state.session_id}\")\n",
    "    \n",
    "    state.task_status = \"completed\"\n",
    "    state.metadata[\"completed_at\"] = \"2025-01-13\"  # In real app, use datetime.now()\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Conditional edge function\n",
    "def should_continue(state: AgentState) -> Literal[\"finalize\", \"process_more\"]:\n",
    "    \"\"\"Decide whether to continue processing or finalize\"\"\"\n",
    "    if state.step_count >= 2:  # Simple condition\n",
    "        return \"finalize\"\n",
    "    return \"process_more\"\n",
    "\n",
    "print(\"ğŸ”§ Node functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. InMemorySaver - For Development and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph with InMemorySaver\n",
    "def create_basic_graph():\n",
    "    \"\"\"Create a basic graph with in-memory persistence\"\"\"\n",
    "    \n",
    "    # Create the graph\n",
    "    graph = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph.add_node(\"process_input\", process_input)\n",
    "    graph.add_node(\"finalize\", finalize_response)\n",
    "    \n",
    "    # Add edges\n",
    "    graph.add_edge(START, \"process_input\")\n",
    "    graph.add_conditional_edges(\n",
    "        \"process_input\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"finalize\": \"finalize\",\n",
    "            \"process_more\": \"process_input\"  # Loop back\n",
    "        }\n",
    "    )\n",
    "    graph.add_edge(\"finalize\", END)\n",
    "    \n",
    "    # Compile with InMemorySaver\n",
    "    memory = InMemorySaver()\n",
    "    app = graph.compile(checkpointer=memory)\n",
    "    \n",
    "    return app, memory\n",
    "\n",
    "# Test the basic graph\n",
    "app, memory = create_basic_graph()\n",
    "print(\"ğŸ¯ Basic graph created with InMemorySaver\")\n",
    "\n",
    "# Test with sample state\n",
    "initial_state = AgentState(\n",
    "    messages=[HumanMessage(content=\"Hello, can you help me learn LangGraph?\")],\n",
    "    user_id=\"user123\",\n",
    "    session_id=\"session456\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "\n",
    "print(\"\\nğŸš€ Running graph...\")\n",
    "result = app.invoke(initial_state, config=config)\n",
    "print(f\"\\nğŸ“Š Final state: Task status = {result.task_status}, Steps = {result.step_count}\")\n",
    "print(f\"ğŸ’¬ Messages: {len(result.messages)} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SqliteSaver - For Local Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlite_graph():\n",
    "    \"\"\"Create a graph with SQLite persistence\"\"\"\n",
    "    \n",
    "    # Create the graph (same structure)\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"process_input\", process_input)\n",
    "    graph.add_node(\"finalize\", finalize_response)\n",
    "    graph.add_edge(START, \"process_input\")\n",
    "    graph.add_conditional_edges(\n",
    "        \"process_input\",\n",
    "        should_continue,\n",
    "        {\"finalize\": \"finalize\", \"process_more\": \"process_input\"}\n",
    "    )\n",
    "    graph.add_edge(\"finalize\", END)\n",
    "    \n",
    "    # Compile with SQLite persistence\n",
    "    sqlite_saver = SqliteSaver.from_conn_string(\"checkpoints.db\")\n",
    "    app = graph.compile(checkpointer=sqlite_saver)\n",
    "    \n",
    "    return app, sqlite_saver\n",
    "\n",
    "# Create SQLite-backed graph\n",
    "sqlite_app, sqlite_saver = create_sqlite_graph()\n",
    "print(\"ğŸ’¾ SQLite graph created - data persists to 'checkpoints.db'\")\n",
    "\n",
    "# Test persistence\n",
    "config_sqlite = {\"configurable\": {\"thread_id\": \"persistent-thread\"}}\n",
    "\n",
    "# First run\n",
    "print(\"\\nğŸ”„ First run with SQLite persistence...\")\n",
    "persistent_state = AgentState(\n",
    "    messages=[HumanMessage(content=\"Tell me about state persistence in LangGraph\")],\n",
    "    user_id=\"persistent_user\",\n",
    "    session_id=\"persistent_session\"\n",
    ")\n",
    "\n",
    "result1 = sqlite_app.invoke(persistent_state, config=config_sqlite)\n",
    "print(f\"ğŸ“ˆ After first run: {result1.task_status}, Steps: {result1.step_count}\")\n",
    "\n",
    "# Simulate resuming from checkpoint\n",
    "print(\"\\nğŸ”„ Resuming from checkpoint...\")\n",
    "# Get current state\n",
    "current_state = sqlite_app.get_state(config_sqlite)\n",
    "print(f\"ğŸ“‹ Retrieved state: Steps = {current_state.values.step_count}\")\n",
    "print(f\"ğŸ’¬ Messages in history: {len(current_state.values.messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Error Handling and Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prone_process(state: AgentState) -> AgentState:\n",
    "    \"\"\"A node that might fail to demonstrate error handling\"\"\"\n",
    "    print(f\"âš¡ Processing step {state.step_count + 1}\")\n",
    "    \n",
    "    # Simulate an error on step 2\n",
    "    if state.step_count == 1:\n",
    "        state.task_status = \"error\"\n",
    "        state.metadata[\"error\"] = \"Simulated processing error\"\n",
    "        print(\"âŒ Error occurred during processing\")\n",
    "        raise Exception(\"Simulated processing error\")\n",
    "    \n",
    "    # Normal processing\n",
    "    if state.messages:\n",
    "        last_message = state.messages[-1]\n",
    "        if isinstance(last_message, HumanMessage):\n",
    "            response = llm.invoke([last_message])\n",
    "            state.messages.append(response)\n",
    "    \n",
    "    state.step_count += 1\n",
    "    state.task_status = \"processing\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def recovery_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Recovery node that handles errors\"\"\"\n",
    "    print(\"ğŸ”§ Attempting recovery...\")\n",
    "    \n",
    "    if state.task_status == \"error\":\n",
    "        # Reset error state\n",
    "        state.task_status = \"processing\"\n",
    "        state.metadata[\"recovered\"] = True\n",
    "        state.messages.append(AIMessage(content=\"I encountered an error but recovered successfully.\"))\n",
    "        print(\"âœ… Recovery successful\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def create_error_handling_graph():\n",
    "    \"\"\"Create a graph with error handling capabilities\"\"\"\n",
    "    \n",
    "    graph = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes including recovery\n",
    "    graph.add_node(\"process\", error_prone_process)\n",
    "    graph.add_node(\"recover\", recovery_node)\n",
    "    graph.add_node(\"finalize\", finalize_response)\n",
    "    \n",
    "    # Add edges\n",
    "    graph.add_edge(START, \"process\")\n",
    "    \n",
    "    # Conditional routing based on state\n",
    "    def route_after_process(state: AgentState) -> Literal[\"recover\", \"finalize\", \"process\"]:\n",
    "        if state.task_status == \"error\":\n",
    "            return \"recover\"\n",
    "        elif state.step_count >= 3:\n",
    "            return \"finalize\"\n",
    "        else:\n",
    "            return \"process\"\n",
    "    \n",
    "    graph.add_conditional_edges(\n",
    "        \"process\",\n",
    "        route_after_process,\n",
    "        {\"recover\": \"recover\", \"finalize\": \"finalize\", \"process\": \"process\"}\n",
    "    )\n",
    "    \n",
    "    graph.add_edge(\"recover\", \"process\")  # Try again after recovery\n",
    "    graph.add_edge(\"finalize\", END)\n",
    "    \n",
    "    # Use SQLite for persistence during error recovery\n",
    "    saver = SqliteSaver.from_conn_string(\"error_recovery.db\")\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Test error handling\n",
    "error_app = create_error_handling_graph()\n",
    "print(\"ğŸ›¡ï¸ Error handling graph created\")\n",
    "\n",
    "error_config = {\"configurable\": {\"thread_id\": \"error-test\"}}\n",
    "error_state = AgentState(\n",
    "    messages=[HumanMessage(content=\"Test error handling\")],\n",
    "    user_id=\"error_user\",\n",
    "    session_id=\"error_session\"\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ§ª Testing error handling and recovery...\")\n",
    "try:\n",
    "    final_result = error_app.invoke(error_state, config=error_config)\n",
    "    print(f\"ğŸ¯ Final result: {final_result.task_status}\")\n",
    "    print(f\"ğŸ”„ Recovery attempted: {'recovered' in final_result.metadata}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Unhandled error: {e}\")\n",
    "    # Show how to recover from checkpoint\n",
    "    print(\"ğŸ“ Checking saved checkpoint...\")\n",
    "    saved_state = error_app.get_state(error_config)\n",
    "    if saved_state:\n",
    "        print(f\"ğŸ’¾ Checkpoint exists with status: {saved_state.values.task_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Advanced State Management Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex state with nested data\n",
    "class AdvancedAgentState(BaseModel):\n",
    "    \"\"\"Advanced state with complex data structures\"\"\"\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    user_profile: dict = Field(default_factory=dict)\n",
    "    conversation_context: dict = Field(default_factory=dict)\n",
    "    processing_history: List[dict] = Field(default_factory=list)\n",
    "    current_task: Optional[str] = None\n",
    "    subtasks: List[str] = Field(default_factory=list)\n",
    "    metadata: dict = Field(default_factory=dict)\n",
    "\n",
    "def context_aware_processor(state: AdvancedAgentState) -> AdvancedAgentState:\n",
    "    \"\"\"Process with context awareness\"\"\"\n",
    "    print(\"ğŸ§  Context-aware processing...\")\n",
    "    \n",
    "    # Add to processing history\n",
    "    state.processing_history.append({\n",
    "        \"step\": len(state.processing_history) + 1,\n",
    "        \"timestamp\": \"2025-01-13T10:00:00Z\",\n",
    "        \"action\": \"context_processing\"\n",
    "    })\n",
    "    \n",
    "    # Update conversation context\n",
    "    if state.messages:\n",
    "        last_msg = state.messages[-1]\n",
    "        state.conversation_context[\"last_topic\"] = \"LangGraph learning\"\n",
    "        state.conversation_context[\"message_count\"] = len(state.messages)\n",
    "        \n",
    "        # Generate contextual response\n",
    "        context_prompt = f\"\"\"\n",
    "        Based on the conversation context: {state.conversation_context}\n",
    "        User message: {last_msg.content if hasattr(last_msg, 'content') else str(last_msg)}\n",
    "        \n",
    "        Provide a helpful response about LangGraph state management.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=context_prompt)])\n",
    "        state.messages.append(response)\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Create advanced graph\n",
    "def create_advanced_graph():\n",
    "    \"\"\"Create graph with advanced state management\"\"\"\n",
    "    \n",
    "    graph = StateGraph(AdvancedAgentState)\n",
    "    graph.add_node(\"context_process\", context_aware_processor)\n",
    "    graph.add_edge(START, \"context_process\")\n",
    "    graph.add_edge(\"context_process\", END)\n",
    "    \n",
    "    # Use SQLite with custom table name\n",
    "    saver = SqliteSaver.from_conn_string(\"advanced_state.db\")\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Test advanced state management\n",
    "advanced_app = create_advanced_graph()\n",
    "print(\"ğŸš€ Advanced state management graph created\")\n",
    "\n",
    "advanced_state = AdvancedAgentState(\n",
    "    messages=[HumanMessage(content=\"How does state serialization work?\")],\n",
    "    user_profile={\"name\": \"Developer\", \"experience\": \"intermediate\"},\n",
    "    current_task=\"learning_state_management\",\n",
    "    subtasks=[\"understand_checkpoints\", \"implement_persistence\"]\n",
    ")\n",
    "\n",
    "advanced_config = {\"configurable\": {\"thread_id\": \"advanced-test\"}}\n",
    "\n",
    "print(\"\\nğŸ”¬ Testing advanced state management...\")\n",
    "advanced_result = advanced_app.invoke(advanced_state, config=advanced_config)\n",
    "\n",
    "print(f\"ğŸ“Š Processing history steps: {len(advanced_result.processing_history)}\")\n",
    "print(f\"ğŸ¯ Current task: {advanced_result.current_task}\")\n",
    "print(f\"ğŸ“ Context keys: {list(advanced_result.conversation_context.keys())}\")\n",
    "print(f\"ğŸ’¬ Total messages: {len(advanced_result.messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ› ï¸ Practical Exercises (30 minutes)\n",
    "\n",
    "### Exercise 1: Build a Persistent Task Manager\n",
    "**Goal**: Create an agent that manages a to-do list with SQLite persistence.\n",
    "\n",
    "**Requirements**:\n",
    "- State should track: tasks list, completed tasks, current priority\n",
    "- Implement: add_task, complete_task, list_tasks nodes\n",
    "- Use SQLite for persistence\n",
    "- Handle task priorities (high, medium, low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your implementation here\n",
    "class TaskManagerState(BaseModel):\n",
    "    \"\"\"State for task management system\"\"\"\n",
    "    # TODO: Define your state schema\n",
    "    pass\n",
    "\n",
    "def add_task_node(state: TaskManagerState) -> TaskManagerState:\n",
    "    \"\"\"Add a new task\"\"\"\n",
    "    # TODO: Implement task addition logic\n",
    "    pass\n",
    "\n",
    "def complete_task_node(state: TaskManagerState) -> TaskManagerState:\n",
    "    \"\"\"Mark a task as completed\"\"\"\n",
    "    # TODO: Implement task completion logic\n",
    "    pass\n",
    "\n",
    "# TODO: Create and test your task manager graph\n",
    "print(\"ğŸ“ Exercise 1: Implement your task manager here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Error Recovery System\n",
    "**Goal**: Build a robust system that can recover from various types of failures.\n",
    "\n",
    "**Requirements**:\n",
    "- Create nodes that simulate different error types\n",
    "- Implement recovery strategies for each error type  \n",
    "- Use checkpoints to resume from last good state\n",
    "- Log all recovery attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your implementation here\n",
    "class RobustAgentState(BaseModel):\n",
    "    \"\"\"State for robust error handling system\"\"\"\n",
    "    # TODO: Define your state schema for error tracking\n",
    "    pass\n",
    "\n",
    "def network_operation(state: RobustAgentState) -> RobustAgentState:\n",
    "    \"\"\"Simulate network operation that might fail\"\"\"\n",
    "    # TODO: Implement with potential network errors\n",
    "    pass\n",
    "\n",
    "def data_processing(state: RobustAgentState) -> RobustAgentState:\n",
    "    \"\"\"Simulate data processing that might fail\"\"\"\n",
    "    # TODO: Implement with potential processing errors\n",
    "    pass\n",
    "\n",
    "# TODO: Create your robust error handling graph\n",
    "print(\"ğŸ›¡ï¸ Exercise 2: Implement your error recovery system here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Create a Stateful Conversation Agent\n",
    "**Goal**: Build an advanced conversational agent that maintains context across sessions.\n",
    "\n",
    "**Advanced Requirements**:\n",
    "- Multi-turn conversation with context retention\n",
    "- User preference learning and adaptation\n",
    "- Conversation summarization for long sessions\n",
    "- PostgreSQL persistence for production-ready deployment\n",
    "- Session management with automatic cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Your implementation here\n",
    "class ConversationState(BaseModel):\n",
    "    \"\"\"Advanced conversation state\"\"\"\n",
    "    # TODO: Design comprehensive conversation state\n",
    "    pass\n",
    "\n",
    "# TODO: Implement your advanced conversational agent\n",
    "print(\"ğŸ¯ Challenge: Build your advanced conversation agent here\")\n",
    "print(\"ğŸ’¡ Hint: Consider conversation summarization, user preferences, and session management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“š Solutions and Best Practices\n",
    "\n",
    "### Exercise 1 Solution: Task Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete solution for Exercise 1\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "\n",
    "class Priority(str, Enum):\n",
    "    HIGH = \"high\"\n",
    "    MEDIUM = \"medium\"\n",
    "    LOW = \"low\"\n",
    "\n",
    "class Task(BaseModel):\n",
    "    id: str\n",
    "    title: str\n",
    "    priority: Priority\n",
    "    created_at: str\n",
    "    completed: bool = False\n",
    "\n",
    "class TaskManagerState(BaseModel):\n",
    "    tasks: List[Task] = Field(default_factory=list)\n",
    "    completed_tasks: List[Task] = Field(default_factory=list)\n",
    "    current_priority: Priority = Priority.MEDIUM\n",
    "    last_action: str = \"\"\n",
    "    user_id: str\n",
    "\n",
    "def add_task_node(state: TaskManagerState) -> TaskManagerState:\n",
    "    \"\"\"Add a new task based on the last message\"\"\"\n",
    "    # In a real implementation, you'd parse the task from user input\n",
    "    new_task = Task(\n",
    "        id=f\"task_{len(state.tasks) + 1}\",\n",
    "        title=f\"Sample task {len(state.tasks) + 1}\",\n",
    "        priority=state.current_priority,\n",
    "        created_at=datetime.now().isoformat()\n",
    "    )\n",
    "    \n",
    "    state.tasks.append(new_task)\n",
    "    state.last_action = f\"Added task: {new_task.title}\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def complete_task_node(state: TaskManagerState) -> TaskManagerState:\n",
    "    \"\"\"Complete the first pending task\"\"\"\n",
    "    if state.tasks:\n",
    "        task_to_complete = state.tasks.pop(0)\n",
    "        task_to_complete.completed = True\n",
    "        state.completed_tasks.append(task_to_complete)\n",
    "        state.last_action = f\"Completed task: {task_to_complete.title}\"\n",
    "    else:\n",
    "        state.last_action = \"No tasks to complete\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def list_tasks_node(state: TaskManagerState) -> TaskManagerState:\n",
    "    \"\"\"List current tasks\"\"\"\n",
    "    pending_count = len(state.tasks)\n",
    "    completed_count = len(state.completed_tasks)\n",
    "    \n",
    "    state.last_action = f\"Listed tasks: {pending_count} pending, {completed_count} completed\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Create task manager graph\n",
    "def create_task_manager():\n",
    "    graph = StateGraph(TaskManagerState)\n",
    "    \n",
    "    graph.add_node(\"add_task\", add_task_node)\n",
    "    graph.add_node(\"complete_task\", complete_task_node) \n",
    "    graph.add_node(\"list_tasks\", list_tasks_node)\n",
    "    \n",
    "    # Simple routing - in real app, would parse user intent\n",
    "    graph.add_edge(START, \"add_task\")\n",
    "    graph.add_edge(\"add_task\", \"list_tasks\")\n",
    "    graph.add_edge(\"list_tasks\", END)\n",
    "    \n",
    "    saver = SqliteSaver.from_conn_string(\"task_manager.db\")\n",
    "    return graph.compile(checkpointer=saver)\n",
    "\n",
    "# Test the task manager\n",
    "task_app = create_task_manager()\n",
    "task_state = TaskManagerState(user_id=\"user123\")\n",
    "task_config = {\"configurable\": {\"thread_id\": \"task-session\"}}\n",
    "\n",
    "result = task_app.invoke(task_state, config=task_config)\n",
    "print(f\"âœ… Task Manager Solution: {result.last_action}\")\n",
    "print(f\"ğŸ“‹ Pending tasks: {len(result.tasks)}, Completed: {len(result.completed_tasks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ”§ Troubleshooting Common Issues\n",
    "\n",
    "### Serialization Errors\n",
    "```python\n",
    "# âŒ Common issue: Non-serializable objects in state\n",
    "# Fix: Use Pydantic models or ensure all objects are JSON-serializable\n",
    "\n",
    "# âœ… Good practice\n",
    "class SerializableState(BaseModel):\n",
    "    data: dict  # JSON-serializable\n",
    "    timestamp: str  # Use string instead of datetime\n",
    "```\n",
    "\n",
    "### Database Connection Issues\n",
    "```python\n",
    "# âœ… Always use connection strings properly\n",
    "try:\n",
    "    saver = SqliteSaver.from_conn_string(\"my_app.db\")\n",
    "except Exception as e:\n",
    "    print(f\"Database error: {e}\")\n",
    "    # Fallback to in-memory\n",
    "    saver = InMemorySaver()\n",
    "```\n",
    "\n",
    "### State Schema Changes\n",
    "```python\n",
    "# âœ… Handle schema migrations gracefully\n",
    "def migrate_state(old_state: dict) -> AgentState:\n",
    "    \"\"\"Migrate old state format to new schema\"\"\"\n",
    "    # Add migration logic here\n",
    "    return AgentState(**old_state)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“– Summary and Next Steps\n",
    "\n",
    "### What You've Learned:\n",
    "âœ… **Graph Architecture**: Nodes, edges, and conditional routing  \n",
    "âœ… **State Management**: Pydantic schemas and type safety  \n",
    "âœ… **Persistence**: InMemory, SQLite, and PostgreSQL checkpointers  \n",
    "âœ… **Error Handling**: Recovery patterns and checkpoint resumption  \n",
    "âœ… **Advanced Patterns**: Complex state structures and context awareness  \n",
    "\n",
    "### Best Practices Covered:\n",
    "- Use Pydantic for type-safe state management\n",
    "- Choose appropriate checkpointer for your use case\n",
    "- Implement proper error handling and recovery\n",
    "- Design state schemas for scalability\n",
    "- Use meaningful thread IDs for session management\n",
    "\n",
    "### Tomorrow's Preview (Day 3):\n",
    "ğŸ§  **Memory Systems & Knowledge Management**\n",
    "- Semantic, episodic, and procedural memory\n",
    "- Vector storage with OpenAI embeddings\n",
    "- Cross-session knowledge retention\n",
    "- Memory management tools and strategies\n",
    "\n",
    "### Resources for Further Learning:\n",
    "- [LangGraph Persistence Documentation](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [Checkpointer Reference](https://langchain-ai.github.io/langgraph/reference/checkpoints/)\n",
    "- [State Management Best Practices](https://langchain-ai.github.io/langgraph/how-tos/)\n",
    "\n",
    "**ğŸ¯ You're now ready to build stateful, persistent LangGraph applications!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "print(\"ğŸ§¹ Session complete! Database files created:\")\n",
    "import os\n",
    "db_files = [f for f in os.listdir('.') if f.endswith('.db')]\n",
    "for db_file in db_files:\n",
    "    print(f\"  ğŸ“ {db_file}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Day 2 Complete! You've mastered state management and persistence in LangGraph.\")\n",
    "print(\"ğŸš€ Ready for Day 3: Memory Systems & Knowledge Management\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}