{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: LangGraph Foundations & Type-Safe Development\n",
    "\n",
    "**Duration**: 2 hours (30 min theory + 60 min code + 30 min exercises)\n",
    "\n",
    "Welcome to the LangGraph Multi-Agent Systems Course! Today we'll build a solid foundation in LangGraph development with a focus on type safety using Pydantic.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this session, you will:\n",
    "- Understand multi-agent systems and graph architecture\n",
    "- Set up a complete LangGraph development environment with OpenAI\n",
    "- Implement type-safe agents using Pydantic models\n",
    "- Work with structured outputs and function calling\n",
    "- Build your first LangGraph agent with error handling\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.8+ installed\n",
    "- OpenAI API key\n",
    "- Basic understanding of Python and async programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ“š Part 1: Learning Materials (30 minutes)\n",
    "\n",
    "## Video Resources\n",
    "\n",
    "Before we dive into coding, watch these essential videos:\n",
    "\n",
    "### Core Concepts\n",
    "- **[LangGraph Introduction](https://www.youtube.com/watch?v=hvAPnpSfSGo)** - Official introduction to LangGraph architecture\n",
    "- **[Multi-Agent Systems Explained](https://www.youtube.com/watch?v=lNFGKd7RzVU)** - Understanding agent communication patterns\n",
    "- **[Pydantic for Type Safety](https://www.youtube.com/watch?v=502XOB0u8OY)** - Building robust Python applications\n",
    "\n",
    "### Documentation Links\n",
    "- [LangGraph Official Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/latest/)\n",
    "\n",
    "## Theory: Multi-Agent Systems Introduction\n",
    "\n",
    "### What are Multi-Agent Systems?\n",
    "Multi-agent systems consist of multiple autonomous agents that interact with each other to solve complex problems. Each agent has:\n",
    "- **Autonomy**: Can act independently\n",
    "- **Reactivity**: Responds to environment changes\n",
    "- **Proactivity**: Takes initiative to achieve goals\n",
    "- **Social ability**: Communicates with other agents\n",
    "\n",
    "### Benefits of Multi-Agent Architecture\n",
    "1. **Modularity**: Each agent handles specific tasks\n",
    "2. **Scalability**: Add agents as needed\n",
    "3. **Robustness**: System continues if one agent fails\n",
    "4. **Specialization**: Agents can be expert in specific domains\n",
    "5. **Parallel Processing**: Multiple agents work simultaneously\n",
    "\n",
    "### LangGraph vs Traditional Approaches\n",
    "\n",
    "| Traditional Chains | LangGraph Approach |\n",
    "|-------------------|--------------------|\n",
    "| Linear execution | Graph-based routing |\n",
    "| Fixed flow | Dynamic decision making |\n",
    "| Single agent | Multi-agent coordination |\n",
    "| Limited state | Rich state management |\n",
    "| No cycles | Supports loops and cycles |\n",
    "\n",
    "## Theory: Type Safety with Pydantic\n",
    "\n",
    "### Why Type Safety Matters\n",
    "- **Runtime Safety**: Catch errors before they happen\n",
    "- **Better Developer Experience**: IDE support and autocomplete\n",
    "- **Documentation**: Types serve as living documentation\n",
    "- **Refactoring**: Confident code changes\n",
    "- **Integration**: Better API contracts\n",
    "\n",
    "### Pydantic Benefits for LangGraph\n",
    "1. **Data Validation**: Automatic input/output validation\n",
    "2. **Serialization**: Easy JSON conversion\n",
    "3. **Schema Generation**: Automatic API schemas\n",
    "4. **Type Hints**: Full IDE support\n",
    "5. **Error Handling**: Clear validation error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ’» Part 2: Hands-on Code (60 minutes)\n",
    "\n",
    "## Environment Setup and Dependencies\n",
    "\n",
    "Let's start by installing and configuring everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langgraph langchain-openai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional, Literal\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Pydantic imports for type safety\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LangChain and OpenAI imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel as LangChainBaseModel\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Configuration\n",
    "\n",
    "Set up your OpenAI API key. You can get one from [OpenAI Platform](https://platform.openai.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ OpenAI connection failed: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************-UAA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Please check your API key and internet connection.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Point directly to your project .env (avoids CWD issues)\n",
    "load_dotenv(Path(\"/Users/harshitgulati/Coding Projects/Langraph/.env\"), override=True)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY missing; check .env path and key name\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.1,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    response = llm.invoke([HumanMessage(content=\"Say 'Hello from LangGraph!'\")])\n",
    "    print(f\"âœ… OpenAI connection successful: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ OpenAI connection failed: {e}\")\n",
    "    print(\"Please check your API key and internet connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic Models for Agent State Management\n",
    "\n",
    "Let's create type-safe state models that will form the foundation of our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base state model for all agents\n",
    "class AgentState(BaseModel):\n",
    "    \"\"\"Base state model with common fields for all agents.\"\"\"\n",
    "    \n",
    "    messages: List[Dict[str, str]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Conversation history\"\n",
    "    )\n",
    "    current_task: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Current task being processed\"\n",
    "    )\n",
    "    user_id: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"User identifier for session management\"\n",
    "    )\n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=datetime.now,\n",
    "        description=\"Last update timestamp\"\n",
    "    )\n",
    "    error: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Last error message if any\"\n",
    "    )\n",
    "    \n",
    "    class Config:\n",
    "        # Allow arbitrary types for datetime\n",
    "        arbitrary_types_allowed = True\n",
    "        # Enable validation on assignment\n",
    "        validate_assignment = True\n",
    "\n",
    "\n",
    "# Specialized state for research tasks\n",
    "class ResearchState(AgentState):\n",
    "    \"\"\"Specialized state for research agents.\"\"\"\n",
    "    \n",
    "    research_query: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Current research query\"\n",
    "    )\n",
    "    findings: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Research findings collected\"\n",
    "    )\n",
    "    sources: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Source URLs or references\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        default=0.0,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Confidence score (0-1)\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Test the models\n",
    "print(\"Testing Pydantic models...\")\n",
    "\n",
    "# Create a basic state\n",
    "basic_state = AgentState(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    current_task=\"greeting\",\n",
    "    user_id=\"user123\"\n",
    ")\n",
    "print(f\"âœ… Basic state: {basic_state.current_task}\")\n",
    "\n",
    "# Create a research state\n",
    "research_state = ResearchState(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Research AI trends\"}],\n",
    "    research_query=\"Latest AI trends 2024\",\n",
    "    confidence=0.8\n",
    ")\n",
    "print(f\"âœ… Research state: {research_state.research_query}\")\n",
    "\n",
    "# Test validation\n",
    "try:\n",
    "    invalid_state = ResearchState(confidence=1.5)  # Should fail\n",
    "except ValidationError as e:\n",
    "    print(f\"âœ… Validation working: {e.errors()[0]['msg']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output with OpenAI Function Calling\n",
    "\n",
    "Let's implement structured outputs using OpenAI's function calling capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structured output schemas\n",
    "class WeatherInfo(BaseModel):\n",
    "    \"\"\"Structured weather information.\"\"\"\n",
    "    \n",
    "    location: str = Field(description=\"City and country\")\n",
    "    temperature: float = Field(description=\"Temperature in Celsius\")\n",
    "    condition: str = Field(description=\"Weather condition\")\n",
    "    humidity: int = Field(ge=0, le=100, description=\"Humidity percentage\")\n",
    "    recommendation: str = Field(description=\"Clothing recommendation\")\n",
    "\n",
    "\n",
    "class TaskAnalysis(BaseModel):\n",
    "    \"\"\"Structured task analysis.\"\"\"\n",
    "    \n",
    "    task_type: Literal[\"research\", \"coding\", \"writing\", \"analysis\", \"other\"] = Field(\n",
    "        description=\"Type of task identified\"\n",
    "    )\n",
    "    complexity: Literal[\"low\", \"medium\", \"high\"] = Field(\n",
    "        description=\"Task complexity level\"\n",
    "    )\n",
    "    estimated_time: int = Field(\n",
    "        ge=1,\n",
    "        description=\"Estimated time in minutes\"\n",
    "    )\n",
    "    required_tools: List[str] = Field(\n",
    "        description=\"List of tools needed\"\n",
    "    )\n",
    "    steps: List[str] = Field(\n",
    "        description=\"Breakdown of task steps\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to get structured weather (simulated)\n",
    "@tool\n",
    "def get_weather_structured(location: str) -> WeatherInfo:\n",
    "    \"\"\"Get structured weather information for a location.\"\"\"\n",
    "    # Simulated weather data\n",
    "    weather_data = {\n",
    "        \"new york\": {\"temp\": 15, \"condition\": \"Cloudy\", \"humidity\": 65},\n",
    "        \"london\": {\"temp\": 8, \"condition\": \"Rainy\", \"humidity\": 80},\n",
    "        \"tokyo\": {\"temp\": 22, \"condition\": \"Sunny\", \"humidity\": 45},\n",
    "        \"sydney\": {\"temp\": 25, \"condition\": \"Partly Cloudy\", \"humidity\": 55}\n",
    "    }\n",
    "    \n",
    "    city_key = location.lower()\n",
    "    if city_key in weather_data:\n",
    "        data = weather_data[city_key]\n",
    "        return WeatherInfo(\n",
    "            location=location.title(),\n",
    "            temperature=data[\"temp\"],\n",
    "            condition=data[\"condition\"],\n",
    "            humidity=data[\"humidity\"],\n",
    "            recommendation=f\"Dress for {data['condition'].lower()} weather at {data['temp']}Â°C\"\n",
    "        )\n",
    "    else:\n",
    "        return WeatherInfo(\n",
    "            location=location,\n",
    "            temperature=20,\n",
    "            condition=\"Unknown\",\n",
    "            humidity=50,\n",
    "            recommendation=\"Check local weather sources\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Function for task analysis using LLM\n",
    "async def analyze_task_structured(task_description: str) -> TaskAnalysis:\n",
    "    \"\"\"Analyze a task and return structured information.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following task and provide structured information:\n",
    "    \n",
    "    Task: {task_description}\n",
    "    \n",
    "    Please analyze:\n",
    "    1. What type of task this is\n",
    "    2. The complexity level\n",
    "    3. Estimated time needed\n",
    "    4. What tools might be required\n",
    "    5. Step-by-step breakdown\n",
    "    \n",
    "    Respond in JSON format matching the TaskAnalysis schema.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        # Parse the LLM response into structured format\n",
    "        # For demo purposes, we'll create a structured response\n",
    "        if \"research\" in task_description.lower():\n",
    "            return TaskAnalysis(\n",
    "                task_type=\"research\",\n",
    "                complexity=\"medium\",\n",
    "                estimated_time=30,\n",
    "                required_tools=[\"web_search\", \"summarizer\"],\n",
    "                steps=[\n",
    "                    \"Define research scope\",\n",
    "                    \"Search for relevant sources\",\n",
    "                    \"Analyze findings\",\n",
    "                    \"Synthesize conclusions\"\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            return TaskAnalysis(\n",
    "                task_type=\"other\",\n",
    "                complexity=\"low\",\n",
    "                estimated_time=15,\n",
    "                required_tools=[\"basic_tools\"],\n",
    "                steps=[\"Understand requirements\", \"Execute task\", \"Verify results\"]\n",
    "            )\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in task analysis: {e}\")\n",
    "        return TaskAnalysis(\n",
    "            task_type=\"other\",\n",
    "            complexity=\"unknown\",\n",
    "            estimated_time=0,\n",
    "            required_tools=[],\n",
    "            steps=[]\n",
    "        )\n",
    "\n",
    "\n",
    "# Test structured outputs\n",
    "print(\"Testing structured outputs...\")\n",
    "\n",
    "# Test weather function\n",
    "weather = get_weather_structured(\"New York\")\n",
    "print(f\"âœ… Weather for {weather.location}: {weather.temperature}Â°C, {weather.condition}\")\n",
    "print(f\"   Recommendation: {weather.recommendation}\")\n",
    "\n",
    "# Test task analysis\n",
    "task_analysis = await analyze_task_structured(\"Research the latest AI developments\")\n",
    "print(f\"âœ… Task analysis: {task_analysis.task_type} task, {task_analysis.complexity} complexity\")\n",
    "print(f\"   Estimated time: {task_analysis.estimated_time} minutes\")\n",
    "print(f\"   Steps: {', '.join(task_analysis.steps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Type-Safe Agent with GPT-4\n",
    "\n",
    "Now let's build our first complete LangGraph agent with type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced agent state for our first agent\n",
    "class AssistantState(AgentState):\n",
    "    \"\"\"State for our AI assistant agent.\"\"\"\n",
    "    \n",
    "    intent: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Detected user intent\"\n",
    "    )\n",
    "    response: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Agent's response\"\n",
    "    )\n",
    "    tools_used: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Tools used in this interaction\"\n",
    "    )\n",
    "    confidence_score: float = Field(\n",
    "        default=0.0,\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"Confidence in the response\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Agent functions with proper error handling\n",
    "async def intent_classifier(state: AssistantState) -> AssistantState:\n",
    "    \"\"\"Classify user intent from the last message.\"\"\"\n",
    "    try:\n",
    "        if not state.messages:\n",
    "            return state\n",
    "        \n",
    "        last_message = state.messages[-1]\n",
    "        user_input = last_message.get(\"content\", \"\")\n",
    "        \n",
    "        # Simple intent classification\n",
    "        intent_prompt = f\"\"\"\n",
    "        Classify the intent of this user message into one of these categories:\n",
    "        - weather: asking about weather\n",
    "        - task_analysis: asking to analyze a task\n",
    "        - greeting: saying hello or greeting\n",
    "        - question: asking a general question\n",
    "        - other: anything else\n",
    "        \n",
    "        User message: {user_input}\n",
    "        \n",
    "        Respond with just the category name.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await llm.ainvoke([HumanMessage(content=intent_prompt)])\n",
    "        intent = response.content.strip().lower()\n",
    "        \n",
    "        # Update state\n",
    "        state.intent = intent\n",
    "        state.timestamp = datetime.now()\n",
    "        \n",
    "        print(f\"ðŸŽ¯ Intent classified: {intent}\")\n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        state.error = f\"Intent classification error: {str(e)}\"\n",
    "        state.intent = \"error\"\n",
    "        print(f\"âŒ Intent classification failed: {e}\")\n",
    "        return state\n",
    "\n",
    "\n",
    "async def response_generator(state: AssistantState) -> AssistantState:\n",
    "    \"\"\"Generate appropriate response based on intent.\"\"\"\n",
    "    try:\n",
    "        user_input = state.messages[-1].get(\"content\", \"\") if state.messages else \"\"\n",
    "        \n",
    "        if state.intent == \"weather\":\n",
    "            # Extract location and get weather\n",
    "            location_prompt = f\"\"\"\n",
    "            Extract the location from this weather request. If no specific location is mentioned, use 'New York'.\n",
    "            Request: {user_input}\n",
    "            Respond with just the city name.\n",
    "            \"\"\"\n",
    "            \n",
    "            location_response = await llm.ainvoke([HumanMessage(content=location_prompt)])\n",
    "            location = location_response.content.strip()\n",
    "            \n",
    "            weather_info = get_weather_structured(location)\n",
    "            state.tools_used.append(\"weather_tool\")\n",
    "            \n",
    "            response = f\"\"\"\n",
    "            ðŸŒ¤ï¸ Weather in {weather_info.location}:\n",
    "            Temperature: {weather_info.temperature}Â°C\n",
    "            Condition: {weather_info.condition}\n",
    "            Humidity: {weather_info.humidity}%\n",
    "            \n",
    "            ðŸ’¡ Recommendation: {weather_info.recommendation}\n",
    "            \"\"\"\n",
    "            state.confidence_score = 0.9\n",
    "            \n",
    "        elif state.intent == \"task_analysis\":\n",
    "            task_info = await analyze_task_structured(user_input)\n",
    "            state.tools_used.append(\"task_analyzer\")\n",
    "            \n",
    "            response = f\"\"\"\n",
    "            ðŸ“‹ Task Analysis:\n",
    "            Type: {task_info.task_type.title()}\n",
    "            Complexity: {task_info.complexity.title()}\n",
    "            Estimated Time: {task_info.estimated_time} minutes\n",
    "            \n",
    "            ðŸ› ï¸ Required Tools: {', '.join(task_info.required_tools)}\n",
    "            \n",
    "            ðŸ“ Steps:\n",
    "            {chr(10).join([f\"{i+1}. {step}\" for i, step in enumerate(task_info.steps)])}\n",
    "            \"\"\"\n",
    "            state.confidence_score = 0.8\n",
    "            \n",
    "        elif state.intent == \"greeting\":\n",
    "            response = \"Hello! I'm your AI assistant. I can help you with weather information, task analysis, and answer various questions. How can I assist you today?\"\n",
    "            state.confidence_score = 1.0\n",
    "            \n",
    "        else:\n",
    "            # General response using LLM\n",
    "            general_prompt = f\"\"\"\n",
    "            You are a helpful AI assistant. Respond to this user message in a friendly and helpful way:\n",
    "            \n",
    "            User: {user_input}\n",
    "            \n",
    "            Keep your response concise but informative.\n",
    "            \"\"\"\n",
    "            \n",
    "            llm_response = await llm.ainvoke([HumanMessage(content=general_prompt)])\n",
    "            response = llm_response.content\n",
    "            state.confidence_score = 0.7\n",
    "        \n",
    "        # Update state\n",
    "        state.response = response.strip()\n",
    "        state.messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": state.response\n",
    "        })\n",
    "        state.timestamp = datetime.now()\n",
    "        \n",
    "        print(f\"âœ¨ Response generated (confidence: {state.confidence_score})\")\n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        state.error = f\"Response generation error: {str(e)}\"\n",
    "        state.response = \"I apologize, but I encountered an error while processing your request. Please try again.\"\n",
    "        state.confidence_score = 0.0\n",
    "        print(f\"âŒ Response generation failed: {e}\")\n",
    "        return state\n",
    "\n",
    "\n",
    "# Build the LangGraph\n",
    "def create_assistant_graph():\n",
    "    \"\"\"Create the assistant graph with proper error handling.\"\"\"\n",
    "    \n",
    "    # Create the graph\n",
    "    workflow = StateGraph(AssistantState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"classify_intent\", intent_classifier)\n",
    "    workflow.add_node(\"generate_response\", response_generator)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"classify_intent\")\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(\"classify_intent\", \"generate_response\")\n",
    "    workflow.add_edge(\"generate_response\", END)\n",
    "    \n",
    "    # Compile the graph\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# Test the agent\n",
    "print(\"Creating AI Assistant Agent...\")\n",
    "assistant_graph = create_assistant_graph()\n",
    "\n",
    "# Test with different types of input\n",
    "test_messages = [\n",
    "    \"Hello! Nice to meet you.\",\n",
    "    \"What's the weather like in London?\",\n",
    "    \"I need to analyze this task: Create a data dashboard for sales metrics\"\n",
    "]\n",
    "\n",
    "for i, message in enumerate(test_messages, 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Test {i}: {message}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create initial state\n",
    "    initial_state = AssistantState(\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        user_id=f\"test_user_{i}\"\n",
    "    )\n",
    "    \n",
    "    # Run the agent\n",
    "    try:\n",
    "        result = await assistant_graph.ainvoke(initial_state)\n",
    "        \n",
    "        print(f\"Intent: {result.intent}\")\n",
    "        print(f\"Tools Used: {result.tools_used}\")\n",
    "        print(f\"Confidence: {result.confidence_score}\")\n",
    "        print(f\"\\nResponse:\\n{result.response}\")\n",
    "        \n",
    "        if result.error:\n",
    "            print(f\"âŒ Error: {result.error}\")\n",
    "        else:\n",
    "            print(\"âœ… Success!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Agent execution failed: {e}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ First LangGraph agent complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling with Pydantic Schemas\n",
    "\n",
    "Let's explore advanced function calling patterns with proper type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Pydantic schemas for function calling\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"Schema for search queries.\"\"\"\n",
    "    \n",
    "    query: str = Field(description=\"The search query\")\n",
    "    max_results: int = Field(default=5, ge=1, le=20, description=\"Maximum number of results\")\n",
    "    category: Optional[Literal[\"news\", \"academic\", \"general\", \"images\"]] = Field(\n",
    "        default=\"general\",\n",
    "        description=\"Search category\"\n",
    "    )\n",
    "    language: str = Field(default=\"en\", description=\"Language code\")\n",
    "\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    \"\"\"Schema for search results.\"\"\"\n",
    "    \n",
    "    title: str = Field(description=\"Result title\")\n",
    "    url: str = Field(description=\"Result URL\")\n",
    "    snippet: str = Field(description=\"Result snippet\")\n",
    "    relevance_score: float = Field(ge=0.0, le=1.0, description=\"Relevance score\")\n",
    "    source: str = Field(description=\"Source domain\")\n",
    "\n",
    "\n",
    "class SearchResponse(BaseModel):\n",
    "    \"\"\"Schema for complete search response.\"\"\"\n",
    "    \n",
    "    query: str = Field(description=\"Original query\")\n",
    "    total_results: int = Field(description=\"Total number of results found\")\n",
    "    results: List[SearchResult] = Field(description=\"List of search results\")\n",
    "    search_time: float = Field(description=\"Search time in seconds\")\n",
    "    suggestions: List[str] = Field(default_factory=list, description=\"Query suggestions\")\n",
    "\n",
    "\n",
    "class CalculationRequest(BaseModel):\n",
    "    \"\"\"Schema for calculation requests.\"\"\"\n",
    "    \n",
    "    expression: str = Field(description=\"Mathematical expression to evaluate\")\n",
    "    precision: int = Field(default=2, ge=0, le=10, description=\"Decimal precision\")\n",
    "    unit: Optional[str] = Field(default=None, description=\"Unit of measurement\")\n",
    "\n",
    "\n",
    "class CalculationResult(BaseModel):\n",
    "    \"\"\"Schema for calculation results.\"\"\"\n",
    "    \n",
    "    expression: str = Field(description=\"Original expression\")\n",
    "    result: float = Field(description=\"Calculation result\")\n",
    "    formatted_result: str = Field(description=\"Formatted result with unit\")\n",
    "    steps: List[str] = Field(default_factory=list, description=\"Calculation steps\")\n",
    "    error: Optional[str] = Field(default=None, description=\"Error message if any\")\n",
    "\n",
    "\n",
    "# Type-safe function implementations\n",
    "@tool\n",
    "def search_web(query_data: SearchQuery) -> SearchResponse:\n",
    "    \"\"\"Simulate web search with structured input/output.\"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Simulated search results\n",
    "    mock_results = [\n",
    "        SearchResult(\n",
    "            title=f\"Result for '{query_data.query}' - Article {i+1}\",\n",
    "            url=f\"https://example{i+1}.com/article\",\n",
    "            snippet=f\"This is a relevant snippet about {query_data.query} from a reliable source.\",\n",
    "            relevance_score=round(random.uniform(0.6, 1.0), 2),\n",
    "            source=f\"example{i+1}.com\"\n",
    "        )\n",
    "        for i in range(min(query_data.max_results, 3))\n",
    "    ]\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    return SearchResponse(\n",
    "        query=query_data.query,\n",
    "        total_results=len(mock_results) * 10,  # Simulate more total results\n",
    "        results=mock_results,\n",
    "        search_time=round(search_time, 3),\n",
    "        suggestions=[f\"{query_data.query} tutorial\", f\"{query_data.query} examples\"]\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_math(calc_request: CalculationRequest) -> CalculationResult:\n",
    "    \"\"\"Perform mathematical calculations with error handling.\"\"\"\n",
    "    import re\n",
    "    import math\n",
    "    \n",
    "    try:\n",
    "        # Simple expression evaluation (safe subset)\n",
    "        expression = calc_request.expression.strip()\n",
    "        \n",
    "        # Allow only safe mathematical operations\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            raise ValueError(\"Expression contains invalid characters\")\n",
    "        \n",
    "        # Evaluate safely\n",
    "        result = eval(expression)\n",
    "        \n",
    "        # Format result\n",
    "        formatted = f\"{result:.{calc_request.precision}f}\"\n",
    "        if calc_request.unit:\n",
    "            formatted += f\" {calc_request.unit}\"\n",
    "        \n",
    "        return CalculationResult(\n",
    "            expression=expression,\n",
    "            result=float(result),\n",
    "            formatted_result=formatted,\n",
    "            steps=[f\"Evaluating: {expression}\", f\"Result: {result}\"]\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        return CalculationResult(\n",
    "            expression=calc_request.expression,\n",
    "            result=0.0,\n",
    "            formatted_result=\"Error\",\n",
    "            error=str(e)\n",
    "        )\n",
    "\n",
    "\n",
    "# Enhanced agent state for function calling\n",
    "class FunctionCallingState(AgentState):\n",
    "    \"\"\"State for agents with function calling capabilities.\"\"\"\n",
    "    \n",
    "    available_functions: List[str] = Field(\n",
    "        default_factory=lambda: [\"search_web\", \"calculate_math\", \"get_weather_structured\"],\n",
    "        description=\"Available function tools\"\n",
    "    )\n",
    "    function_calls: List[Dict[str, Any]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"History of function calls made\"\n",
    "    )\n",
    "    results: List[Dict[str, Any]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Function call results\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Test the type-safe function calling\n",
    "print(\"Testing type-safe function calling...\")\n",
    "\n",
    "# Test search function\n",
    "search_query = SearchQuery(\n",
    "    query=\"LangGraph tutorials\",\n",
    "    max_results=3,\n",
    "    category=\"general\"\n",
    ")\n",
    "\n",
    "search_result = search_web(search_query)\n",
    "print(f\"âœ… Search completed in {search_result.search_time}s\")\n",
    "print(f\"   Found {search_result.total_results} total results\")\n",
    "print(f\"   Top result: {search_result.results[0].title}\")\n",
    "\n",
    "# Test calculation function\n",
    "calc_request = CalculationRequest(\n",
    "    expression=\"(25 + 75) * 0.15\",\n",
    "    precision=2,\n",
    "    unit=\"USD\"\n",
    ")\n",
    "\n",
    "calc_result = calculate_math(calc_request)\n",
    "print(f\"âœ… Calculation: {calc_result.expression} = {calc_result.formatted_result}\")\n",
    "if calc_result.error:\n",
    "    print(f\"   Error: {calc_result.error}\")\n",
    "\n",
    "# Test validation errors\n",
    "try:\n",
    "    invalid_search = SearchQuery(query=\"test\", max_results=25)  # Should fail\n",
    "except ValidationError as e:\n",
    "    print(f\"âœ… Validation caught error: {e.errors()[0]['msg']}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Function calling with Pydantic schemas complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸš€ Part 3: Practical Exercises (30 minutes)\n",
    "\n",
    "Now it's time to put your knowledge to practice! Complete these exercises to reinforce your learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Weather Agent with Structured Responses\n",
    "\n",
    "**Objective**: Build a weather agent that can handle multiple cities and provide detailed forecasts.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a `WeatherForecast` Pydantic model with 3-day forecast\n",
    "2. Implement a function that takes multiple cities\n",
    "3. Add weather alerts and recommendations\n",
    "4. Include proper error handling\n",
    "\n",
    "**Starter Code**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your turn to implement!\n",
    "from typing import List, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class DayForecast(BaseModel):\n",
    "    \"\"\"Single day weather forecast.\"\"\"\n",
    "    # TODO: Add fields for date, temperature (high/low), condition, chance of rain\n",
    "    pass\n",
    "\n",
    "class WeatherAlert(BaseModel):\n",
    "    \"\"\"Weather alert information.\"\"\"\n",
    "    # TODO: Add fields for alert type, severity, description\n",
    "    pass\n",
    "\n",
    "class WeatherForecast(BaseModel):\n",
    "    \"\"\"Multi-day weather forecast.\"\"\"\n",
    "    # TODO: Add fields for location, current weather, 3-day forecast, alerts\n",
    "    pass\n",
    "\n",
    "@tool\n",
    "def get_multi_city_weather(cities: List[str]) -> List[WeatherForecast]:\n",
    "    \"\"\"Get weather forecasts for multiple cities.\"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# weather_forecasts = get_multi_city_weather([\"New York\", \"London\", \"Tokyo\"])\n",
    "# for forecast in weather_forecasts:\n",
    "#     print(f\"Weather in {forecast.location}:\")\n",
    "#     # TODO: Print forecast details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "class DayForecast(BaseModel):\n",
    "    \"\"\"Single day weather forecast.\"\"\"\n",
    "    date: datetime = Field(description=\"Forecast date\")\n",
    "    high_temp: float = Field(description=\"High temperature in Celsius\")\n",
    "    low_temp: float = Field(description=\"Low temperature in Celsius\")\n",
    "    condition: str = Field(description=\"Weather condition\")\n",
    "    rain_chance: int = Field(ge=0, le=100, description=\"Chance of rain percentage\")\n",
    "    wind_speed: float = Field(ge=0, description=\"Wind speed in km/h\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "class WeatherAlert(BaseModel):\n",
    "    \"\"\"Weather alert information.\"\"\"\n",
    "    alert_type: Literal[\"storm\", \"heat\", \"cold\", \"wind\", \"flood\"] = Field(\n",
    "        description=\"Type of weather alert\"\n",
    "    )\n",
    "    severity: Literal[\"low\", \"moderate\", \"high\", \"extreme\"] = Field(\n",
    "        description=\"Alert severity level\"\n",
    "    )\n",
    "    description: str = Field(description=\"Alert description\")\n",
    "    start_time: datetime = Field(description=\"Alert start time\")\n",
    "    end_time: datetime = Field(description=\"Alert end time\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "class WeatherForecast(BaseModel):\n",
    "    \"\"\"Multi-day weather forecast.\"\"\"\n",
    "    location: str = Field(description=\"City and country\")\n",
    "    current_temp: float = Field(description=\"Current temperature\")\n",
    "    current_condition: str = Field(description=\"Current weather condition\")\n",
    "    forecast_days: List[DayForecast] = Field(description=\"3-day forecast\")\n",
    "    alerts: List[WeatherAlert] = Field(default_factory=list, description=\"Active weather alerts\")\n",
    "    recommendations: List[str] = Field(description=\"Weather-based recommendations\")\n",
    "    last_updated: datetime = Field(default_factory=datetime.now, description=\"Last update time\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_multi_city_weather(cities: List[str]) -> List[WeatherForecast]:\n",
    "    \"\"\"Get weather forecasts for multiple cities.\"\"\"\n",
    "    forecasts = []\n",
    "    \n",
    "    for city in cities:\n",
    "        try:\n",
    "            # Generate mock forecast data\n",
    "            base_temp = random.randint(5, 30)\n",
    "            conditions = [\"Sunny\", \"Cloudy\", \"Rainy\", \"Partly Cloudy\", \"Stormy\"]\n",
    "            \n",
    "            # Create 3-day forecast\n",
    "            forecast_days = []\n",
    "            for i in range(3):\n",
    "                date = datetime.now() + timedelta(days=i)\n",
    "                temp_variation = random.randint(-5, 5)\n",
    "                \n",
    "                day_forecast = DayForecast(\n",
    "                    date=date,\n",
    "                    high_temp=base_temp + temp_variation + 3,\n",
    "                    low_temp=base_temp + temp_variation - 3,\n",
    "                    condition=random.choice(conditions),\n",
    "                    rain_chance=random.randint(0, 80),\n",
    "                    wind_speed=random.uniform(5, 25)\n",
    "                )\n",
    "                forecast_days.append(day_forecast)\n",
    "            \n",
    "            # Generate alerts (sometimes)\n",
    "            alerts = []\n",
    "            if random.random() < 0.3:  # 30% chance of alert\n",
    "                alert = WeatherAlert(\n",
    "                    alert_type=\"storm\",\n",
    "                    severity=\"moderate\",\n",
    "                    description=\"Thunderstorms expected in the evening\",\n",
    "                    start_time=datetime.now() + timedelta(hours=6),\n",
    "                    end_time=datetime.now() + timedelta(hours=12)\n",
    "                )\n",
    "                alerts.append(alert)\n",
    "            \n",
    "            # Generate recommendations\n",
    "            recommendations = [\n",
    "                f\"Current temperature is {base_temp}Â°C - dress accordingly\",\n",
    "                \"Check rain forecast before outdoor activities\",\n",
    "                \"UV protection recommended during sunny periods\"\n",
    "            ]\n",
    "            \n",
    "            forecast = WeatherForecast(\n",
    "                location=city,\n",
    "                current_temp=base_temp,\n",
    "                current_condition=random.choice(conditions),\n",
    "                forecast_days=forecast_days,\n",
    "                alerts=alerts,\n",
    "                recommendations=recommendations\n",
    "            )\n",
    "            \n",
    "            forecasts.append(forecast)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting weather for {city}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return forecasts\n",
    "\n",
    "\n",
    "# Test the implementation\n",
    "print(\"Testing multi-city weather forecast...\")\n",
    "weather_forecasts = get_multi_city_weather([\"New York\", \"London\", \"Tokyo\"])\n",
    "\n",
    "for forecast in weather_forecasts:\n",
    "    print(f\"\\nðŸŒ¤ï¸ Weather in {forecast.location}:\")\n",
    "    print(f\"Current: {forecast.current_temp}Â°C, {forecast.current_condition}\")\n",
    "    \n",
    "    print(f\"\\n3-Day Forecast:\")\n",
    "    for day in forecast.forecast_days:\n",
    "        print(f\"  {day.date.strftime('%Y-%m-%d')}: {day.high_temp}Â°C/{day.low_temp}Â°C, {day.condition} ({day.rain_chance}% rain)\")\n",
    "    \n",
    "    if forecast.alerts:\n",
    "        print(f\"\\nâš ï¸ Alerts:\")\n",
    "        for alert in forecast.alerts:\n",
    "            print(f\"  {alert.severity.upper()} {alert.alert_type}: {alert.description}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ Recommendations:\")\n",
    "    for rec in forecast.recommendations:\n",
    "        print(f\"  â€¢ {rec}\")\n",
    "\n",
    "print(\"\\nâœ… Exercise 1 complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Type-Safe Research Agent\n",
    "\n",
    "**Objective**: Build a research agent that can gather, analyze, and synthesize information with proper type safety.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a `ResearchPaper` Pydantic model\n",
    "2. Implement search and analysis functions\n",
    "3. Add citation management\n",
    "4. Create a synthesis function that combines findings\n",
    "\n",
    "**Starter Code**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your turn to implement!\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    \"\"\"Research citation information.\"\"\"\n",
    "    # TODO: Add fields for author, title, journal, year, url\n",
    "    pass\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "    \"\"\"Research paper information.\"\"\"\n",
    "    # TODO: Add fields for title, abstract, key_findings, citations, relevance_score\n",
    "    pass\n",
    "\n",
    "class ResearchSynthesis(BaseModel):\n",
    "    \"\"\"Synthesized research findings.\"\"\"\n",
    "    # TODO: Add fields for topic, key_themes, conclusions, recommendations, sources\n",
    "    pass\n",
    "\n",
    "@tool\n",
    "def search_research_papers(topic: str, max_papers: int = 5) -> List[ResearchPaper]:\n",
    "    \"\"\"Search for research papers on a topic.\"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "@tool\n",
    "def synthesize_research(papers: List[ResearchPaper], research_question: str) -> ResearchSynthesis:\n",
    "    \"\"\"Synthesize findings from multiple papers.\"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# papers = search_research_papers(\"artificial intelligence ethics\")\n",
    "# synthesis = synthesize_research(papers, \"What are the main ethical concerns in AI?\")\n",
    "# print(synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    \"\"\"Research citation information.\"\"\"\n",
    "    authors: List[str] = Field(description=\"List of authors\")\n",
    "    title: str = Field(description=\"Paper title\")\n",
    "    journal: str = Field(description=\"Journal or conference name\")\n",
    "    year: int = Field(ge=1900, le=2024, description=\"Publication year\")\n",
    "    url: Optional[str] = Field(default=None, description=\"Paper URL\")\n",
    "    doi: Optional[str] = Field(default=None, description=\"Digital Object Identifier\")\n",
    "\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "    \"\"\"Research paper information.\"\"\"\n",
    "    title: str = Field(description=\"Paper title\")\n",
    "    abstract: str = Field(description=\"Paper abstract\")\n",
    "    key_findings: List[str] = Field(description=\"Main findings or contributions\")\n",
    "    citation: Citation = Field(description=\"Citation information\")\n",
    "    relevance_score: float = Field(ge=0.0, le=1.0, description=\"Relevance to search query\")\n",
    "    keywords: List[str] = Field(description=\"Paper keywords\")\n",
    "    methodology: Optional[str] = Field(default=None, description=\"Research methodology\")\n",
    "\n",
    "\n",
    "class ResearchSynthesis(BaseModel):\n",
    "    \"\"\"Synthesized research findings.\"\"\"\n",
    "    topic: str = Field(description=\"Research topic\")\n",
    "    research_question: str = Field(description=\"Original research question\")\n",
    "    key_themes: List[str] = Field(description=\"Main themes identified\")\n",
    "    conclusions: List[str] = Field(description=\"Key conclusions\")\n",
    "    recommendations: List[str] = Field(description=\"Recommendations for future work\")\n",
    "    sources_analyzed: int = Field(description=\"Number of sources analyzed\")\n",
    "    confidence_level: float = Field(ge=0.0, le=1.0, description=\"Confidence in synthesis\")\n",
    "    limitations: List[str] = Field(description=\"Limitations of the analysis\")\n",
    "    created_at: datetime = Field(default_factory=datetime.now, description=\"Synthesis creation time\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_research_papers(topic: str, max_papers: int = 5) -> List[ResearchPaper]:\n",
    "    \"\"\"Search for research papers on a topic.\"\"\"\n",
    "    # Mock research papers for demonstration\n",
    "    mock_papers_data = {\n",
    "        \"artificial intelligence ethics\": [\n",
    "            {\n",
    "                \"title\": \"Ethical Considerations in AI Development\",\n",
    "                \"abstract\": \"This paper examines the ethical implications of artificial intelligence development and deployment in modern society.\",\n",
    "                \"key_findings\": [\n",
    "                    \"Bias in AI systems can perpetuate social inequalities\",\n",
    "                    \"Transparency in AI decision-making is crucial for accountability\",\n",
    "                    \"Privacy concerns arise from extensive data collection\"\n",
    "                ],\n",
    "                \"authors\": [\"Smith, J.\", \"Johnson, A.\"],\n",
    "                \"journal\": \"Journal of AI Ethics\",\n",
    "                \"year\": 2023,\n",
    "                \"keywords\": [\"ethics\", \"artificial intelligence\", \"bias\", \"transparency\"]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Fairness in Machine Learning Algorithms\",\n",
    "                \"abstract\": \"An analysis of fairness metrics and bias mitigation techniques in machine learning systems.\",\n",
    "                \"key_findings\": [\n",
    "                    \"Multiple fairness definitions can conflict with each other\",\n",
    "                    \"Bias mitigation requires ongoing monitoring and adjustment\",\n",
    "                    \"Stakeholder involvement is essential for defining fairness\"\n",
    "                ],\n",
    "                \"authors\": [\"Brown, M.\", \"Davis, K.\", \"Wilson, R.\"],\n",
    "                \"journal\": \"Machine Learning Conference 2023\",\n",
    "                \"year\": 2023,\n",
    "                \"keywords\": [\"fairness\", \"machine learning\", \"bias mitigation\", \"algorithms\"]\n",
    "            }\n",
    "        ],\n",
    "        \"climate change\": [\n",
    "            {\n",
    "                \"title\": \"Global Temperature Trends and Climate Modeling\",\n",
    "                \"abstract\": \"Comprehensive analysis of global temperature data and climate model predictions for the next century.\",\n",
    "                \"key_findings\": [\n",
    "                    \"Global temperatures have risen by 1.1Â°C since pre-industrial times\",\n",
    "                    \"Climate models show continued warming under current emission scenarios\",\n",
    "                    \"Arctic regions are warming faster than global average\"\n",
    "                ],\n",
    "                \"authors\": [\"Climate, R.\", \"Hansen, J.\"],\n",
    "                \"journal\": \"Nature Climate Change\",\n",
    "                \"year\": 2023,\n",
    "                \"keywords\": [\"climate change\", \"temperature\", \"modeling\", \"global warming\"]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    papers = []\n",
    "    topic_key = topic.lower()\n",
    "    \n",
    "    # Find matching papers\n",
    "    for key, paper_list in mock_papers_data.items():\n",
    "        if any(word in topic_key for word in key.split()):\n",
    "            for paper_data in paper_list[:max_papers]:\n",
    "                citation = Citation(\n",
    "                    authors=paper_data[\"authors\"],\n",
    "                    title=paper_data[\"title\"],\n",
    "                    journal=paper_data[\"journal\"],\n",
    "                    year=paper_data[\"year\"],\n",
    "                    url=f\"https://example.com/papers/{paper_data['title'].replace(' ', '_').lower()}\",\n",
    "                    doi=f\"10.1000/example.{random.randint(1000, 9999)}\"\n",
    "                )\n",
    "                \n",
    "                paper = ResearchPaper(\n",
    "                    title=paper_data[\"title\"],\n",
    "                    abstract=paper_data[\"abstract\"],\n",
    "                    key_findings=paper_data[\"key_findings\"],\n",
    "                    citation=citation,\n",
    "                    relevance_score=random.uniform(0.7, 1.0),\n",
    "                    keywords=paper_data[\"keywords\"],\n",
    "                    methodology=\"Quantitative analysis with statistical modeling\"\n",
    "                )\n",
    "                papers.append(paper)\n",
    "    \n",
    "    # If no specific papers found, create generic ones\n",
    "    if not papers:\n",
    "        for i in range(min(max_papers, 2)):\n",
    "            citation = Citation(\n",
    "                authors=[f\"Author{i+1}, X.\", f\"Researcher{i+1}, Y.\"],\n",
    "                title=f\"Research on {topic.title()} - Study {i+1}\",\n",
    "                journal=\"Generic Research Journal\",\n",
    "                year=2023,\n",
    "                url=f\"https://example.com/generic_{i+1}\"\n",
    "            )\n",
    "            \n",
    "            paper = ResearchPaper(\n",
    "                title=f\"Research on {topic.title()} - Study {i+1}\",\n",
    "                abstract=f\"This study investigates various aspects of {topic} and provides insights into current trends and future directions.\",\n",
    "                key_findings=[\n",
    "                    f\"Key finding 1 about {topic}\",\n",
    "                    f\"Important observation regarding {topic}\",\n",
    "                    f\"Future implications for {topic} research\"\n",
    "                ],\n",
    "                citation=citation,\n",
    "                relevance_score=random.uniform(0.6, 0.9),\n",
    "                keywords=[topic.lower(), \"research\", \"analysis\"],\n",
    "                methodology=\"Mixed methods approach\"\n",
    "            )\n",
    "            papers.append(paper)\n",
    "    \n",
    "    return papers[:max_papers]\n",
    "\n",
    "\n",
    "@tool\n",
    "def synthesize_research(papers: List[ResearchPaper], research_question: str) -> ResearchSynthesis:\n",
    "    \"\"\"Synthesize findings from multiple papers.\"\"\"\n",
    "    if not papers:\n",
    "        return ResearchSynthesis(\n",
    "            topic=\"Unknown\",\n",
    "            research_question=research_question,\n",
    "            key_themes=[],\n",
    "            conclusions=[\"No papers available for synthesis\"],\n",
    "            recommendations=[\"Conduct additional research\"],\n",
    "            sources_analyzed=0,\n",
    "            confidence_level=0.0,\n",
    "            limitations=[\"No data available\"]\n",
    "        )\n",
    "    \n",
    "    # Extract common themes\n",
    "    all_keywords = []\n",
    "    all_findings = []\n",
    "    \n",
    "    for paper in papers:\n",
    "        all_keywords.extend(paper.keywords)\n",
    "        all_findings.extend(paper.key_findings)\n",
    "    \n",
    "    # Identify key themes (most common keywords)\n",
    "    keyword_counts = {}\n",
    "    for keyword in all_keywords:\n",
    "        keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1\n",
    "    \n",
    "    key_themes = sorted(keyword_counts.keys(), key=lambda x: keyword_counts[x], reverse=True)[:5]\n",
    "    \n",
    "    # Generate conclusions based on findings\n",
    "    conclusions = [\n",
    "        f\"Analysis of {len(papers)} papers reveals consistent themes in {', '.join(key_themes[:3])}\",\n",
    "        \"Multiple studies indicate the importance of ongoing research in this area\",\n",
    "        \"Cross-study analysis shows both convergent and divergent findings\"\n",
    "    ]\n",
    "    \n",
    "    # Generate recommendations\n",
    "    recommendations = [\n",
    "        \"Future research should address identified gaps in current literature\",\n",
    "        \"Longitudinal studies would provide valuable insights\",\n",
    "        \"Interdisciplinary approaches may yield novel perspectives\",\n",
    "        \"Replication studies are needed to validate current findings\"\n",
    "    ]\n",
    "    \n",
    "    # Calculate confidence level based on number of papers and their relevance\n",
    "    avg_relevance = sum(paper.relevance_score for paper in papers) / len(papers)\n",
    "    confidence = min(0.9, avg_relevance * (len(papers) / 10))  # Max 0.9 confidence\n",
    "    \n",
    "    # Identify limitations\n",
    "    limitations = [\n",
    "        f\"Analysis based on {len(papers)} papers may not represent full literature\",\n",
    "        \"Publication bias may affect representativeness of findings\",\n",
    "        \"Synthesis relies on abstract-level analysis\"\n",
    "    ]\n",
    "    \n",
    "    if len(papers) < 5:\n",
    "        limitations.append(\"Limited number of sources analyzed\")\n",
    "    \n",
    "    # Determine topic from papers\n",
    "    topic = papers[0].title.split(\" - \")[0] if papers else \"Research\"\n",
    "    \n",
    "    return ResearchSynthesis(\n",
    "        topic=topic,\n",
    "        research_question=research_question,\n",
    "        key_themes=key_themes,\n",
    "        conclusions=conclusions,\n",
    "        recommendations=recommendations,\n",
    "        sources_analyzed=len(papers),\n",
    "        confidence_level=confidence,\n",
    "        limitations=limitations\n",
    "    )\n",
    "\n",
    "\n",
    "# Test the implementation\n",
    "print(\"Testing research agent...\")\n",
    "\n",
    "# Search for papers\n",
    "papers = search_research_papers(\"artificial intelligence ethics\", max_papers=3)\n",
    "print(f\"\\nðŸ“š Found {len(papers)} papers:\")\n",
    "for i, paper in enumerate(papers, 1):\n",
    "    print(f\"{i}. {paper.title} (Relevance: {paper.relevance_score:.2f})\")\n",
    "    print(f\"   Authors: {', '.join(paper.citation.authors)}\")\n",
    "    print(f\"   Journal: {paper.citation.journal} ({paper.citation.year})\")\n",
    "\n",
    "# Synthesize research\n",
    "synthesis = synthesize_research(papers, \"What are the main ethical concerns in AI development?\")\n",
    "\n",
    "print(f\"\\nðŸ”¬ Research Synthesis:\")\n",
    "print(f\"Topic: {synthesis.topic}\")\n",
    "print(f\"Research Question: {synthesis.research_question}\")\n",
    "print(f\"Sources Analyzed: {synthesis.sources_analyzed}\")\n",
    "print(f\"Confidence Level: {synthesis.confidence_level:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Key Themes:\")\n",
    "for theme in synthesis.key_themes:\n",
    "    print(f\"  â€¢ {theme}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Conclusions:\")\n",
    "for conclusion in synthesis.conclusions:\n",
    "    print(f\"  â€¢ {conclusion}\")\n",
    "\n",
    "print(f\"\\nðŸš€ Recommendations:\")\n",
    "for rec in synthesis.recommendations:\n",
    "    print(f\"  â€¢ {rec}\")\n",
    "\n",
    "print(f\"\\nâš ï¸ Limitations:\")\n",
    "for limitation in synthesis.limitations:\n",
    "    print(f\"  â€¢ {limitation}\")\n",
    "\n",
    "print(\"\\nâœ… Exercise 2 complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Custom Pydantic Tools Extension\n",
    "\n",
    "**Objective**: Create a comprehensive tool system with advanced validation and error handling.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a base `Tool` class with common functionality\n",
    "2. Implement custom validators using Pydantic\n",
    "3. Add tool chaining capabilities\n",
    "4. Include comprehensive error handling and logging\n",
    "5. Create at least 3 different tool types\n",
    "\n",
    "**Challenge Code**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Advanced Tool System\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, Callable, Any\n",
    "from pydantic import validator, root_validator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ToolExecutionResult(BaseModel):\n",
    "    \"\"\"Result of tool execution.\"\"\"\n",
    "    tool_name: str = Field(description=\"Name of the executed tool\")\n",
    "    success: bool = Field(description=\"Whether execution was successful\")\n",
    "    result: Any = Field(description=\"Tool execution result\")\n",
    "    error_message: Optional[str] = Field(default=None, description=\"Error message if failed\")\n",
    "    execution_time: float = Field(description=\"Execution time in seconds\")\n",
    "    timestamp: datetime = Field(default_factory=datetime.now, description=\"Execution timestamp\")\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict, description=\"Additional metadata\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "class ToolInput(BaseModel):\n",
    "    \"\"\"Base class for tool inputs with validation.\"\"\"\n",
    "    \n",
    "    @validator('*', pre=True)\n",
    "    def validate_not_empty_string(cls, v):\n",
    "        \"\"\"Ensure string fields are not empty.\"\"\"\n",
    "        if isinstance(v, str) and not v.strip():\n",
    "            raise ValueError(\"String fields cannot be empty\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class BaseTool(ABC, BaseModel):\n",
    "    \"\"\"Base class for all tools with common functionality.\"\"\"\n",
    "    \n",
    "    name: str = Field(description=\"Tool name\")\n",
    "    description: str = Field(description=\"Tool description\")\n",
    "    version: str = Field(default=\"1.0.0\", description=\"Tool version\")\n",
    "    enabled: bool = Field(default=True, description=\"Whether tool is enabled\")\n",
    "    max_retries: int = Field(default=3, ge=0, le=10, description=\"Maximum retry attempts\")\n",
    "    timeout: float = Field(default=30.0, gt=0, description=\"Timeout in seconds\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def execute(self, input_data: ToolInput) -> ToolExecutionResult:\n",
    "        \"\"\"Execute the tool with given input.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    async def execute_with_retry(self, input_data: ToolInput) -> ToolExecutionResult:\n",
    "        \"\"\"Execute tool with automatic retry logic.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                success=False,\n",
    "                result=None,\n",
    "                error_message=\"Tool is disabled\",\n",
    "                execution_time=0.0\n",
    "            )\n",
    "        \n",
    "        last_error = None\n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            try:\n",
    "                logger.info(f\"Executing {self.name}, attempt {attempt + 1}\")\n",
    "                return await self.execute(input_data)\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed for {self.name}: {e}\")\n",
    "                if attempt < self.max_retries:\n",
    "                    continue\n",
    "        \n",
    "        return ToolExecutionResult(\n",
    "            tool_name=self.name,\n",
    "            success=False,\n",
    "            result=None,\n",
    "            error_message=f\"Failed after {self.max_retries + 1} attempts: {last_error}\",\n",
    "            execution_time=0.0\n",
    "        )\n",
    "\n",
    "\n",
    "# Specific tool implementations\n",
    "class TextAnalysisInput(ToolInput):\n",
    "    \"\"\"Input for text analysis tool.\"\"\"\n",
    "    text: str = Field(min_length=1, max_length=10000, description=\"Text to analyze\")\n",
    "    analysis_type: Literal[\"sentiment\", \"keywords\", \"summary\", \"language\"] = Field(\n",
    "        description=\"Type of analysis to perform\"\n",
    "    )\n",
    "    \n",
    "    @validator('text')\n",
    "    def validate_text_content(cls, v):\n",
    "        \"\"\"Validate text content.\"\"\"\n",
    "        if len(v.split()) < 2:\n",
    "            raise ValueError(\"Text must contain at least 2 words\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class DataProcessingInput(ToolInput):\n",
    "    \"\"\"Input for data processing tool.\"\"\"\n",
    "    data: List[Dict[str, Any]] = Field(description=\"Data to process\")\n",
    "    operation: Literal[\"filter\", \"aggregate\", \"transform\", \"validate\"] = Field(\n",
    "        description=\"Processing operation\"\n",
    "    )\n",
    "    parameters: Dict[str, Any] = Field(default_factory=dict, description=\"Operation parameters\")\n",
    "    \n",
    "    @validator('data')\n",
    "    def validate_data_not_empty(cls, v):\n",
    "        if not v:\n",
    "            raise ValueError(\"Data list cannot be empty\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class APICallInput(ToolInput):\n",
    "    \"\"\"Input for API call tool.\"\"\"\n",
    "    url: str = Field(description=\"API endpoint URL\")\n",
    "    method: Literal[\"GET\", \"POST\", \"PUT\", \"DELETE\"] = Field(default=\"GET\", description=\"HTTP method\")\n",
    "    headers: Dict[str, str] = Field(default_factory=dict, description=\"Request headers\")\n",
    "    params: Dict[str, Any] = Field(default_factory=dict, description=\"Request parameters\")\n",
    "    \n",
    "    @validator('url')\n",
    "    def validate_url_format(cls, v):\n",
    "        if not v.startswith(('http://', 'https://')):\n",
    "            raise ValueError(\"URL must start with http:// or https://\")\n",
    "        return v\n",
    "\n",
    "\n",
    "# Tool implementations\n",
    "class TextAnalysisTool(BaseTool):\n",
    "    \"\"\"Tool for analyzing text content.\"\"\"\n",
    "    \n",
    "    def __init__(self, **data):\n",
    "        super().__init__(\n",
    "            name=\"text_analyzer\",\n",
    "            description=\"Analyzes text for sentiment, keywords, summaries, and language detection\",\n",
    "            **data\n",
    "        )\n",
    "    \n",
    "    async def execute(self, input_data: TextAnalysisInput) -> ToolExecutionResult:\n",
    "        \"\"\"Execute text analysis.\"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            text = input_data.text\n",
    "            analysis_type = input_data.analysis_type\n",
    "            \n",
    "            if analysis_type == \"sentiment\":\n",
    "                # Mock sentiment analysis\n",
    "                positive_words = [\"good\", \"great\", \"excellent\", \"amazing\", \"wonderful\"]\n",
    "                negative_words = [\"bad\", \"terrible\", \"awful\", \"horrible\", \"disappointing\"]\n",
    "                \n",
    "                words = text.lower().split()\n",
    "                positive_count = sum(1 for word in words if word in positive_words)\n",
    "                negative_count = sum(1 for word in words if word in negative_words)\n",
    "                \n",
    "                if positive_count > negative_count:\n",
    "                    sentiment = \"positive\"\n",
    "                    score = 0.7\n",
    "                elif negative_count > positive_count:\n",
    "                    sentiment = \"negative\"\n",
    "                    score = 0.3\n",
    "                else:\n",
    "                    sentiment = \"neutral\"\n",
    "                    score = 0.5\n",
    "                \n",
    "                result = {\n",
    "                    \"sentiment\": sentiment,\n",
    "                    \"score\": score,\n",
    "                    \"positive_words\": positive_count,\n",
    "                    \"negative_words\": negative_count\n",
    "                }\n",
    "                \n",
    "            elif analysis_type == \"keywords\":\n",
    "                # Mock keyword extraction\n",
    "                words = text.lower().split()\n",
    "                word_freq = {}\n",
    "                for word in words:\n",
    "                    if len(word) > 3:  # Only consider words longer than 3 characters\n",
    "                        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "                \n",
    "                keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                result = {\"keywords\": keywords, \"total_words\": len(words)}\n",
    "                \n",
    "            elif analysis_type == \"summary\":\n",
    "                # Mock text summarization\n",
    "                sentences = text.split('.')\n",
    "                summary = sentences[0] if sentences else text[:100]\n",
    "                result = {\n",
    "                    \"summary\": summary.strip(),\n",
    "                    \"original_length\": len(text),\n",
    "                    \"summary_length\": len(summary),\n",
    "                    \"compression_ratio\": len(summary) / len(text) if text else 0\n",
    "                }\n",
    "                \n",
    "            elif analysis_type == \"language\":\n",
    "                # Mock language detection\n",
    "                result = {\n",
    "                    \"detected_language\": \"en\",\n",
    "                    \"confidence\": 0.95,\n",
    "                    \"alternative_languages\": [\"es\", \"fr\"]\n",
    "                }\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            return ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                success=True,\n",
    "                result=result,\n",
    "                execution_time=execution_time,\n",
    "                metadata={\"analysis_type\": analysis_type, \"text_length\": len(text)}\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            return ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                success=False,\n",
    "                result=None,\n",
    "                error_message=str(e),\n",
    "                execution_time=execution_time\n",
    "            )\n",
    "\n",
    "\n",
    "class DataProcessingTool(BaseTool):\n",
    "    \"\"\"Tool for data processing operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, **data):\n",
    "        super().__init__(\n",
    "            name=\"data_processor\",\n",
    "            description=\"Processes data with filter, aggregate, transform, and validate operations\",\n",
    "            **data\n",
    "        )\n",
    "    \n",
    "    async def execute(self, input_data: DataProcessingInput) -> ToolExecutionResult:\n",
    "        \"\"\"Execute data processing operation.\"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            data = input_data.data\n",
    "            operation = input_data.operation\n",
    "            params = input_data.parameters\n",
    "            \n",
    "            if operation == \"filter\":\n",
    "                field = params.get(\"field\")\n",
    "                value = params.get(\"value\")\n",
    "                if field and value is not None:\n",
    "                    result = [item for item in data if item.get(field) == value]\n",
    "                else:\n",
    "                    result = data\n",
    "                    \n",
    "            elif operation == \"aggregate\":\n",
    "                field = params.get(\"field\")\n",
    "                agg_type = params.get(\"type\", \"count\")\n",
    "                \n",
    "                if agg_type == \"count\":\n",
    "                    result = {\"count\": len(data)}\n",
    "                elif agg_type == \"sum\" and field:\n",
    "                    total = sum(item.get(field, 0) for item in data if isinstance(item.get(field), (int, float)))\n",
    "                    result = {\"sum\": total}\n",
    "                elif agg_type == \"average\" and field:\n",
    "                    values = [item.get(field) for item in data if isinstance(item.get(field), (int, float))]\n",
    "                    avg = sum(values) / len(values) if values else 0\n",
    "                    result = {\"average\": avg}\n",
    "                else:\n",
    "                    result = {\"count\": len(data)}\n",
    "                    \n",
    "            elif operation == \"transform\":\n",
    "                field = params.get(\"field\")\n",
    "                transform_type = params.get(\"type\", \"uppercase\")\n",
    "                \n",
    "                result = []\n",
    "                for item in data:\n",
    "                    new_item = item.copy()\n",
    "                    if field in new_item and isinstance(new_item[field], str):\n",
    "                        if transform_type == \"uppercase\":\n",
    "                            new_item[field] = new_item[field].upper()\n",
    "                        elif transform_type == \"lowercase\":\n",
    "                            new_item[field] = new_item[field].lower()\n",
    "                    result.append(new_item)\n",
    "                    \n",
    "            elif operation == \"validate\":\n",
    "                required_fields = params.get(\"required_fields\", [])\n",
    "                valid_items = []\n",
    "                invalid_items = []\n",
    "                \n",
    "                for item in data:\n",
    "                    if all(field in item for field in required_fields):\n",
    "                        valid_items.append(item)\n",
    "                    else:\n",
    "                        invalid_items.append(item)\n",
    "                \n",
    "                result = {\n",
    "                    \"valid_items\": valid_items,\n",
    "                    \"invalid_items\": invalid_items,\n",
    "                    \"validation_summary\": {\n",
    "                        \"total\": len(data),\n",
    "                        \"valid\": len(valid_items),\n",
    "                        \"invalid\": len(invalid_items)\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            return ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                success=True,\n",
    "                result=result,\n",
    "                execution_time=execution_time,\n",
    "                metadata={\"operation\": operation, \"data_size\": len(data)}\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            return ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                success=False,\n",
    "                result=None,\n",
    "                error_message=str(e),\n",
    "                execution_time=execution_time\n",
    "            )\n",
    "\n",
    "\n",
    "class APICallTool(BaseTool):\n",
    "    \"\"\"Tool for making API calls.\"\"\"\n",
    "    \n",
    "    def __init__(self, **data):\n",
    "        super().__init__(\n",
    "            name=\"api_caller\",\n",
    "            description=\"Makes HTTP API calls with various methods and parameters\",\n",
    "            **data\n",
    "        )\n",
    "    \n",
    "    async def execute(self, input_data: APICallInput) -> ToolExecutionResult:\n",
    "        \"\"\"Execute API call.\"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Mock API call (in real implementation, use aiohttp or requests)\n",
    "            url = input_data.url\n",
    "            method = input_data.method\n",
    "            \n",
    "            # Simulate API response\n",
    "            mock_response = {\n",
    "                \"status_code\": 200,\n",
    "                \"data\": {\n",
    "                    \"message\": f\"Successful {method} request to {url}\",\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"method\": method,\n",
    "                    \"url\": url\n",
    "                },\n",
    "                \"headers\": {\"Content-Type\": \"application/json\"}\n",
    "            }\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            return ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                success=True,\n",
    "                result=mock_response,\n",
    "                execution_time=execution_time,\n",
    "                metadata={\"method\": method, \"url\": url}\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            return ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                success=False,\n",
    "                result=None,\n",
    "                error_message=str(e),\n",
    "                execution_time=execution_time\n",
    "            )\n",
    "\n",
    "\n",
    "# Tool chaining system\n",
    "class ToolChain(BaseModel):\n",
    "    \"\"\"Chain multiple tools together.\"\"\"\n",
    "    \n",
    "    tools: List[BaseTool] = Field(description=\"List of tools in the chain\")\n",
    "    name: str = Field(description=\"Chain name\")\n",
    "    \n",
    "    async def execute_chain(self, inputs: List[ToolInput]) -> List[ToolExecutionResult]:\n",
    "        \"\"\"Execute all tools in the chain.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, (tool, input_data) in enumerate(zip(self.tools, inputs)):\n",
    "            logger.info(f\"Executing tool {i+1}/{len(self.tools)} in chain: {tool.name}\")\n",
    "            result = await tool.execute_with_retry(input_data)\n",
    "            results.append(result)\n",
    "            \n",
    "            # Stop chain execution if a tool fails (optional behavior)\n",
    "            if not result.success:\n",
    "                logger.error(f\"Tool chain '{self.name}' stopped due to failure in {tool.name}\")\n",
    "                break\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Test the advanced tool system\n",
    "async def test_advanced_tools():\n",
    "    \"\"\"Test the advanced tool system.\"\"\"\n",
    "    print(\"ðŸ”§ Testing Advanced Tool System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create tools\n",
    "    text_tool = TextAnalysisTool()\n",
    "    data_tool = DataProcessingTool()\n",
    "    api_tool = APICallTool()\n",
    "    \n",
    "    # Test text analysis\n",
    "    print(\"\\n1. Testing Text Analysis Tool:\")\n",
    "    text_input = TextAnalysisInput(\n",
    "        text=\"This is a wonderful and amazing product. I absolutely love it!\",\n",
    "        analysis_type=\"sentiment\"\n",
    "    )\n",
    "    \n",
    "    result = await text_tool.execute_with_retry(text_input)\n",
    "    print(f\"   Success: {result.success}\")\n",
    "    print(f\"   Result: {result.result}\")\n",
    "    print(f\"   Execution time: {result.execution_time:.3f}s\")\n",
    "    \n",
    "    # Test data processing\n",
    "    print(\"\\n2. Testing Data Processing Tool:\")\n",
    "    data_input = DataProcessingInput(\n",
    "        data=[\n",
    "            {\"name\": \"Alice\", \"age\": 30, \"score\": 85},\n",
    "            {\"name\": \"Bob\", \"age\": 25, \"score\": 92},\n",
    "            {\"name\": \"Charlie\", \"age\": 35, \"score\": 78}\n",
    "        ],\n",
    "        operation=\"aggregate\",\n",
    "        parameters={\"field\": \"score\", \"type\": \"average\"}\n",
    "    )\n",
    "    \n",
    "    result = await data_tool.execute_with_retry(data_input)\n",
    "    print(f\"   Success: {result.success}\")\n",
    "    print(f\"   Result: {result.result}\")\n",
    "    print(f\"   Execution time: {result.execution_time:.3f}s\")\n",
    "    \n",
    "    # Test API call\n",
    "    print(\"\\n3. Testing API Call Tool:\")\n",
    "    api_input = APICallInput(\n",
    "        url=\"https://api.example.com/data\",\n",
    "        method=\"GET\",\n",
    "        headers={\"Authorization\": \"Bearer token123\"}\n",
    "    )\n",
    "    \n",
    "    result = await api_tool.execute_with_retry(api_input)\n",
    "    print(f\"   Success: {result.success}\")\n",
    "    print(f\"   Status Code: {result.result['status_code']}\")\n",
    "    print(f\"   Execution time: {result.execution_time:.3f}s\")\n",
    "    \n",
    "    # Test tool chaining\n",
    "    print(\"\\n4. Testing Tool Chain:\")\n",
    "    tool_chain = ToolChain(\n",
    "        name=\"analysis_chain\",\n",
    "        tools=[text_tool, data_tool]\n",
    "    )\n",
    "    \n",
    "    chain_inputs = [\n",
    "        TextAnalysisInput(text=\"Great product with excellent features\", analysis_type=\"keywords\"),\n",
    "        DataProcessingInput(\n",
    "            data=[{\"keyword\": \"great\", \"count\": 5}, {\"keyword\": \"excellent\", \"count\": 3}],\n",
    "            operation=\"aggregate\",\n",
    "            parameters={\"type\": \"count\"}\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    chain_results = await tool_chain.execute_chain(chain_inputs)\n",
    "    print(f\"   Chain executed {len(chain_results)} tools\")\n",
    "    for i, result in enumerate(chain_results):\n",
    "        print(f\"   Tool {i+1}: {result.tool_name} - Success: {result.success}\")\n",
    "    \n",
    "    # Test validation errors\n",
    "    print(\"\\n5. Testing Validation Errors:\")\n",
    "    try:\n",
    "        invalid_input = TextAnalysisInput(text=\"\", analysis_type=\"sentiment\")\n",
    "    except ValidationError as e:\n",
    "        print(f\"   âœ… Validation error caught: {e.errors()[0]['msg']}\")\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ Advanced tool system testing complete!\")\n",
    "\n",
    "\n",
    "# Run the test\n",
    "await test_advanced_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸŽ‰ Day 1 Summary\n",
    "\n",
    "Congratulations! You've completed Day 1 of the LangGraph Multi-Agent Systems Course. Here's what you've accomplished:\n",
    "\n",
    "## ðŸ† Key Achievements\n",
    "\n",
    "### 1. **Environment Setup**\n",
    "- âœ… Configured OpenAI API integration\n",
    "- âœ… Set up LangGraph development environment\n",
    "- âœ… Installed and configured all necessary dependencies\n",
    "\n",
    "### 2. **Type Safety Mastery**\n",
    "- âœ… Created comprehensive Pydantic models for state management\n",
    "- âœ… Implemented custom validators and error handling\n",
    "- âœ… Built type-safe tool systems with advanced validation\n",
    "\n",
    "### 3. **LangGraph Fundamentals**\n",
    "- âœ… Built your first LangGraph agent with proper architecture\n",
    "- âœ… Implemented intent classification and response generation\n",
    "- âœ… Added comprehensive error handling and retry logic\n",
    "\n",
    "### 4. **Structured Outputs**\n",
    "- âœ… Mastered OpenAI function calling with Pydantic schemas\n",
    "- âœ… Created weather and task analysis tools\n",
    "- âœ… Implemented proper input/output validation\n",
    "\n",
    "### 5. **Practical Applications**\n",
    "- âœ… Built a multi-city weather forecast system\n",
    "- âœ… Created a research paper analysis and synthesis tool\n",
    "- âœ… Developed an advanced tool chaining system\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "You're now ready for **Day 2: State Management & Persistence**! Tomorrow you'll learn:\n",
    "- Graph architecture patterns\n",
    "- Checkpointer implementations (InMemory, SQLite, PostgreSQL)\n",
    "- State persistence and recovery\n",
    "- Advanced routing and conditional logic\n",
    "\n",
    "## ðŸ“š Additional Resources\n",
    "\n",
    "For deeper learning, explore:\n",
    "- [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/)\n",
    "- [Pydantic Advanced Usage](https://docs.pydantic.dev/latest/usage/)\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [Multi-Agent Systems Research](https://arxiv.org/search/?query=multi-agent+systems&searchtype=all)\n",
    "\n",
    "## ðŸ’¡ Pro Tips for Tomorrow\n",
    "\n",
    "1. **Review State Models**: The Pydantic models you created today will be essential for state persistence\n",
    "2. **Practice Error Handling**: The patterns you learned will be crucial for robust state management\n",
    "3. **Understand Graph Flow**: Think about how your agents can maintain state across interactions\n",
    "\n",
    "Great work today! See you in Day 2! ðŸŽ¯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
